{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Exercise2Denise_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4335Vao7Uyap"
      },
      "source": [
        "def GetBatches(TrainingX, TrainingY):\n",
        "    NumberBatches = 64\n",
        "\n",
        "    #randomize order of the data set\n",
        "    idx = torch.randperm(TrainingX.shape[0]) \n",
        "    print(\"IDX: \", idx)\n",
        "\n",
        "    TrainingX = TrainingX[idx]\n",
        "    TrainingY = TrainingY[idx]\n",
        "\n",
        "    #split into batches\n",
        "    newTrainingX = torch.split(TrainingX,int(len(TrainingX)/NumberBatches))\n",
        "    newTrainingY = torch.split(TrainingY,int(len(TrainingY)/NumberBatches))\n",
        "\n",
        "    return newTrainingX, newTrainingY"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "ktj6wQOPUyas",
        "outputId": "aacba55e-be0f-42bf-fc34-c00e814b39c7"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from time import time\n",
        "\n",
        "#https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627\n",
        "\n",
        "#FileNames\n",
        "#inputFilename = 'prediction-challenge-01-data.npz'\n",
        "inputFilename = 'sample_data/prediction-challenge-01-data.npz'\n",
        "#outputFilename = 'prediction-challenge-01-data.npz'\n",
        "outputFilename = 'prediction.npy'\n",
        "\n",
        "\n",
        "with np.load(inputFilename) as fh:\n",
        "    data_x = fh['data_x']\n",
        "    data_y = fh['data_y']\n",
        "    test_x = fh['test_x']\n",
        "\n",
        "\n",
        "\n",
        "# TRAINING DATA: INPUT (x) AND OUTPUT (y)\n",
        "# 1. INDEX: IMAGE SERIAL NUMBER\n",
        "# 2. INDEX: COLOR CHANNEL\n",
        "# 3/4. INDEX: PIXEL VALUE\n",
        "print(data_x.shape, data_x.dtype)\n",
        "print(data_y.shape, data_y.dtype)\n",
        "\n",
        "X = torch.from_numpy(data_x)\n",
        "Y = torch.from_numpy(data_y)\n",
        "PredictMeX = torch.from_numpy(test_x)\n",
        "\n",
        "print(\"X\",X.shape)\n",
        "\n",
        "#Build Testset from Trainingset\n",
        "dataX = torch.split(X, [15000,5000])\n",
        "dataY = torch.split(Y, [15000,5000])\n",
        "\n",
        "TrainingX = dataX[0]\n",
        "TestX = dataX[1]\n",
        "TrainingY = dataY[0]\n",
        "TestY = dataY[1]\n",
        "\n",
        "#Alternatively, use all data for training:\n",
        "#TrainingX = X\n",
        "#TrainingY = Y\n",
        "\n",
        "print(TrainingX.shape)\n",
        "# TEST DATA: INPUT (x) ONLY\n",
        "print(test_x.shape, test_x.dtype)\n",
        "\n",
        "plt.imshow(data_x[0, 0])\n",
        "plt.title(data_y[0])\n",
        "plt.show()\n",
        "\n",
        "#Build Model\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 1, 28, 28) float32\n",
            "(20000,) int64\n",
            "X torch.Size([20000, 1, 28, 28])\n",
            "torch.Size([15000, 1, 28, 28])\n",
            "(2000, 1, 28, 28) float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAP+ElEQVR4nO3dfbBcdX3H8c83IQSIRJImhhiCUIlKzEwC3iYVUcBUDBEbcJAhMjRYnMsU8JFKGewIndKRdnjwiaerpCSKURQo0aZUjGCkaRMuDOYBCERIJCEPhDgmioT78O0fe3AucM9vb/bs7tl7v+/XzM7dPd89e76z8MnZ3d8552fuLgBD37CyGwDQHIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhR7/M7CgzW2ZmvzWz7Wb2TTM7oOy+UDvCjjw3SdopaaKkGZJOknRRqR2hEMKOPEdLutPdX3b37ZLuk/TukntCAYQdeb4q6RwzO8TMJkk6TZXAY5Ai7MizQpU9+R5JWyR1SvqPUjtCIYQdb2Bmw1TZi98taZSkcZLGSPrXMvtCMcZZb3g9Mxsn6QVJh7n777JlZ0i62t2nldocasaeHW/g7rskPSvp78zsADM7TNICSWvK7QxFEHbk+ZikOars4TdK6pL0+VI7QiF8jAeCYM8OBEHYgSAIOxAEYQeCaOpZTAfaSD9Io5q5SSCUl/UHveL7rL9aobCb2RxJX5M0XNK33f2a1PMP0ijNstlFNgkgYZUvz63V/DHezIZLulGVEySmSppvZlNrfT0AjVXkO/tMSRvd/Rl3f0XS9yXNq09bAOqtSNgnSXquz+Mt2bLXMLN2M+s0s84u7SuwOQBFNPzXeHfvcPc2d28boZGN3hyAHEXCvlXS5D6Pj8iWAWhBRcL+sKQpZna0mR0o6RxJS+vTFoB6q3nozd27zewSSf+tytDbQndfX7fOANRVoXF2d18maVmdegHQQBwuCwRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQTZ2yGbWxkemZdJ6/5D25tZ4Tfpdc98YZS5L1ix+bn6zb6jcn60f+5MXcWs/6Dcl1UV/s2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCHP3pm1stI31WTa7adsbLKxtWrK+7yt7k/WfTb0nt3b7nrcm1+0p+O/9BaO3JOsLNn8wt7b2B1OT60767pPJes+Lu5P1iFb5cu3x3dZfrdBBNWa2SdJeST2Sut29rcjrAWicehxBd4q776rD6wBoIL6zA0EUDbtL+qmZPWJm7f09wczazazTzDq7tK/g5gDUqujH+BPdfauZvUXS/Wb2pLuv6PsEd++Q1CFVfqAruD0ANSq0Z3f3rdnfnZLukTSzHk0BqL+aw25mo8zs0FfvSzpV0rp6NQagvop8jJ8g6R4ze/V1vufu99WlqyFm2PRjk/VPfu/HyfrJBz+frB+7+O9za0d/aXVyXfX2pOtVfOXbc5P1jad15Bcv+3ly3XPP/qtkfdc/Hp+sD3/g0WQ9mprD7u7PSJpex14ANBBDb0AQhB0IgrADQRB2IAjCDgTBpaTrwA5Iv41HdPwmWZ8xMj209qHrv5isH33DymS9kab+845kfebqi3NrPjz92qd8alWy/tFb7k3W73jfjNxaz678S1wPVezZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtnr4KXT06da3nLELcn61bv+Ilk/vMRx9Gq6Nz+XrI/rSNdTHv+fdyXrH7z78WT9kHv6vaKyJGnv+2tqaVBjzw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDOXgcvHlvsbbz72fRFeg/XE4Vef7DqXZOesvnyW/82Wb/9oq/m1q4IOJ8Je3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIJx9joYvbm30Pp7XhyVrB9e6NWHrsNX/zH9hIua08dgUXXPbmYLzWynma3rs2ysmd1vZk9nf8c0tk0ARQ3kY/ztkua8btnlkpa7+xRJy7PHAFpY1bC7+wpJu1+3eJ6kRdn9RZLOqHNfAOqs1u/sE9x9W3Z/u6QJeU80s3ZJ7ZJ0kA6pcXMAiir8a7y7uyRP1Dvcvc3d20ZoZNHNAahRrWHfYWYTJSn7u7N+LQFohFrDvlTSguz+AknpuXMBlK7qd3YzWyLpZEnjzGyLpCslXSPpTjO7QNJmSWc3sslWN3pJeh7xD/zNWcn6+W3p68Kv1IH73VMEz59wcNktDCpVw+7u83NKs+vcC4AG4nBZIAjCDgRB2IEgCDsQBGEHguAU13rw3AMIJUmv3Jl7NLEkqf2qxcn6zz/6hWT9oB+vTtYHq2GHHpqsTz895iW2a8WeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJy9CcYu/N9kfc6bL0vWV9x8XbI+67z23NrIlemx6knf3ZCs9+x6MVmvZlf7e3Nr3YdYct097+5K1jcedWuy/o4ffia3doz+L7nuUMSeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCMK9yLnY9jbaxPsu4KO3+6jnl+GR97jcezK19dszG5LrX7n5nsr74qZnJ+hXT7kvWzz00f5y+x4tNdX3mxrnJ+r6Tthd6/cFolS/XHt/d7wEM7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2YeA4aNH59Y2/NPU5LpPnX1TvdtpmtmfujBZH/lfDzepk9ZRaJzdzBaa2U4zW9dn2VVmttXMHstu6aMbAJRuIB/jb5c0p5/lN7j7jOy2rL5tAai3qmF39xWSdjehFwANVOQHukvMbE32MX9M3pPMrN3MOs2ss0v7CmwOQBG1hv1mSW+XNEPSNkm5V0R09w53b3P3thEaWePmABRVU9jdfYe797h7r6RvSUqfGgWgdDWF3cwm9nl4pqR1ec8F0BqqXjfezJZIOlnSODPbIulKSSeb2QxJLmmTpPSAJ4qx9PXVN31mWm7t3+elx9F7lT7OYva6s5L1revTc8/3jurJrc2a9uvkutdOXpqsL771hmT9lF98Orc25ZNrk+t6d3eyPhhVDbu7z+9n8W0N6AVAA3G4LBAEYQeCIOxAEIQdCIKwA0EwZXMLGD5+fLL+1GXHJOsbPvHN3Nr6rleS6878ly8k62+5aWWyfoyeTdZTflulfoFOTNZ/8+UTkvWnLsx/X4770bnJdd961tPJ+mAcmmPPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBcCnpJvD3Tk/W3/H1J5P1ayb+Ilk//fFzcmujFrycXLd72+Cd1thGHJisT/plfr1j8orkuqe/66RkvXfv3mS9LEzZDICwA1EQdiAIwg4EQdiBIAg7EARhB4LgfPY6sJHpmW7GX7c5Wa82jt52W/qc87ddmX/O+eA763rgvMq5+isefE9+8bz0OPtQxJ4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4IYyJTNkyUtljRBlSmaO9z9a2Y2VtIPJB2lyrTNZ7t7tUuBD009+dMSS9LBw7uS9eerrD/+V+l6VC99bFay/p/zr82vvZS+Vr+60v/NBqOB7Nm7JV3q7lMl/aWki81sqqTLJS139ymSlmePAbSoqmF3923u/mh2f6+kJyRNkjRP0qLsaYskndGoJgEUt1/f2c3sKEnHSVolaYK7b8tK21X5mA+gRQ047Gb2Jkl3Sfqcu+/pW/PKhez6vZidmbWbWaeZdXZpX6FmAdRuQGE3sxGqBP0Od787W7zDzCZm9YmSdva3rrt3uHubu7eNUPqEEQCNUzXsZmaSbpP0hLtf36e0VNKC7P4CSffWvz0A9VL1UtJmdqKkX0paK6k3W3yFKt/b75R0pKTNqgy97U69VtRLSf9x3sxkfdmNX0/Wd/emT1T9xOcvza2NumtVct0y9Z50XLI+7MsvJOt3vfNHyfpP/jAxt7bo4x9Ortu7Jn1571aVupR01XF2d39IUr8rS4qXXGCQ4gg6IAjCDgRB2IEgCDsQBGEHgiDsQBBM2dwCumcnLnks6ZmPD0/Wl5x6c25t/b5JyXWvfvCvk/UD9qa37XmDspnzP/xAbu2CwzrTK1dx0sqLkvUpX8w/7KP7uS2Ftt2qmLIZAGEHoiDsQBCEHQiCsANBEHYgCMIOBME4+xDQ+/7888I/ckv+OLckffqwZ+rdzmtc+cL03NoPN6TPZz/yG+l90bCHHqupp6GMcXYAhB2IgrADQRB2IAjCDgRB2IEgCDsQBOPswBDCODsAwg5EQdiBIAg7EARhB4Ig7EAQhB0IomrYzWyymT1gZo+b2Xoz+2y2/Coz22pmj2W3uY1vF0Ctqs7PLqlb0qXu/qiZHSrpETO7P6vd4O7XNq49APVSNezuvk3Stuz+XjN7QlJ6mhEALWe/vrOb2VGSjpO0Klt0iZmtMbOFZjYmZ512M+s0s84u7SvULIDaDTjsZvYmSXdJ+py775F0s6S3S5qhyp7/uv7Wc/cOd29z97YRGlmHlgHUYkBhN7MRqgT9Dne/W5LcfYe797h7r6RvSZrZuDYBFDWQX+NN0m2SnnD36/ssn9jnaWdKWlf/9gDUy0B+jX+fpPMkrTWzV6/de4Wk+WY2Q5JL2iTpwoZ0CKAuBvJr/EOS+js/dln92wHQKBxBBwRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCKKpUzab2QuSNvdZNE7SrqY1sH9atbdW7Uuit1rVs7e3ufv4/gpNDfsbNm7W6e5tpTWQ0Kq9tWpfEr3Vqlm98TEeCIKwA0GUHfaOkref0qq9tWpfEr3Vqim9lfqdHUDzlL1nB9AkhB0IopSwm9kcM9tgZhvN7PIyeshjZpvMbG02DXVnyb0sNLOdZrauz7KxZna/mT2d/e13jr2SemuJabwT04yX+t6VPf1507+zm9lwSU9J+pCkLZIeljTf3R9vaiM5zGyTpDZ3L/0ADDP7gKTfS1rs7tOyZf8mabe7X5P9QznG3f+hRXq7StLvy57GO5utaGLfacYlnSHpfJX43iX6OltNeN/K2LPPlLTR3Z9x91ckfV/SvBL6aHnuvkLS7tctnidpUXZ/kSr/szRdTm8twd23ufuj2f29kl6dZrzU9y7RV1OUEfZJkp7r83iLWmu+d5f0UzN7xMzay26mHxPcfVt2f7ukCWU204+q03g30+umGW+Z966W6c+L4ge6NzrR3Y+XdJqki7OPqy3JK9/BWmnsdEDTeDdLP9OM/0mZ712t058XVUbYt0qa3OfxEdmyluDuW7O/OyXdo9abinrHqzPoZn93ltzPn7TSNN79TTOuFnjvypz+vIywPyxpipkdbWYHSjpH0tIS+ngDMxuV/XAiMxsl6VS13lTUSyUtyO4vkHRvib28RqtM4503zbhKfu9Kn/7c3Zt+kzRXlV/kfy3pS2X0kNPXn0v6VXZbX3Zvkpao8rGuS5XfNi6Q9GeSlkt6WtLPJI1tod6+I2mtpDWqBGtiSb2dqMpH9DWSHstuc8t+7xJ9NeV943BZIAh+oAOCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIP4f59/j2Ei7wNwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlQhpoV4Uyat",
        "outputId": "dcf416d5-e518-46eb-d19c-6c8b5b9da671"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "time0 = time()\n",
        "epochs = 100\n",
        "     \n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    \n",
        "    losses = []\n",
        "\n",
        "    BatchesX, BatchesY = GetBatches(TrainingX, TrainingY)\n",
        "    \n",
        "    for i in range(len(BatchesX)):\n",
        "        #Flatten\n",
        "        x = BatchesX[i]\n",
        "        x = torch.flatten(x, start_dim = 1)\n",
        "        y = BatchesY[i]\n",
        "  \n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "\n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(BatchesX[0])))\n",
        "    \n",
        "    #print('weights 1',torch.nonzero(model[0].weight.grad ))\n",
        "\n",
        "\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60) \n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IDX:  tensor([12984, 13673,  2077,  ...,  9351,  7736, 12019])\n",
            "Epoch 0 - Training loss: 0.8946635379241064\n",
            "IDX:  tensor([2245, 1529, 1341,  ..., 6669, 5398, 1304])\n",
            "Epoch 1 - Training loss: 0.2556478749228339\n",
            "IDX:  tensor([ 9239,  9806,  9779,  ...,  8837, 11021,  4271])\n",
            "Epoch 2 - Training loss: 0.1329947209511048\n",
            "IDX:  tensor([10623,  2185,  1192,  ...,  7842, 12499, 11019])\n",
            "Epoch 3 - Training loss: 0.0901601818891672\n",
            "IDX:  tensor([ 5120,  8954,  3484,  ..., 10500,   344,   338])\n",
            "Epoch 4 - Training loss: 0.07359974818606661\n",
            "IDX:  tensor([ 7157,  4586,  2453,  ..., 14364,  9230, 13943])\n",
            "Epoch 5 - Training loss: 0.07295325357053015\n",
            "IDX:  tensor([ 3065, 13363, 13876,  ..., 12788, 10902,   569])\n",
            "Epoch 6 - Training loss: 0.061219577160146504\n",
            "IDX:  tensor([  525, 12562,  9050,  ...,  4003, 13305,  2305])\n",
            "Epoch 7 - Training loss: 0.06027685010280365\n",
            "IDX:  tensor([13074,   272,  2109,  ..., 13114,  1419, 12886])\n",
            "Epoch 8 - Training loss: 0.05813948138274698\n",
            "IDX:  tensor([4233, 6445, 8270,  ..., 5509, 1699, 6194])\n",
            "Epoch 9 - Training loss: 0.04896067350338667\n",
            "IDX:  tensor([12453,  1527,  1910,  ...,  8756,  1231,  1220])\n",
            "Epoch 10 - Training loss: 0.05038366680089225\n",
            "IDX:  tensor([8557, 5155, 4535,  ..., 6035, 8733, 6123])\n",
            "Epoch 11 - Training loss: 0.04856905277468201\n",
            "IDX:  tensor([ 2512,  9029,  2077,  ..., 13812,  5936, 10563])\n",
            "Epoch 12 - Training loss: 0.0494494503761968\n",
            "IDX:  tensor([  320, 12789,   394,  ...,  8018, 12655,  1322])\n",
            "Epoch 13 - Training loss: 0.040017307536979005\n",
            "IDX:  tensor([3419,  479, 1822,  ..., 1301, 8880, 5811])\n",
            "Epoch 14 - Training loss: 0.03861559437126176\n",
            "IDX:  tensor([ 636, 3918, 1117,  ..., 6674, 1726,  547])\n",
            "Epoch 15 - Training loss: 0.0352296512414757\n",
            "IDX:  tensor([ 8150,  8500, 10924,  ...,  6262, 12492,  2209])\n",
            "Epoch 16 - Training loss: 0.032927837493455306\n",
            "IDX:  tensor([ 8380,  1692, 14672,  ...,  1955,  3162, 14597])\n",
            "Epoch 17 - Training loss: 0.03439579491750298\n",
            "IDX:  tensor([ 6855, 13116, 11870,  ...,  6039,  3488,  3952])\n",
            "Epoch 18 - Training loss: 0.039189419303184904\n",
            "IDX:  tensor([11170,  9614,  9527,  ...,  9913,  8741,  6177])\n",
            "Epoch 19 - Training loss: 0.02892280914860531\n",
            "IDX:  tensor([ 6737,   938, 12665,  ..., 12700,  8889,  9912])\n",
            "Epoch 20 - Training loss: 0.026530909129621413\n",
            "IDX:  tensor([12852,  3207,  3123,  ...,  6118,  5383,  1909])\n",
            "Epoch 21 - Training loss: 0.02551178116765287\n",
            "IDX:  tensor([14779,  9375, 10665,  ...,  1253, 12831, 14251])\n",
            "Epoch 22 - Training loss: 0.02789388099510191\n",
            "IDX:  tensor([5669, 7033, 6730,  ..., 1510,  731,  635])\n",
            "Epoch 23 - Training loss: 0.02334538080657904\n",
            "IDX:  tensor([ 6315,  8896, 13272,  ...,  7272,   866,  3034])\n",
            "Epoch 24 - Training loss: 0.023378745055733584\n",
            "IDX:  tensor([ 2592, 10565, 13261,  ...,  7759,  5293,  1853])\n",
            "Epoch 25 - Training loss: 0.02338298142919492\n",
            "IDX:  tensor([ 1114,  3833,  7529,  ...,  9559, 10148,  8876])\n",
            "Epoch 26 - Training loss: 0.018895677863978423\n",
            "IDX:  tensor([6790,  211, 4465,  ..., 9773, 2521, 5513])\n",
            "Epoch 27 - Training loss: 0.01666405234629145\n",
            "IDX:  tensor([ 3406,   374,  8062,  ..., 13479, 13895, 14820])\n",
            "Epoch 28 - Training loss: 0.018402778615172092\n",
            "IDX:  tensor([14756, 14258,  8261,  ..., 12599, 14814,  1268])\n",
            "Epoch 29 - Training loss: 0.017971485633050833\n",
            "IDX:  tensor([ 8470,  2170,  3078,  ...,  3058,  1316, 12593])\n",
            "Epoch 30 - Training loss: 0.016430224041239574\n",
            "IDX:  tensor([13701,  2803, 10212,  ...,   119,  6266,  4771])\n",
            "Epoch 31 - Training loss: 0.014499596730033811\n",
            "IDX:  tensor([ 9869, 13243,  3865,  ..., 13767,  8195,  2750])\n",
            "Epoch 32 - Training loss: 0.01345513203046006\n",
            "IDX:  tensor([8570, 4315, 2815,  ..., 8814, 8971, 5289])\n",
            "Epoch 33 - Training loss: 0.011849765415088488\n",
            "IDX:  tensor([10529,  2817, 14418,  ...,  5394, 11066, 14480])\n",
            "Epoch 34 - Training loss: 0.011460801360705314\n",
            "IDX:  tensor([ 6345,   677,  5165,  ...,  6809, 14842,  4749])\n",
            "Epoch 35 - Training loss: 0.014414244801060766\n",
            "IDX:  tensor([ 4203,  9624, 10334,  ...,  4988, 10238, 12760])\n",
            "Epoch 36 - Training loss: 0.015377456942199068\n",
            "IDX:  tensor([ 4998,  5208, 12163,  ..., 14546,  6169,   248])\n",
            "Epoch 37 - Training loss: 0.012377971194238745\n",
            "IDX:  tensor([ 5714, 12641,  7073,  ..., 12655, 11045, 10127])\n",
            "Epoch 38 - Training loss: 0.01131437891202732\n",
            "IDX:  tensor([2499,  891, 3009,  ..., 3967, 4571, 8781])\n",
            "Epoch 39 - Training loss: 0.008875209997352371\n",
            "IDX:  tensor([ 1584,  5199, 12574,  ...,  3462,  1761,    50])\n",
            "Epoch 40 - Training loss: 0.00822371837651182\n",
            "IDX:  tensor([ 3427, 10000, 12316,  ...,  3990,  5456, 14344])\n",
            "Epoch 41 - Training loss: 0.008099327540486796\n",
            "IDX:  tensor([10615, 13397,    65,  ...,  5466,  9689,  7001])\n",
            "Epoch 42 - Training loss: 0.010754050284228088\n",
            "IDX:  tensor([13015,  9436,  1139,  ..., 10644, 13909,  1568])\n",
            "Epoch 43 - Training loss: 0.00824582320638001\n",
            "IDX:  tensor([12115, 14779,  9501,  ..., 13330,  8327,  8067])\n",
            "Epoch 44 - Training loss: 0.0066819823915178645\n",
            "IDX:  tensor([ 3370, 13687,  8654,  ...,  8264, 14383,  7056])\n",
            "Epoch 45 - Training loss: 0.008148671090045674\n",
            "IDX:  tensor([ 7723,  9725,  6477,  ..., 11089,  2264, 13545])\n",
            "Epoch 46 - Training loss: 0.008468754302996855\n",
            "IDX:  tensor([10047,  1183,  9658,  ..., 11324,  9056, 11069])\n",
            "Epoch 47 - Training loss: 0.014813856597846517\n",
            "IDX:  tensor([ 2073, 11745,  8801,  ...,   274, 10014,  7118])\n",
            "Epoch 48 - Training loss: 0.014957861735599423\n",
            "IDX:  tensor([ 7050,  8937, 11538,  ...,  6897, 11837,  8047])\n",
            "Epoch 49 - Training loss: 0.01513294011959408\n",
            "IDX:  tensor([  951,   653, 10702,  ..., 13854,  2521,  4335])\n",
            "Epoch 50 - Training loss: 0.011484438396242058\n",
            "IDX:  tensor([8959, 3196, 2071,  ..., 6064,  876, 3694])\n",
            "Epoch 51 - Training loss: 0.011493650363481099\n",
            "IDX:  tensor([13065,  2654, 14129,  ...,  9820,  1061, 13959])\n",
            "Epoch 52 - Training loss: 0.01200245720315446\n",
            "IDX:  tensor([ 7674,  4763, 11695,  ...,  6215,  1238, 12433])\n",
            "Epoch 53 - Training loss: 0.011646806256463513\n",
            "IDX:  tensor([ 5696,  8280,  9532,  ...,  8393, 13846,   550])\n",
            "Epoch 54 - Training loss: 0.010044109098151581\n",
            "IDX:  tensor([11557, 11794, 12995,  ...,  4035, 11341,  1360])\n",
            "Epoch 55 - Training loss: 0.01834989611339769\n",
            "IDX:  tensor([ 3324,   590, 14813,  ...,  1375,  1010, 10649])\n",
            "Epoch 56 - Training loss: 0.019139482353169184\n",
            "IDX:  tensor([14639, 13108,   241,  ...,   547,  2923, 11556])\n",
            "Epoch 57 - Training loss: 0.016172830548742387\n",
            "IDX:  tensor([4218, 5494, 3632,  ..., 6114, 2392,   62])\n",
            "Epoch 58 - Training loss: 0.009639996597463759\n",
            "IDX:  tensor([10488,  3104, 11045,  ...,  6675,  7725,  3425])\n",
            "Epoch 59 - Training loss: 0.006705949687932292\n",
            "IDX:  tensor([5624, 1975, 6229,  ..., 8173, 6974, 1229])\n",
            "Epoch 60 - Training loss: 0.006073498128292461\n",
            "IDX:  tensor([14802, 11907,  7926,  ...,  9146,  1430, 14199])\n",
            "Epoch 61 - Training loss: 0.005644955832519147\n",
            "IDX:  tensor([ 8364,  3409,  7024,  ...,  4295, 13750,  2168])\n",
            "Epoch 62 - Training loss: 0.006053304250459545\n",
            "IDX:  tensor([11081,  1838, 14142,  ...,  1120,  5424, 11107])\n",
            "Epoch 63 - Training loss: 0.025906698111619834\n",
            "IDX:  tensor([ 4428, 10221, 12932,  ..., 11483,  9866,  7679])\n",
            "Epoch 64 - Training loss: 0.01164115447168931\n",
            "IDX:  tensor([14445, 13743, 13431,  ..., 11225, 14680,   417])\n",
            "Epoch 65 - Training loss: 0.007528184136996667\n",
            "IDX:  tensor([10950, 14457, 13770,  ...,  9440,  7251, 12446])\n",
            "Epoch 66 - Training loss: 0.01567038649899097\n",
            "IDX:  tensor([  981,   234,  7799,  ...,  8983, 11408,  4156])\n",
            "Epoch 67 - Training loss: 0.010864797231599959\n",
            "IDX:  tensor([14118,  8754,  3461,  ...,  7702,  8955,  1191])\n",
            "Epoch 68 - Training loss: 0.006381691015588167\n",
            "IDX:  tensor([13615,  6241,  1434,  ...,   920,  7200,  6995])\n",
            "Epoch 69 - Training loss: 0.006645930905102028\n",
            "IDX:  tensor([ 6632,  5407, 10859,  ..., 11374, 13091,  8071])\n",
            "Epoch 70 - Training loss: 0.005214184904958591\n",
            "IDX:  tensor([14617,  6300,  7827,  ..., 11038, 13813,  8821])\n",
            "Epoch 71 - Training loss: 0.008416097884814644\n",
            "IDX:  tensor([ 5120,  1081,  8925,  ..., 13083,  2457,  6829])\n",
            "Epoch 72 - Training loss: 0.01579175538952566\n",
            "IDX:  tensor([2770,   36, 6860,  ..., 4424,  411, 9317])\n",
            "Epoch 73 - Training loss: 0.02070266126981403\n",
            "IDX:  tensor([  674, 11112,  9265,  ...,   628, 12490, 14053])\n",
            "Epoch 74 - Training loss: 0.008161501321169492\n",
            "IDX:  tensor([ 8135,  7097,  9740,  ..., 11204,  1828,  4995])\n",
            "Epoch 75 - Training loss: 0.004486437363084406\n",
            "IDX:  tensor([ 8801,  2779,  4544,  ..., 13538,  9075, 12704])\n",
            "Epoch 76 - Training loss: 0.004248558937643583\n",
            "IDX:  tensor([2215, 6484, 5899,  ..., 1063, 6162, 5543])\n",
            "Epoch 77 - Training loss: 0.0033900668823685595\n",
            "IDX:  tensor([13380,   436,  9756,  ..., 10501,  9968,  7511])\n",
            "Epoch 78 - Training loss: 0.003658968700899725\n",
            "IDX:  tensor([ 7259, 14446,  1750,  ...,  6852,  4221,  4299])\n",
            "Epoch 79 - Training loss: 0.0025638871898314764\n",
            "IDX:  tensor([12192,  3514,  2479,  ...,  9215,  4131,  5553])\n",
            "Epoch 80 - Training loss: 0.002185298752290412\n",
            "IDX:  tensor([14345,  3013,  8709,  ...,  9513, 10325,  6836])\n",
            "Epoch 81 - Training loss: 0.002508116196918114\n",
            "IDX:  tensor([ 7929,   383, 13501,  ..., 12459,   282,  7927])\n",
            "Epoch 82 - Training loss: 0.0017480000095944973\n",
            "IDX:  tensor([12108,  5376, 11836,  ...,  5608, 10175, 14361])\n",
            "Epoch 83 - Training loss: 0.0013682754912830812\n",
            "IDX:  tensor([ 9872,  3827,  3053,  ...,   111,  6778, 13042])\n",
            "Epoch 84 - Training loss: 0.0015249589961081839\n",
            "IDX:  tensor([ 6239,  9674, 10604,  ..., 10135, 10172, 13874])\n",
            "Epoch 85 - Training loss: 0.0013695057454413504\n",
            "IDX:  tensor([  392,  9799, 12989,  ...,  8826,  2602,  6495])\n",
            "Epoch 86 - Training loss: 0.0010357370183322555\n",
            "IDX:  tensor([ 2962, 12454,  5723,  ...,  1604,  6578, 14681])\n",
            "Epoch 87 - Training loss: 0.0009399700351283313\n",
            "IDX:  tensor([ 5942,  4955, 10310,  ...,  3902, 12860, 13229])\n",
            "Epoch 88 - Training loss: 0.0007783144193927312\n",
            "IDX:  tensor([12987, 11975,  3752,  ..., 11547,  1517,  3477])\n",
            "Epoch 89 - Training loss: 0.000746713609881918\n",
            "IDX:  tensor([2529, 9964, 1408,  ..., 7330, 4040, 2367])\n",
            "Epoch 90 - Training loss: 0.0006482996976621943\n",
            "IDX:  tensor([ 9247,  1487, 13646,  ...,  3319, 14547,  4040])\n",
            "Epoch 91 - Training loss: 0.0005532169663101974\n",
            "IDX:  tensor([13085,   220,  2645,  ..., 10559,  1919,  8817])\n",
            "Epoch 92 - Training loss: 0.0005220914951608463\n",
            "IDX:  tensor([ 8076,  5389,  6800,  ...,  8052, 10249,  9178])\n",
            "Epoch 93 - Training loss: 0.0005214566449583985\n",
            "IDX:  tensor([ 3260,  8179,  7688,  ..., 12053,  3138,  9839])\n",
            "Epoch 94 - Training loss: 0.0005241687787432049\n",
            "IDX:  tensor([13567, 12410, 12435,  ...,  1890,  6187,  5881])\n",
            "Epoch 95 - Training loss: 0.0005088576564538436\n",
            "IDX:  tensor([ 565,  672, 4931,  ..., 8354, 9494, 9054])\n",
            "Epoch 96 - Training loss: 0.0004491230209122221\n",
            "IDX:  tensor([11699,  1717,  2292,  ...,  4423,  3435, 10886])\n",
            "Epoch 97 - Training loss: 0.0004232277041231481\n",
            "IDX:  tensor([11455,  7050, 12546,  ..., 14439,  6616,  9035])\n",
            "Epoch 98 - Training loss: 0.0004004028011185543\n",
            "IDX:  tensor([ 8535, 14693,  2764,  ...,  5603,  8708,  2729])\n",
            "Epoch 99 - Training loss: 0.0003882864816387932\n",
            "\n",
            "Training Time (in minutes) = 0.508097239335378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "KovCpVOKUyau",
        "outputId": "36283503-0583-4b59-b411-1f6d215e11fc"
      },
      "source": [
        "# Test Model\n",
        "correct_count, all_count = 0, 0\n",
        "\n",
        "wrong_predictions = []\n",
        "\n",
        "for i in range(TestX.shape[0]):\n",
        "    image = torch.flatten(TestX[i], start_dim = 1)\n",
        "\n",
        "    # Turn off gradients to speed up this part\n",
        "    with torch.no_grad():\n",
        "        logps = model(image)\n",
        "\n",
        "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = TestY[i]\n",
        "    if true_label == pred_label:\n",
        "        correct_count += 1\n",
        "    else:\n",
        "      wrong_predictions.append(pred_label)\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"Correct predictions =\", correct_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))\n",
        "\n",
        "values, counts = np.unique(wrong_predictions, return_counts=True)\n",
        "print(\"Wrong predicted labels: \")\n",
        "plt.bar(values, counts)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 5000\n",
            "Correct predictions = 4701\n",
            "\n",
            "Model Accuracy = 0.9402\n",
            "Wrong predicted labels: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALPElEQVR4nO3df6jdd33H8edrSYu/YK3rpdSk3Q1YKmGglUtXVxBpFToitn+UUZkljEr+0a1ugkb/G+yPCMMff4gQWrfAilVioaUd20qtjIFk3rSd2mbSrIuaLjVXtOr2x1zme3/cb2a8TXLP/XHOyfue5wPKPd/vOTff95fePvvN957PvakqJEn9/Ma0B5AkrY8Bl6SmDLgkNWXAJakpAy5JTW2f5MGuuuqqmp+fn+QhJam9o0eP/qiq5lbun2jA5+fnWVxcnOQhJam9JN87335voUhSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTE12JKUkXMr//8bH++ScO7Bnrnz8NXoFLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKhTySZl7XRURegUtSUwZckpoy4JLUlAGXpKYMuCQ1NXLAk2xL8kySx4btXUmOJDme5MtJLh/fmJKkldZyBX4fcOyc7U8Bn6mqNwM/Ae7dzMEkSRc3UsCT7AT2APcP2wFuBQ4PLzkE3DmOASVJ5zfqFfhngY8Bvxy2fwt4parODNsngR2bPJsk6SJWXYmZ5L3A6ao6muRdaz1Akn3APoDrrrtuzQNqesa9Og225q+5kiZllCvwW4D3JTkBPMTyrZPPAVckOfs/gJ3AS+f75Ko6WFULVbUwNze3CSNLkmCEgFfVJ6pqZ1XNA3cDX6uqPwSeAu4aXrYXeGRsU0qSXmUj7wP/OPBnSY6zfE/8gc0ZSZI0ijX9NMKq+jrw9eHxi8BNmz+SJGkUrsSUpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNbWmX6kmTcr8/sfHfowTB/aM/RjSOHkFLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKRfySCu4iEhdeAUuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWpq1YAneU2Sf07yL0meS/Lnw/5dSY4kOZ7ky0kuH/+4kqSzRrkC/2/g1qp6K/A24PYkNwOfAj5TVW8GfgLcO74xJUkrrRrwWvafw+Zlwz8F3AocHvYfAu4cy4SSpPMa6R54km1JngVOA08A/wa8UlVnhpecBHaMZ0RJ0vmMFPCq+t+qehuwE7gJeMuoB0iyL8liksWlpaV1jilJWmlN70KpqleAp4B3AFckOfvzxHcCL13gcw5W1UJVLczNzW1oWEnSr4zyLpS5JFcMj18LvAc4xnLI7xpethd4ZFxDSpJebZTfyHMNcCjJNpaD/5WqeizJ88BDSf4CeAZ4YIxzSpJWWDXgVfUt4Mbz7H+R5fvhkqQpcCWmJDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktTU9mkPoIub3//42I9x4sCesR9Dlz6/1vrxClySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpfxqhdAnxJwJqLbwCl6SmVg14kmuTPJXk+STPJblv2P/GJE8keWH4eOX4x5UknTXKFfgZ4KNVtRu4GfhQkt3AfuDJqroeeHLYliRNyKoBr6pTVfX08PjnwDFgB3AHcGh42SHgznENKUl6tTXdA08yD9wIHAGurqpTw1MvA1df4HP2JVlMsri0tLSBUSVJ5xo54EneAHwV+EhV/ezc56qqgDrf51XVwapaqKqFubm5DQ0rSfqVkQKe5DKW4/1gVT087P5hkmuG568BTo9nREnS+YzyLpQADwDHqurT5zz1KLB3eLwXeGTzx5MkXcgoC3luAe4Bvp3k2WHfJ4EDwFeS3At8D/iD8Yy4zAUOkvTrVg14Vf0TkAs8fdvmjiNJGpUrMSWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNeWvVBuBq0AlXYq8Apekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqatWAJ/liktNJvnPOvjcmeSLJC8PHK8c7piRppVGuwP8auH3Fvv3Ak1V1PfDksC1JmqBVA15V/wj8eMXuO4BDw+NDwJ2bPJckaRXrvQd+dVWdGh6/DFx9oRcm2ZdkMcni0tLSOg8nSVppw9/ErKoC6iLPH6yqhapamJub2+jhJEmD9Qb8h0muARg+nt68kSRJo1hvwB8F9g6P9wKPbM44kqRRjfI2wi8B3wBuSHIyyb3AAeA9SV4A3j1sS5ImaPtqL6iq91/gqds2eRZJ0hq4ElOSmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTW0o4EluT/LdJMeT7N+soSRJq1t3wJNsAz4P/D6wG3h/kt2bNZgk6eI2cgV+E3C8ql6sql8ADwF3bM5YkqTVpKrW94nJXcDtVfXBYfse4Her6sMrXrcP2Dds3gB8d/3jrslVwI8mdKxLzayeu+c9W2bpvH+7quZW7tw+7qNW1UHg4LiPs1KSxapamPRxLwWzeu6e92yZ1fM+10ZuobwEXHvO9s5hnyRpAjYS8G8C1yfZleRy4G7g0c0ZS5K0mnXfQqmqM0k+DPw9sA34YlU9t2mTbdzEb9tcQmb13D3v2TKr5/3/1v1NTEnSdLkSU5KaMuCS1NSWDPgsLvFPcm2Sp5I8n+S5JPdNe6ZJSrItyTNJHpv2LJOS5Iokh5P8a5JjSd4x7ZkmIcmfDl/j30nypSSvmfZM07LlAj7DS/zPAB+tqt3AzcCHZuS8z7oPODbtISbsc8DfVdVbgLcyA+efZAfwJ8BCVf0Oy2+guHu6U03Plgs4M7rEv6pOVdXTw+Ofs/wf847pTjUZSXYCe4D7pz3LpCT5TeCdwAMAVfWLqnplulNNzHbgtUm2A68D/mPK80zNVgz4DuAH52yfZEZCdlaSeeBG4Mh0J5mYzwIfA3457UEmaBewBPzVcOvo/iSvn/ZQ41ZVLwF/CXwfOAX8tKr+YbpTTc9WDPhMS/IG4KvAR6rqZ9OeZ9ySvBc4XVVHpz3LhG0H3g58oapuBP4L2PLf70lyJct/o94FvAl4fZIPTHeq6dmKAZ/ZJf5JLmM53g9W1cPTnmdCbgHel+QEy7fLbk3yN9MdaSJOAier6uzfsg6zHPSt7t3Av1fVUlX9D/Aw8HtTnmlqtmLAZ3KJf5KwfD/0WFV9etrzTEpVfaKqdlbVPMv/rr9WVVv+iqyqXgZ+kOSGYddtwPNTHGlSvg/cnOR1w9f8bczAN28vZOw/jXDSGizxH5dbgHuAbyd5dtj3yar62ynOpPH6Y+DB4ULlReCPpjzP2FXVkSSHgadZfufVM8zwknqX0ktSU1vxFookzQQDLklNGXBJasqAS1JTBlySmjLgktSUAZekpv4PSiBewRB9ujgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efI-s7pvUyau"
      },
      "source": [
        "#Visualize test data and prediction\n",
        "modelprediction = []\n",
        "for x in PredictMeX:\n",
        "    #x = torch.from_numpy(x)\n",
        "    image = torch.flatten(x, start_dim = 1)\n",
        "\n",
        "    # Turn off gradients to speed up this part\n",
        "    with torch.no_grad():\n",
        "        logps = model(image)\n",
        "\n",
        "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    modelprediction.append(pred_label)\n",
        "    \n",
        "    #plt.imshow(x.reshape(28,28))\n",
        "    #plt.title(pred_label)\n",
        "    #plt.show()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vVuP1yVUyau"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "prediction = np.asarray(modelprediction)# THAT'S YOUR JOB\n",
        "\n",
        "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
        "assert prediction.ndim == 1\n",
        "assert prediction.shape[0] == 2000\n",
        "\n",
        "# AND SAVE EXACTLY AS SHOWN BELOW\n",
        "np.save(outputFilename, prediction)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "GE7g_7lCdIak",
        "outputId": "9ad6b6de-6a93-4d9a-c784-b6e1b7f95148"
      },
      "source": [
        "#import pandas as pd\n",
        "\n",
        "#df = pd.DataFrame(data=prediction)\n",
        "\n",
        "print(\"Predictions: \", prediction.size)\n",
        "\n",
        "values, counts = np.unique(prediction, return_counts=True)\n",
        "#df = pd.DataFrame(data=counts, columns=values)\n",
        "\n",
        "plt.bar(values, counts)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions:  2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}