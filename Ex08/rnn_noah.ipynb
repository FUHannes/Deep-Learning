{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1142c020",
   "metadata": {},
   "source": [
    "## Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd38af38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) <U400\n",
      "(400,) int64\n",
      "(100,) <U1200\n",
      "(100,) int64\n",
      "(250,) <U2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('rnn-challenge-data.npz', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "    data_x = X['data_x']\n",
    "    data_y = X['data_y']\n",
    "    val_x = X['val_x']\n",
    "    val_y = X['val_y']\n",
    "    test_x = X['test_x']\n",
    "\n",
    "# TRAINING DATA: INPUT (x) AND OUTPUT (y)\n",
    "print(data_x.shape, data_x.dtype)\n",
    "print(data_y.shape, data_y.dtype)\n",
    "\n",
    "# VALIDATION DATA: INPUT (x) AND OUTPUT (y)\n",
    "print(val_x.shape, val_x.dtype)\n",
    "print(val_y.shape, val_y.dtype)\n",
    "\n",
    "# TEST DATA: INPUT (x) ONLY\n",
    "print(test_x.shape, test_x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354bea5",
   "metadata": {},
   "source": [
    "## Encode genome sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e87cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "\n",
    "def encode_genome_sequence(genome_sequence):\n",
    "    # convert string to list of chars\n",
    "    char_array =  np.array(list(genome_sequence))\n",
    "    \n",
    "    # encode characters using one-hot-encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(char_array)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    \n",
    "    # one hot encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    encoded=onehot_encoder.fit_transform(integer_encoded)\n",
    "    return encoded\n",
    "    \n",
    "encoded_x = encode_genome_sequence(data_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2fad0",
   "metadata": {},
   "source": [
    "## Custom Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b24bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomSequenceDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, transform=None, target_transform=None):\n",
    "        self.sequences = x_data\n",
    "        self.labels = y_data\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence=self.sequences[idx]\n",
    "        label=self.labels[idx]\n",
    "        if self.transform:\n",
    "            sequence = self.transform(sequence)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label,len(sequence))\n",
    "        # make y as large as x \n",
    "        return sequence, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474e7f0",
   "metadata": {},
   "source": [
    "## Create Dataloader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8278a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_dataset=CustomSequenceDataset(data_x,data_y,transform = encode_genome_sequence)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08acbde",
   "metadata": {},
   "source": [
    "## Create Dataloader for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d32c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=CustomSequenceDataset(val_x,val_y,transform = encode_genome_sequence)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, 1)\n",
    "train_testloader = torch.utils.data.DataLoader(train_dataset,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c77ec6",
   "metadata": {},
   "source": [
    "## Check Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe3f347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Layer expects the format (sequence_length,batch-size,feature_size) or (batch,sequence,feature) if param batch_first\n",
    "x,y=next(iter(trainloader))\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6119b",
   "metadata": {},
   "source": [
    "Ok, batch seems to be first, I'll set the parameter batch_first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08ce96",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e72ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size=8\n",
    "        self.n_layers=2\n",
    "        ## gets One-Hot-encoded genome element and returns the hidden values\n",
    "        self.lstm = nn.LSTM(input_size=4, hidden_size=self.hidden_size,num_layers=self.n_layers,batch_first=True)\n",
    "\n",
    "        # Classifier to make prediction from hidden layer\n",
    "        self.classify1 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.classify2 = nn.Linear(self.hidden_size, 5)\n",
    "\n",
    "    def forward(self, sequence, hidden_states):\n",
    "        lstm_out, _ = self.lstm(sequence.float(),hidden_states)\n",
    "        hidden_layer=self.classify1(lstm_out)\n",
    "        class_space = self.classify2(hidden_layer)\n",
    "        logit = F.log_softmax(class_space, dim=1)\n",
    "        return logit\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "        \"\"\" Set hidden states (h,c) to zero. Can be used for initialization \"\"\"\n",
    "        weight = next(self.parameters()).data\n",
    "        h = weight.new(self.n_layers, batch_size, self.hidden_size).zero_()\n",
    "        c= weight.new(self.n_layers, batch_size, self.hidden_size).zero_()\n",
    "        return h,c\n",
    "    \n",
    "lstm = LSTM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e881a2b",
   "metadata": {},
   "source": [
    "## Optional: Load weights from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14284636",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/batch-size1/weights-a0.47-e27.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5ee484f85324>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/batch-size1/weights-a0.47-e27.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moverall_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jojo/Desktop/Studium/Deep-Learning/Tutorium/pytorchEnv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jojo/Desktop/Studium/Deep-Learning/Tutorium/pytorchEnv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jojo/Desktop/Studium/Deep-Learning/Tutorium/pytorchEnv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/batch-size1/weights-a0.47-e27.pth'"
     ]
    }
   ],
   "source": [
    "lstm.load_state_dict(torch.load('models/batch-size1/weights-a0.47-e27.pth'))\n",
    "lstm.eval()\n",
    "overall_epochs=40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30423a59",
   "metadata": {},
   "source": [
    "## Training and Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2754281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "def decode_label(encoded_label):\n",
    "    return argmax(encoded_label)\n",
    "\n",
    "def decode_labels(encoded_labels):\n",
    "    return argmax(encoded_labels,axis=1)\n",
    "\n",
    "# Geht nur mit Batch-Size=1\n",
    "def get_accuracy(dataloader,batch_size=1):\n",
    "    predictions=[]\n",
    "    correct_or_wrong=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequence,label in dataloader:\n",
    "            hidden_states=lstm.init_hidden(batch_size)\n",
    "            pred_label = lstm(sequence,hidden_states)\n",
    "            last_label = pred_label[0][len(pred_label[0])-1]\n",
    "            prediction= decode_label(last_label)\n",
    "            predictions.append(prediction)\n",
    "            correct_or_wrong.append(prediction == label)\n",
    "    return sum(correct_or_wrong)/len(correct_or_wrong)\n",
    "\n",
    "# Geht nur mit Batch-Size=1\n",
    "def get_accuracy(dataloader,batch_size=1):\n",
    "    predictions=[]\n",
    "    correct_or_wrong=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequence,label in dataloader:\n",
    "            hidden_states=lstm.init_hidden(batch_size)\n",
    "            pred_label = lstm(sequence,hidden_states)\n",
    "            last_label = pred_label[0][len(pred_label[0])-1]\n",
    "            prediction= decode_label(last_label)\n",
    "            predictions.append(prediction)\n",
    "            correct_or_wrong.append(prediction == label)\n",
    "    return sum(correct_or_wrong)/len(correct_or_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f984f66d",
   "metadata": {},
   "source": [
    "## Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74b60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    return(get_accuracy(testloader).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fba7e7",
   "metadata": {},
   "source": [
    "## Define Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec52d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.NLLLoss() # Negative Log Likelihood because classification\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e155fa",
   "metadata": {},
   "source": [
    "# Save hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c9f8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder\n",
    "import os \n",
    "from datetime import datetime\n",
    "folder_path = \"models/\"+datetime.now().isoformat()+'/'\n",
    "os.mkdir(folder_path)\n",
    "\n",
    "# dump hyperparameters as json\n",
    "#import json \n",
    "#with open(folder_path+'parameters.json','w') as file:\n",
    "#    json.dump({batch_size,class(loss_fn)},file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95677087",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13c7de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_epochs=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f84bc901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0, iterations:     5] loss: 5.991\n",
      "[epoch 0, iterations:    10] loss: 5.992\n",
      "[epoch 0, iterations:    15] loss: 5.992\n",
      "[epoch 0, iterations:    20] loss: 5.992\n",
      "[epoch 0, iterations:    25] loss: 5.992\n",
      "[epoch 0, iterations:    30] loss: 5.991\n",
      "[epoch 0, iterations:    35] loss: 5.992\n",
      "[epoch 0, iterations:    40] loss: 5.992\n",
      "[epoch 0, iterations:    45] loss: 5.991\n",
      "[epoch 0, iterations:    50] loss: 5.992\n",
      "[epoch 0, iterations:    55] loss: 5.991\n",
      "[epoch 0, iterations:    60] loss: 5.991\n",
      "[epoch 0, iterations:    65] loss: 5.991\n",
      "[epoch 0, iterations:    70] loss: 5.991\n",
      "[epoch 0, iterations:    75] loss: 5.991\n",
      "[epoch 0, iterations:    80] loss: 5.991\n",
      "[epoch 0, iterations:    85] loss: 5.991\n",
      "[epoch 0, iterations:    90] loss: 5.992\n",
      "[epoch 0, iterations:    95] loss: 5.991\n",
      "[epoch 0, iterations:   100] loss: 5.991\n",
      "[epoch 0, iterations:   105] loss: 5.990\n",
      "[epoch 0, iterations:   110] loss: 5.991\n",
      "[epoch 0, iterations:   115] loss: 5.991\n",
      "[epoch 0, iterations:   120] loss: 5.991\n",
      "[epoch 0, iterations:   125] loss: 5.991\n",
      "[epoch 0, iterations:   130] loss: 5.991\n",
      "[epoch 0, iterations:   135] loss: 5.991\n",
      "[epoch 0, iterations:   140] loss: 5.990\n",
      "[epoch 0, iterations:   145] loss: 5.990\n",
      "[epoch 0, iterations:   150] loss: 5.990\n",
      "[epoch 0, iterations:   155] loss: 5.991\n",
      "[epoch 0, iterations:   160] loss: 5.991\n",
      "[epoch 0, iterations:   165] loss: 5.990\n",
      "[epoch 0, iterations:   170] loss: 5.990\n",
      "[epoch 0, iterations:   175] loss: 5.991\n",
      "[epoch 0, iterations:   180] loss: 5.990\n",
      "[epoch 0, iterations:   185] loss: 5.991\n",
      "[epoch 0, iterations:   190] loss: 5.990\n",
      "[epoch 0, iterations:   195] loss: 5.989\n",
      "[epoch 0, iterations:   200] loss: 5.991\n",
      "[epoch 0, iterations:   205] loss: 5.990\n",
      "[epoch 0, iterations:   210] loss: 5.991\n",
      "[epoch 0, iterations:   215] loss: 5.990\n",
      "[epoch 0, iterations:   220] loss: 5.989\n",
      "[epoch 0, iterations:   225] loss: 5.990\n",
      "[epoch 0, iterations:   230] loss: 5.989\n",
      "[epoch 0, iterations:   235] loss: 5.988\n",
      "[epoch 0, iterations:   240] loss: 5.991\n",
      "[epoch 0, iterations:   245] loss: 5.988\n",
      "[epoch 0, iterations:   250] loss: 5.989\n",
      "[epoch 0, iterations:   255] loss: 5.991\n",
      "[epoch 0, iterations:   260] loss: 5.989\n",
      "[epoch 0, iterations:   265] loss: 5.990\n",
      "[epoch 0, iterations:   270] loss: 5.990\n",
      "[epoch 0, iterations:   275] loss: 5.989\n",
      "[epoch 0, iterations:   280] loss: 5.987\n",
      "[epoch 0, iterations:   285] loss: 5.988\n",
      "[epoch 0, iterations:   290] loss: 5.987\n",
      "[epoch 0, iterations:   295] loss: 5.988\n",
      "[epoch 0, iterations:   300] loss: 5.992\n",
      "[epoch 0, iterations:   305] loss: 5.989\n",
      "[epoch 0, iterations:   310] loss: 5.989\n",
      "[epoch 0, iterations:   315] loss: 5.991\n",
      "[epoch 0, iterations:   320] loss: 5.987\n",
      "[epoch 0, iterations:   325] loss: 5.985\n",
      "[epoch 0, iterations:   330] loss: 5.985\n",
      "[epoch 0, iterations:   335] loss: 5.988\n",
      "[epoch 0, iterations:   340] loss: 5.989\n",
      "[epoch 0, iterations:   345] loss: 5.988\n",
      "[epoch 0, iterations:   350] loss: 5.985\n",
      "[epoch 0, iterations:   355] loss: 5.988\n",
      "[epoch 0, iterations:   360] loss: 5.986\n",
      "[epoch 0, iterations:   365] loss: 5.987\n",
      "[epoch 0, iterations:   370] loss: 5.984\n",
      "[epoch 0, iterations:   375] loss: 5.982\n",
      "[epoch 0, iterations:   380] loss: 5.982\n",
      "[epoch 0, iterations:   385] loss: 5.987\n",
      "[epoch 0, iterations:   390] loss: 5.983\n",
      "[epoch 0, iterations:   395] loss: 5.984\n",
      "[epoch 0, iterations:   400] loss: 5.984\n",
      "[epoch 1, iterations:     5] loss: 5.963\n",
      "[epoch 1, iterations:    10] loss: 5.987\n",
      "[epoch 1, iterations:    15] loss: 5.985\n",
      "[epoch 1, iterations:    20] loss: 5.985\n",
      "[epoch 1, iterations:    25] loss: 5.947\n",
      "[epoch 1, iterations:    30] loss: 5.974\n",
      "[epoch 1, iterations:    35] loss: 5.974\n",
      "[epoch 1, iterations:    40] loss: 5.975\n",
      "[epoch 1, iterations:    45] loss: 5.967\n",
      "[epoch 1, iterations:    50] loss: 5.969\n",
      "[epoch 1, iterations:    55] loss: 5.973\n",
      "[epoch 1, iterations:    60] loss: 5.969\n",
      "[epoch 1, iterations:    65] loss: 5.978\n",
      "[epoch 1, iterations:    70] loss: 5.965\n",
      "[epoch 1, iterations:    75] loss: 5.961\n",
      "[epoch 1, iterations:    80] loss: 5.966\n",
      "[epoch 1, iterations:    85] loss: 5.976\n",
      "[epoch 1, iterations:    90] loss: 5.960\n",
      "[epoch 1, iterations:    95] loss: 5.968\n",
      "[epoch 1, iterations:   100] loss: 5.957\n",
      "[epoch 1, iterations:   105] loss: 5.955\n",
      "[epoch 1, iterations:   110] loss: 5.960\n",
      "[epoch 1, iterations:   115] loss: 5.962\n",
      "[epoch 1, iterations:   120] loss: 5.963\n",
      "[epoch 1, iterations:   125] loss: 5.965\n",
      "[epoch 1, iterations:   130] loss: 5.953\n",
      "[epoch 1, iterations:   135] loss: 5.950\n",
      "[epoch 1, iterations:   140] loss: 5.953\n",
      "[epoch 1, iterations:   145] loss: 5.956\n",
      "[epoch 1, iterations:   150] loss: 5.964\n",
      "[epoch 1, iterations:   155] loss: 5.943\n",
      "[epoch 1, iterations:   160] loss: 5.944\n",
      "[epoch 1, iterations:   165] loss: 5.949\n",
      "[epoch 1, iterations:   170] loss: 5.945\n",
      "[epoch 1, iterations:   175] loss: 5.944\n",
      "[epoch 1, iterations:   180] loss: 5.932\n",
      "[epoch 1, iterations:   185] loss: 5.931\n",
      "[epoch 1, iterations:   190] loss: 5.929\n",
      "[epoch 1, iterations:   195] loss: 5.931\n",
      "[epoch 1, iterations:   200] loss: 5.904\n",
      "[epoch 1, iterations:   205] loss: 5.802\n",
      "[epoch 1, iterations:   210] loss: 5.892\n",
      "[epoch 1, iterations:   215] loss: 5.923\n",
      "[epoch 1, iterations:   220] loss: 5.927\n",
      "[epoch 1, iterations:   225] loss: 5.923\n",
      "[epoch 1, iterations:   230] loss: 5.946\n",
      "[epoch 1, iterations:   235] loss: 5.950\n",
      "[epoch 1, iterations:   240] loss: 5.947\n",
      "[epoch 1, iterations:   245] loss: 5.943\n",
      "[epoch 1, iterations:   250] loss: 5.942\n",
      "[epoch 1, iterations:   255] loss: 5.953\n",
      "[epoch 1, iterations:   260] loss: 5.947\n",
      "[epoch 1, iterations:   265] loss: 5.926\n",
      "[epoch 1, iterations:   270] loss: 5.938\n",
      "[epoch 1, iterations:   275] loss: 5.949\n",
      "[epoch 1, iterations:   280] loss: 5.949\n",
      "[epoch 1, iterations:   285] loss: 5.948\n",
      "[epoch 1, iterations:   290] loss: 5.937\n",
      "[epoch 1, iterations:   295] loss: 5.940\n",
      "[epoch 1, iterations:   300] loss: 5.937\n",
      "[epoch 1, iterations:   305] loss: 5.924\n",
      "[epoch 1, iterations:   310] loss: 5.933\n",
      "[epoch 1, iterations:   315] loss: 5.959\n",
      "[epoch 1, iterations:   320] loss: 5.935\n",
      "[epoch 1, iterations:   325] loss: 5.941\n",
      "[epoch 1, iterations:   330] loss: 5.944\n",
      "[epoch 1, iterations:   335] loss: 5.924\n",
      "[epoch 1, iterations:   340] loss: 5.937\n",
      "[epoch 1, iterations:   345] loss: 5.929\n",
      "[epoch 1, iterations:   350] loss: 5.931\n",
      "[epoch 1, iterations:   355] loss: 5.947\n",
      "[epoch 1, iterations:   360] loss: 5.908\n",
      "[epoch 1, iterations:   365] loss: 5.900\n",
      "[epoch 1, iterations:   370] loss: 5.949\n",
      "[epoch 1, iterations:   375] loss: 5.925\n",
      "[epoch 1, iterations:   380] loss: 5.931\n",
      "[epoch 1, iterations:   385] loss: 5.925\n",
      "[epoch 1, iterations:   390] loss: 5.923\n",
      "[epoch 1, iterations:   395] loss: 5.951\n",
      "[epoch 1, iterations:   400] loss: 5.905\n",
      "[epoch 2, iterations:     5] loss: 5.930\n",
      "[epoch 2, iterations:    10] loss: 5.907\n",
      "[epoch 2, iterations:    15] loss: 5.938\n",
      "[epoch 2, iterations:    20] loss: 5.945\n",
      "[epoch 2, iterations:    25] loss: 5.929\n",
      "[epoch 2, iterations:    30] loss: 5.921\n",
      "[epoch 2, iterations:    35] loss: 5.893\n",
      "[epoch 2, iterations:    40] loss: 5.939\n",
      "[epoch 2, iterations:    45] loss: 5.891\n",
      "[epoch 2, iterations:    50] loss: 5.909\n",
      "[epoch 2, iterations:    55] loss: 5.908\n",
      "[epoch 2, iterations:    60] loss: 5.894\n",
      "[epoch 2, iterations:    65] loss: 5.923\n",
      "[epoch 2, iterations:    70] loss: 5.892\n",
      "[epoch 2, iterations:    75] loss: 5.884\n",
      "[epoch 2, iterations:    80] loss: 5.921\n",
      "[epoch 2, iterations:    85] loss: 5.936\n",
      "[epoch 2, iterations:    90] loss: 5.906\n",
      "[epoch 2, iterations:    95] loss: 5.899\n",
      "[epoch 2, iterations:   100] loss: 5.900\n",
      "[epoch 2, iterations:   105] loss: 5.888\n",
      "[epoch 2, iterations:   110] loss: 5.897\n",
      "[epoch 2, iterations:   115] loss: 5.882\n",
      "[epoch 2, iterations:   120] loss: 5.904\n",
      "[epoch 2, iterations:   125] loss: 5.864\n",
      "[epoch 2, iterations:   130] loss: 5.883\n",
      "[epoch 2, iterations:   135] loss: 5.893\n",
      "[epoch 2, iterations:   140] loss: 5.863\n",
      "[epoch 2, iterations:   145] loss: 5.889\n",
      "[epoch 2, iterations:   150] loss: 5.884\n",
      "[epoch 2, iterations:   155] loss: 5.850\n",
      "[epoch 2, iterations:   160] loss: 5.843\n",
      "[epoch 2, iterations:   165] loss: 5.884\n",
      "[epoch 2, iterations:   170] loss: 5.904\n",
      "[epoch 2, iterations:   175] loss: 5.863\n",
      "[epoch 2, iterations:   180] loss: 5.866\n",
      "[epoch 2, iterations:   185] loss: 5.831\n",
      "[epoch 2, iterations:   190] loss: 5.811\n",
      "[epoch 2, iterations:   195] loss: 5.768\n",
      "[epoch 2, iterations:   200] loss: 5.738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2, iterations:   205] loss: 5.541\n",
      "[epoch 2, iterations:   210] loss: 5.637\n",
      "[epoch 2, iterations:   215] loss: 5.795\n",
      "[epoch 2, iterations:   220] loss: 5.958\n",
      "[epoch 2, iterations:   225] loss: 5.931\n",
      "[epoch 2, iterations:   230] loss: 5.941\n",
      "[epoch 2, iterations:   235] loss: 5.960\n",
      "[epoch 2, iterations:   240] loss: 5.950\n",
      "[epoch 2, iterations:   245] loss: 5.927\n",
      "[epoch 2, iterations:   250] loss: 5.922\n",
      "[epoch 2, iterations:   255] loss: 5.975\n",
      "[epoch 2, iterations:   260] loss: 5.960\n",
      "[epoch 2, iterations:   265] loss: 5.936\n",
      "[epoch 2, iterations:   270] loss: 5.995\n",
      "[epoch 2, iterations:   275] loss: 5.971\n",
      "[epoch 2, iterations:   280] loss: 5.951\n",
      "[epoch 2, iterations:   285] loss: 5.975\n",
      "[epoch 2, iterations:   290] loss: 5.966\n",
      "[epoch 2, iterations:   295] loss: 5.941\n",
      "[epoch 2, iterations:   300] loss: 5.930\n",
      "[epoch 2, iterations:   305] loss: 5.921\n",
      "[epoch 2, iterations:   310] loss: 5.942\n",
      "[epoch 2, iterations:   315] loss: 5.970\n",
      "[epoch 2, iterations:   320] loss: 5.954\n",
      "[epoch 2, iterations:   325] loss: 5.968\n",
      "[epoch 2, iterations:   330] loss: 5.939\n",
      "[epoch 2, iterations:   335] loss: 5.947\n",
      "[epoch 2, iterations:   340] loss: 5.906\n",
      "[epoch 2, iterations:   345] loss: 5.946\n",
      "[epoch 2, iterations:   350] loss: 5.940\n",
      "[epoch 2, iterations:   355] loss: 5.985\n",
      "[epoch 2, iterations:   360] loss: 5.917\n",
      "[epoch 2, iterations:   365] loss: 5.948\n",
      "[epoch 2, iterations:   370] loss: 5.979\n",
      "[epoch 2, iterations:   375] loss: 5.971\n",
      "[epoch 2, iterations:   380] loss: 5.921\n",
      "[epoch 2, iterations:   385] loss: 5.971\n",
      "[epoch 2, iterations:   390] loss: 5.925\n",
      "[epoch 2, iterations:   395] loss: 5.986\n",
      "[epoch 2, iterations:   400] loss: 5.933\n",
      "[epoch 3, iterations:     5] loss: 5.983\n",
      "[epoch 3, iterations:    10] loss: 5.950\n",
      "[epoch 3, iterations:    15] loss: 5.971\n",
      "[epoch 3, iterations:    20] loss: 5.943\n",
      "[epoch 3, iterations:    25] loss: 5.941\n",
      "[epoch 3, iterations:    30] loss: 5.892\n",
      "[epoch 3, iterations:    35] loss: 5.918\n",
      "[epoch 3, iterations:    40] loss: 5.962\n",
      "[epoch 3, iterations:    45] loss: 5.927\n",
      "[epoch 3, iterations:    50] loss: 5.919\n",
      "[epoch 3, iterations:    55] loss: 5.955\n",
      "[epoch 3, iterations:    60] loss: 5.933\n",
      "[epoch 3, iterations:    65] loss: 5.904\n",
      "[epoch 3, iterations:    70] loss: 5.996\n",
      "[epoch 3, iterations:    75] loss: 5.905\n",
      "[epoch 3, iterations:    80] loss: 5.908\n",
      "[epoch 3, iterations:    85] loss: 5.893\n",
      "[epoch 3, iterations:    90] loss: 5.956\n",
      "[epoch 3, iterations:    95] loss: 5.933\n",
      "[epoch 3, iterations:   100] loss: 5.852\n",
      "[epoch 3, iterations:   105] loss: 5.938\n",
      "[epoch 3, iterations:   110] loss: 5.895\n",
      "[epoch 3, iterations:   115] loss: 5.583\n",
      "[epoch 3, iterations:   120] loss: 5.534\n",
      "[epoch 3, iterations:   125] loss: 5.942\n",
      "[epoch 3, iterations:   130] loss: 5.936\n",
      "[epoch 3, iterations:   135] loss: 5.914\n",
      "[epoch 3, iterations:   140] loss: 5.902\n",
      "[epoch 3, iterations:   145] loss: 5.926\n",
      "[epoch 3, iterations:   150] loss: 5.968\n",
      "[epoch 3, iterations:   155] loss: 5.896\n",
      "[epoch 3, iterations:   160] loss: 5.919\n",
      "[epoch 3, iterations:   165] loss: 5.922\n",
      "[epoch 3, iterations:   170] loss: 5.936\n",
      "[epoch 3, iterations:   175] loss: 5.950\n",
      "[epoch 3, iterations:   180] loss: 5.889\n",
      "[epoch 3, iterations:   185] loss: 5.952\n",
      "[epoch 3, iterations:   190] loss: 5.954\n",
      "[epoch 3, iterations:   195] loss: 5.970\n",
      "[epoch 3, iterations:   200] loss: 5.921\n",
      "[epoch 3, iterations:   205] loss: 5.899\n",
      "[epoch 3, iterations:   210] loss: 5.953\n",
      "[epoch 3, iterations:   215] loss: 5.936\n",
      "[epoch 3, iterations:   220] loss: 5.911\n",
      "[epoch 3, iterations:   225] loss: 5.975\n",
      "[epoch 3, iterations:   230] loss: 5.924\n",
      "[epoch 3, iterations:   235] loss: 5.916\n",
      "[epoch 3, iterations:   240] loss: 5.954\n",
      "[epoch 3, iterations:   245] loss: 5.948\n",
      "[epoch 3, iterations:   250] loss: 5.906\n",
      "[epoch 3, iterations:   255] loss: 5.980\n",
      "[epoch 3, iterations:   260] loss: 5.947\n",
      "[epoch 3, iterations:   265] loss: 5.944\n",
      "[epoch 3, iterations:   270] loss: 5.934\n",
      "[epoch 3, iterations:   275] loss: 5.999\n",
      "[epoch 3, iterations:   280] loss: 5.911\n",
      "[epoch 3, iterations:   285] loss: 5.943\n",
      "[epoch 3, iterations:   290] loss: 5.941\n",
      "[epoch 3, iterations:   295] loss: 5.922\n",
      "[epoch 3, iterations:   300] loss: 5.956\n",
      "[epoch 3, iterations:   305] loss: 5.943\n",
      "[epoch 3, iterations:   310] loss: 5.908\n",
      "[epoch 3, iterations:   315] loss: 5.921\n",
      "[epoch 3, iterations:   320] loss: 5.944\n",
      "[epoch 3, iterations:   325] loss: 5.903\n",
      "[epoch 3, iterations:   330] loss: 5.888\n",
      "[epoch 3, iterations:   335] loss: 5.913\n",
      "[epoch 3, iterations:   340] loss: 5.843\n",
      "[epoch 3, iterations:   345] loss: 5.946\n",
      "[epoch 3, iterations:   350] loss: 5.974\n",
      "[epoch 3, iterations:   355] loss: 5.903\n",
      "[epoch 3, iterations:   360] loss: 5.897\n",
      "[epoch 3, iterations:   365] loss: 5.832\n",
      "[epoch 3, iterations:   370] loss: 5.991\n",
      "[epoch 3, iterations:   375] loss: 5.919\n",
      "[epoch 3, iterations:   380] loss: 5.863\n",
      "[epoch 3, iterations:   385] loss: 5.958\n",
      "[epoch 3, iterations:   390] loss: 5.999\n",
      "[epoch 3, iterations:   395] loss: 5.942\n",
      "[epoch 3, iterations:   400] loss: 6.044\n",
      "[epoch 4, iterations:     5] loss: 5.958\n",
      "[epoch 4, iterations:    10] loss: 5.894\n",
      "[epoch 4, iterations:    15] loss: 5.889\n",
      "[epoch 4, iterations:    20] loss: 5.854\n",
      "[epoch 4, iterations:    25] loss: 5.932\n",
      "[epoch 4, iterations:    30] loss: 5.907\n",
      "[epoch 4, iterations:    35] loss: 5.861\n",
      "[epoch 4, iterations:    40] loss: 5.940\n",
      "[epoch 4, iterations:    45] loss: 5.911\n",
      "[epoch 4, iterations:    50] loss: 5.982\n",
      "[epoch 4, iterations:    55] loss: 5.898\n",
      "[epoch 4, iterations:    60] loss: 5.968\n",
      "[epoch 4, iterations:    65] loss: 5.801\n",
      "[epoch 4, iterations:    70] loss: 5.915\n",
      "[epoch 4, iterations:    75] loss: 5.895\n",
      "[epoch 4, iterations:    80] loss: 5.926\n",
      "[epoch 4, iterations:    85] loss: 5.991\n",
      "[epoch 4, iterations:    90] loss: 5.945\n",
      "[epoch 4, iterations:    95] loss: 6.049\n",
      "[epoch 4, iterations:   100] loss: 5.930\n",
      "[epoch 4, iterations:   105] loss: 5.876\n",
      "[epoch 4, iterations:   110] loss: 5.903\n",
      "[epoch 4, iterations:   115] loss: 5.888\n",
      "[epoch 4, iterations:   120] loss: 5.924\n",
      "[epoch 4, iterations:   125] loss: 5.917\n",
      "[epoch 4, iterations:   130] loss: 5.936\n",
      "[epoch 4, iterations:   135] loss: 5.945\n",
      "[epoch 4, iterations:   140] loss: 5.826\n",
      "[epoch 4, iterations:   145] loss: 5.802\n",
      "[epoch 4, iterations:   150] loss: 5.825\n",
      "[epoch 4, iterations:   155] loss: 5.911\n",
      "[epoch 4, iterations:   160] loss: 5.866\n",
      "[epoch 4, iterations:   165] loss: 5.969\n",
      "[epoch 4, iterations:   170] loss: 6.011\n",
      "[epoch 4, iterations:   175] loss: 6.019\n",
      "[epoch 4, iterations:   180] loss: 5.918\n",
      "[epoch 4, iterations:   185] loss: 5.868\n",
      "[epoch 4, iterations:   190] loss: 5.899\n",
      "[epoch 4, iterations:   195] loss: 5.828\n",
      "[epoch 4, iterations:   200] loss: 5.851\n",
      "[epoch 4, iterations:   205] loss: 5.851\n",
      "[epoch 4, iterations:   210] loss: 5.857\n",
      "[epoch 4, iterations:   215] loss: 5.959\n",
      "[epoch 4, iterations:   220] loss: 5.824\n",
      "[epoch 4, iterations:   225] loss: 5.957\n",
      "[epoch 4, iterations:   230] loss: 5.900\n",
      "[epoch 4, iterations:   235] loss: 5.884\n",
      "[epoch 4, iterations:   240] loss: 5.946\n",
      "[epoch 4, iterations:   245] loss: 5.900\n",
      "[epoch 4, iterations:   250] loss: 5.894\n",
      "[epoch 4, iterations:   255] loss: 5.893\n",
      "[epoch 4, iterations:   260] loss: 5.740\n",
      "[epoch 4, iterations:   265] loss: 5.772\n",
      "[epoch 4, iterations:   270] loss: 5.897\n",
      "[epoch 4, iterations:   275] loss: 5.882\n",
      "[epoch 4, iterations:   280] loss: 5.880\n",
      "[epoch 4, iterations:   285] loss: 6.030\n",
      "[epoch 4, iterations:   290] loss: 5.942\n",
      "[epoch 4, iterations:   295] loss: 5.848\n",
      "[epoch 4, iterations:   300] loss: 5.854\n",
      "[epoch 4, iterations:   305] loss: 5.859\n",
      "[epoch 4, iterations:   310] loss: 5.899\n",
      "[epoch 4, iterations:   315] loss: 5.946\n",
      "[epoch 4, iterations:   320] loss: 5.866\n",
      "[epoch 4, iterations:   325] loss: 5.896\n",
      "[epoch 4, iterations:   330] loss: 6.004\n",
      "[epoch 4, iterations:   335] loss: 6.012\n",
      "[epoch 4, iterations:   340] loss: 5.872\n",
      "[epoch 4, iterations:   345] loss: 5.843\n",
      "[epoch 4, iterations:   350] loss: 5.772\n",
      "[epoch 4, iterations:   355] loss: 5.861\n",
      "[epoch 4, iterations:   360] loss: 5.865\n",
      "[epoch 4, iterations:   365] loss: 5.911\n",
      "[epoch 4, iterations:   370] loss: 6.007\n",
      "[epoch 4, iterations:   375] loss: 5.913\n",
      "[epoch 4, iterations:   380] loss: 5.764\n",
      "[epoch 4, iterations:   385] loss: 5.958\n",
      "[epoch 4, iterations:   390] loss: 5.827\n",
      "[epoch 4, iterations:   395] loss: 5.944\n",
      "[epoch 4, iterations:   400] loss: 5.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5, iterations:     5] loss: 5.868\n",
      "[epoch 5, iterations:    10] loss: 5.821\n",
      "[epoch 5, iterations:    15] loss: 5.824\n",
      "[epoch 5, iterations:    20] loss: 5.863\n",
      "[epoch 5, iterations:    25] loss: 5.902\n",
      "[epoch 5, iterations:    30] loss: 5.786\n",
      "[epoch 5, iterations:    35] loss: 5.983\n",
      "[epoch 5, iterations:    40] loss: 5.793\n",
      "[epoch 5, iterations:    45] loss: 5.862\n",
      "[epoch 5, iterations:    50] loss: 5.823\n",
      "[epoch 5, iterations:    55] loss: 5.864\n",
      "[epoch 5, iterations:    60] loss: 5.731\n",
      "[epoch 5, iterations:    65] loss: 5.793\n",
      "[epoch 5, iterations:    70] loss: 5.917\n",
      "[epoch 5, iterations:    75] loss: 6.034\n",
      "[epoch 5, iterations:    80] loss: 5.790\n",
      "[epoch 5, iterations:    85] loss: 5.887\n",
      "[epoch 5, iterations:    90] loss: 5.772\n",
      "[epoch 5, iterations:    95] loss: 5.935\n",
      "[epoch 5, iterations:   100] loss: 5.883\n",
      "[epoch 5, iterations:   105] loss: 5.936\n",
      "[epoch 5, iterations:   110] loss: 5.744\n",
      "[epoch 5, iterations:   115] loss: 5.962\n",
      "[epoch 5, iterations:   120] loss: 5.915\n",
      "[epoch 5, iterations:   125] loss: 5.830\n",
      "[epoch 5, iterations:   130] loss: 5.786\n",
      "[epoch 5, iterations:   135] loss: 5.883\n",
      "[epoch 5, iterations:   140] loss: 5.769\n",
      "[epoch 5, iterations:   145] loss: 5.977\n",
      "[epoch 5, iterations:   150] loss: 5.960\n",
      "[epoch 5, iterations:   155] loss: 5.963\n",
      "[epoch 5, iterations:   160] loss: 5.854\n",
      "[epoch 5, iterations:   165] loss: 5.746\n",
      "[epoch 5, iterations:   170] loss: 5.688\n",
      "[epoch 5, iterations:   175] loss: 5.684\n",
      "[epoch 5, iterations:   180] loss: 5.555\n",
      "[epoch 5, iterations:   185] loss: 5.578\n",
      "[epoch 5, iterations:   190] loss: 5.472\n",
      "[epoch 5, iterations:   195] loss: 5.730\n",
      "[epoch 5, iterations:   200] loss: 5.910\n",
      "[epoch 5, iterations:   205] loss: 5.717\n",
      "[epoch 5, iterations:   210] loss: 5.642\n",
      "[epoch 5, iterations:   215] loss: 5.607\n",
      "[epoch 5, iterations:   220] loss: 5.381\n",
      "[epoch 5, iterations:   225] loss: 5.656\n",
      "[epoch 5, iterations:   230] loss: 5.634\n",
      "[epoch 5, iterations:   235] loss: 6.026\n",
      "[epoch 5, iterations:   240] loss: 5.797\n",
      "[epoch 5, iterations:   245] loss: 5.796\n",
      "[epoch 5, iterations:   250] loss: 5.714\n",
      "[epoch 5, iterations:   255] loss: 5.749\n",
      "[epoch 5, iterations:   260] loss: 5.783\n",
      "[epoch 5, iterations:   265] loss: 5.957\n",
      "[epoch 5, iterations:   270] loss: 5.954\n",
      "[epoch 5, iterations:   275] loss: 5.836\n",
      "[epoch 5, iterations:   280] loss: 5.845\n",
      "[epoch 5, iterations:   285] loss: 5.898\n",
      "[epoch 5, iterations:   290] loss: 5.808\n",
      "[epoch 5, iterations:   295] loss: 5.812\n",
      "[epoch 5, iterations:   300] loss: 5.795\n",
      "[epoch 5, iterations:   305] loss: 5.805\n",
      "[epoch 5, iterations:   310] loss: 5.783\n",
      "[epoch 5, iterations:   315] loss: 5.937\n",
      "[epoch 5, iterations:   320] loss: 5.782\n",
      "[epoch 5, iterations:   325] loss: 5.677\n",
      "[epoch 5, iterations:   330] loss: 5.949\n",
      "[epoch 5, iterations:   335] loss: 5.697\n",
      "[epoch 5, iterations:   340] loss: 5.701\n",
      "[epoch 5, iterations:   345] loss: 5.871\n",
      "[epoch 5, iterations:   350] loss: 5.619\n",
      "[epoch 5, iterations:   355] loss: 5.821\n",
      "[epoch 5, iterations:   360] loss: 5.858\n",
      "[epoch 5, iterations:   365] loss: 5.719\n",
      "[epoch 5, iterations:   370] loss: 5.881\n",
      "[epoch 5, iterations:   375] loss: 5.760\n",
      "[epoch 5, iterations:   380] loss: 5.876\n",
      "[epoch 5, iterations:   385] loss: 5.853\n",
      "[epoch 5, iterations:   390] loss: 5.841\n",
      "[epoch 5, iterations:   395] loss: 6.001\n",
      "[epoch 5, iterations:   400] loss: 5.792\n",
      "[epoch 6, iterations:     5] loss: 5.723\n",
      "[epoch 6, iterations:    10] loss: 5.761\n",
      "[epoch 6, iterations:    15] loss: 5.673\n",
      "[epoch 6, iterations:    20] loss: 5.773\n",
      "[epoch 6, iterations:    25] loss: 5.731\n",
      "[epoch 6, iterations:    30] loss: 5.980\n",
      "[epoch 6, iterations:    35] loss: 5.857\n",
      "[epoch 6, iterations:    40] loss: 5.696\n",
      "[epoch 6, iterations:    45] loss: 5.762\n",
      "[epoch 6, iterations:    50] loss: 5.859\n",
      "[epoch 6, iterations:    55] loss: 5.776\n",
      "[epoch 6, iterations:    60] loss: 5.808\n",
      "[epoch 6, iterations:    65] loss: 5.979\n",
      "[epoch 6, iterations:    70] loss: 5.833\n",
      "[epoch 6, iterations:    75] loss: 5.798\n",
      "[epoch 6, iterations:    80] loss: 5.763\n",
      "[epoch 6, iterations:    85] loss: 5.766\n",
      "[epoch 6, iterations:    90] loss: 5.935\n",
      "[epoch 6, iterations:    95] loss: 5.781\n",
      "[epoch 6, iterations:   100] loss: 5.687\n",
      "[epoch 6, iterations:   105] loss: 5.942\n",
      "[epoch 6, iterations:   110] loss: 5.861\n",
      "[epoch 6, iterations:   115] loss: 5.832\n",
      "[epoch 6, iterations:   120] loss: 5.909\n",
      "[epoch 6, iterations:   125] loss: 5.853\n",
      "[epoch 6, iterations:   130] loss: 5.659\n",
      "[epoch 6, iterations:   135] loss: 5.831\n",
      "[epoch 6, iterations:   140] loss: 5.874\n",
      "[epoch 6, iterations:   145] loss: 5.822\n",
      "[epoch 6, iterations:   150] loss: 5.833\n",
      "[epoch 6, iterations:   155] loss: 5.786\n",
      "[epoch 6, iterations:   160] loss: 5.671\n",
      "[epoch 6, iterations:   165] loss: 5.809\n",
      "[epoch 6, iterations:   170] loss: 5.706\n",
      "[epoch 6, iterations:   175] loss: 5.622\n",
      "[epoch 6, iterations:   180] loss: 5.637\n",
      "[epoch 6, iterations:   185] loss: 5.727\n",
      "[epoch 6, iterations:   190] loss: 5.559\n",
      "[epoch 6, iterations:   195] loss: 5.866\n",
      "[epoch 6, iterations:   200] loss: 5.775\n",
      "[epoch 6, iterations:   205] loss: 5.574\n",
      "[epoch 6, iterations:   210] loss: 5.783\n",
      "[epoch 6, iterations:   215] loss: 5.719\n",
      "[epoch 6, iterations:   220] loss: 5.738\n",
      "[epoch 6, iterations:   225] loss: 5.712\n",
      "[epoch 6, iterations:   230] loss: 5.723\n",
      "[epoch 6, iterations:   235] loss: 5.788\n",
      "[epoch 6, iterations:   240] loss: 5.798\n",
      "[epoch 6, iterations:   245] loss: 5.842\n",
      "[epoch 6, iterations:   250] loss: 5.908\n",
      "[epoch 6, iterations:   255] loss: 5.742\n",
      "[epoch 6, iterations:   260] loss: 5.749\n",
      "[epoch 6, iterations:   265] loss: 5.772\n",
      "[epoch 6, iterations:   270] loss: 5.802\n",
      "[epoch 6, iterations:   275] loss: 5.758\n",
      "[epoch 6, iterations:   280] loss: 5.837\n",
      "[epoch 6, iterations:   285] loss: 5.986\n",
      "[epoch 6, iterations:   290] loss: 5.845\n",
      "[epoch 6, iterations:   295] loss: 5.803\n",
      "[epoch 6, iterations:   300] loss: 5.790\n",
      "[epoch 6, iterations:   305] loss: 5.546\n",
      "[epoch 6, iterations:   310] loss: 5.713\n",
      "[epoch 6, iterations:   315] loss: 5.760\n",
      "[epoch 6, iterations:   320] loss: 5.910\n",
      "[epoch 6, iterations:   325] loss: 5.802\n",
      "[epoch 6, iterations:   330] loss: 5.856\n",
      "[epoch 6, iterations:   335] loss: 5.702\n",
      "[epoch 6, iterations:   340] loss: 5.800\n",
      "[epoch 6, iterations:   345] loss: 5.900\n",
      "[epoch 6, iterations:   350] loss: 5.841\n",
      "[epoch 6, iterations:   355] loss: 5.695\n",
      "[epoch 6, iterations:   360] loss: 5.866\n",
      "[epoch 6, iterations:   365] loss: 5.724\n",
      "[epoch 6, iterations:   370] loss: 5.615\n",
      "[epoch 6, iterations:   375] loss: 5.542\n",
      "[epoch 6, iterations:   380] loss: 5.852\n",
      "[epoch 6, iterations:   385] loss: 5.797\n",
      "[epoch 6, iterations:   390] loss: 5.570\n",
      "[epoch 6, iterations:   395] loss: 5.771\n",
      "[epoch 6, iterations:   400] loss: 5.739\n",
      "[epoch 7, iterations:     5] loss: 5.675\n",
      "[epoch 7, iterations:    10] loss: 5.765\n",
      "[epoch 7, iterations:    15] loss: 5.763\n",
      "[epoch 7, iterations:    20] loss: 5.645\n",
      "[epoch 7, iterations:    25] loss: 5.603\n",
      "[epoch 7, iterations:    30] loss: 5.803\n",
      "[epoch 7, iterations:    35] loss: 5.508\n",
      "[epoch 7, iterations:    40] loss: 5.877\n",
      "[epoch 7, iterations:    45] loss: 5.980\n",
      "[epoch 7, iterations:    50] loss: 5.663\n",
      "[epoch 7, iterations:    55] loss: 5.811\n",
      "[epoch 7, iterations:    60] loss: 5.761\n",
      "[epoch 7, iterations:    65] loss: 5.680\n",
      "[epoch 7, iterations:    70] loss: 5.484\n",
      "[epoch 7, iterations:    75] loss: 5.687\n",
      "[epoch 7, iterations:    80] loss: 5.777\n",
      "[epoch 7, iterations:    85] loss: 5.761\n",
      "[epoch 7, iterations:    90] loss: 5.729\n",
      "[epoch 7, iterations:    95] loss: 5.697\n",
      "[epoch 7, iterations:   100] loss: 5.585\n",
      "[epoch 7, iterations:   105] loss: 5.705\n",
      "[epoch 7, iterations:   110] loss: 5.776\n",
      "[epoch 7, iterations:   115] loss: 5.690\n",
      "[epoch 7, iterations:   120] loss: 5.515\n",
      "[epoch 7, iterations:   125] loss: 5.503\n",
      "[epoch 7, iterations:   130] loss: 5.867\n",
      "[epoch 7, iterations:   135] loss: 5.562\n",
      "[epoch 7, iterations:   140] loss: 5.382\n",
      "[epoch 7, iterations:   145] loss: 5.497\n",
      "[epoch 7, iterations:   150] loss: 5.474\n",
      "[epoch 7, iterations:   155] loss: 5.248\n",
      "[epoch 7, iterations:   160] loss: 5.097\n",
      "[epoch 7, iterations:   165] loss: 5.931\n",
      "[epoch 7, iterations:   170] loss: 5.823\n",
      "[epoch 7, iterations:   175] loss: 5.820\n",
      "[epoch 7, iterations:   180] loss: 5.694\n",
      "[epoch 7, iterations:   185] loss: 6.018\n",
      "[epoch 7, iterations:   190] loss: 5.731\n",
      "[epoch 7, iterations:   195] loss: 5.662\n",
      "[epoch 7, iterations:   200] loss: 6.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7, iterations:   205] loss: 5.839\n",
      "[epoch 7, iterations:   210] loss: 6.050\n",
      "[epoch 7, iterations:   215] loss: 5.839\n",
      "[epoch 7, iterations:   220] loss: 5.840\n",
      "[epoch 7, iterations:   225] loss: 5.675\n",
      "[epoch 7, iterations:   230] loss: 5.857\n",
      "[epoch 7, iterations:   235] loss: 5.820\n",
      "[epoch 7, iterations:   240] loss: 5.905\n",
      "[epoch 7, iterations:   245] loss: 5.880\n",
      "[epoch 7, iterations:   250] loss: 5.874\n",
      "[epoch 7, iterations:   255] loss: 5.744\n",
      "[epoch 7, iterations:   260] loss: 5.929\n",
      "[epoch 7, iterations:   265] loss: 5.634\n",
      "[epoch 7, iterations:   270] loss: 6.090\n",
      "[epoch 7, iterations:   275] loss: 5.855\n",
      "[epoch 7, iterations:   280] loss: 5.943\n",
      "[epoch 7, iterations:   285] loss: 5.892\n",
      "[epoch 7, iterations:   290] loss: 5.790\n",
      "[epoch 7, iterations:   295] loss: 5.801\n",
      "[epoch 7, iterations:   300] loss: 5.764\n",
      "[epoch 7, iterations:   305] loss: 5.895\n",
      "[epoch 7, iterations:   310] loss: 5.819\n",
      "[epoch 7, iterations:   315] loss: 5.636\n",
      "[epoch 7, iterations:   320] loss: 5.969\n",
      "[epoch 7, iterations:   325] loss: 5.848\n",
      "[epoch 7, iterations:   330] loss: 5.776\n",
      "[epoch 7, iterations:   335] loss: 5.775\n",
      "[epoch 7, iterations:   340] loss: 5.926\n",
      "[epoch 7, iterations:   345] loss: 5.928\n",
      "[epoch 7, iterations:   350] loss: 5.676\n",
      "[epoch 7, iterations:   355] loss: 5.890\n",
      "[epoch 7, iterations:   360] loss: 5.637\n",
      "[epoch 7, iterations:   365] loss: 5.820\n",
      "[epoch 7, iterations:   370] loss: 5.810\n",
      "[epoch 7, iterations:   375] loss: 5.955\n",
      "[epoch 7, iterations:   380] loss: 5.856\n",
      "[epoch 7, iterations:   385] loss: 5.730\n",
      "[epoch 7, iterations:   390] loss: 5.719\n",
      "[epoch 7, iterations:   395] loss: 6.004\n",
      "[epoch 7, iterations:   400] loss: 5.760\n",
      "[epoch 8, iterations:     5] loss: 5.631\n",
      "[epoch 8, iterations:    10] loss: 5.950\n",
      "[epoch 8, iterations:    15] loss: 5.652\n",
      "[epoch 8, iterations:    20] loss: 5.645\n",
      "[epoch 8, iterations:    25] loss: 5.668\n",
      "[epoch 8, iterations:    30] loss: 5.685\n",
      "[epoch 8, iterations:    35] loss: 5.804\n",
      "[epoch 8, iterations:    40] loss: 5.994\n",
      "[epoch 8, iterations:    45] loss: 5.655\n",
      "[epoch 8, iterations:    50] loss: 5.573\n",
      "[epoch 8, iterations:    55] loss: 5.670\n",
      "[epoch 8, iterations:    60] loss: 5.626\n",
      "[epoch 8, iterations:    65] loss: 5.568\n",
      "[epoch 8, iterations:    70] loss: 5.711\n",
      "[epoch 8, iterations:    75] loss: 5.537\n",
      "[epoch 8, iterations:    80] loss: 5.579\n",
      "[epoch 8, iterations:    85] loss: 5.581\n",
      "[epoch 8, iterations:    90] loss: 5.441\n",
      "[epoch 8, iterations:    95] loss: 5.471\n",
      "[epoch 8, iterations:   100] loss: 4.988\n",
      "[epoch 8, iterations:   105] loss: 5.691\n",
      "[epoch 8, iterations:   110] loss: 5.830\n",
      "[epoch 8, iterations:   115] loss: 5.937\n",
      "[epoch 8, iterations:   120] loss: 5.742\n",
      "[epoch 8, iterations:   125] loss: 5.958\n",
      "[epoch 8, iterations:   130] loss: 5.819\n",
      "[epoch 8, iterations:   135] loss: 5.905\n",
      "[epoch 8, iterations:   140] loss: 5.618\n",
      "[epoch 8, iterations:   145] loss: 5.813\n",
      "[epoch 8, iterations:   150] loss: 5.936\n",
      "[epoch 8, iterations:   155] loss: 5.822\n",
      "[epoch 8, iterations:   160] loss: 5.841\n",
      "[epoch 8, iterations:   165] loss: 5.819\n",
      "[epoch 8, iterations:   170] loss: 6.065\n",
      "[epoch 8, iterations:   175] loss: 5.815\n",
      "[epoch 8, iterations:   180] loss: 5.633\n",
      "[epoch 8, iterations:   185] loss: 5.885\n",
      "[epoch 8, iterations:   190] loss: 5.861\n",
      "[epoch 8, iterations:   195] loss: 5.904\n",
      "[epoch 8, iterations:   200] loss: 5.960\n",
      "[epoch 8, iterations:   205] loss: 5.790\n",
      "[epoch 8, iterations:   210] loss: 5.622\n",
      "[epoch 8, iterations:   215] loss: 5.847\n",
      "[epoch 8, iterations:   220] loss: 5.826\n",
      "[epoch 8, iterations:   225] loss: 5.539\n",
      "[epoch 8, iterations:   230] loss: 5.844\n",
      "[epoch 8, iterations:   235] loss: 5.856\n",
      "[epoch 8, iterations:   240] loss: 5.766\n",
      "[epoch 8, iterations:   245] loss: 5.574\n",
      "[epoch 8, iterations:   250] loss: 5.592\n",
      "[epoch 8, iterations:   255] loss: 5.483\n",
      "[epoch 8, iterations:   260] loss: 5.010\n",
      "[epoch 8, iterations:   265] loss: 5.520\n",
      "[epoch 8, iterations:   270] loss: 5.019\n",
      "[epoch 8, iterations:   275] loss: 5.831\n",
      "[epoch 8, iterations:   280] loss: 5.930\n",
      "[epoch 8, iterations:   285] loss: 5.817\n",
      "[epoch 8, iterations:   290] loss: 5.836\n",
      "[epoch 8, iterations:   295] loss: 5.725\n",
      "[epoch 8, iterations:   300] loss: 5.911\n",
      "[epoch 8, iterations:   305] loss: 5.744\n",
      "[epoch 8, iterations:   310] loss: 5.841\n",
      "[epoch 8, iterations:   315] loss: 5.795\n",
      "[epoch 8, iterations:   320] loss: 5.804\n",
      "[epoch 8, iterations:   325] loss: 5.585\n",
      "[epoch 8, iterations:   330] loss: 5.710\n",
      "[epoch 8, iterations:   335] loss: 5.951\n",
      "[epoch 8, iterations:   340] loss: 5.946\n",
      "[epoch 8, iterations:   345] loss: 5.862\n",
      "[epoch 8, iterations:   350] loss: 5.765\n",
      "[epoch 8, iterations:   355] loss: 5.675\n",
      "[epoch 8, iterations:   360] loss: 6.027\n",
      "[epoch 8, iterations:   365] loss: 5.674\n",
      "[epoch 8, iterations:   370] loss: 5.564\n",
      "[epoch 8, iterations:   375] loss: 5.258\n",
      "[epoch 8, iterations:   380] loss: 5.340\n",
      "[epoch 8, iterations:   385] loss: 5.731\n",
      "[epoch 8, iterations:   390] loss: 5.942\n",
      "[epoch 8, iterations:   395] loss: 5.563\n",
      "[epoch 8, iterations:   400] loss: 5.897\n",
      "[epoch 9, iterations:     5] loss: 5.646\n",
      "[epoch 9, iterations:    10] loss: 5.883\n",
      "[epoch 9, iterations:    15] loss: 5.782\n",
      "[epoch 9, iterations:    20] loss: 5.862\n",
      "[epoch 9, iterations:    25] loss: 5.785\n",
      "[epoch 9, iterations:    30] loss: 6.014\n",
      "[epoch 9, iterations:    35] loss: 5.491\n",
      "[epoch 9, iterations:    40] loss: 5.909\n",
      "[epoch 9, iterations:    45] loss: 5.594\n",
      "[epoch 9, iterations:    50] loss: 5.857\n",
      "[epoch 9, iterations:    55] loss: 5.787\n",
      "[epoch 9, iterations:    60] loss: 5.605\n",
      "[epoch 9, iterations:    65] loss: 5.494\n",
      "[epoch 9, iterations:    70] loss: 5.804\n",
      "[epoch 9, iterations:    75] loss: 5.918\n",
      "[epoch 9, iterations:    80] loss: 5.721\n",
      "[epoch 9, iterations:    85] loss: 5.880\n",
      "[epoch 9, iterations:    90] loss: 5.685\n",
      "[epoch 9, iterations:    95] loss: 5.971\n",
      "[epoch 9, iterations:   100] loss: 5.588\n",
      "[epoch 9, iterations:   105] loss: 5.255\n",
      "[epoch 9, iterations:   110] loss: 4.973\n",
      "[epoch 9, iterations:   115] loss: 5.668\n",
      "[epoch 9, iterations:   120] loss: 5.780\n",
      "[epoch 9, iterations:   125] loss: 5.779\n",
      "[epoch 9, iterations:   130] loss: 5.986\n",
      "[epoch 9, iterations:   135] loss: 5.695\n",
      "[epoch 9, iterations:   140] loss: 5.989\n",
      "[epoch 9, iterations:   145] loss: 5.852\n",
      "[epoch 9, iterations:   150] loss: 5.839\n",
      "[epoch 9, iterations:   155] loss: 5.687\n",
      "[epoch 9, iterations:   160] loss: 5.693\n",
      "[epoch 9, iterations:   165] loss: 5.693\n",
      "[epoch 9, iterations:   170] loss: 5.761\n",
      "[epoch 9, iterations:   175] loss: 5.850\n",
      "[epoch 9, iterations:   180] loss: 5.862\n",
      "[epoch 9, iterations:   185] loss: 5.839\n",
      "[epoch 9, iterations:   190] loss: 5.615\n",
      "[epoch 9, iterations:   195] loss: 5.806\n",
      "[epoch 9, iterations:   200] loss: 5.445\n",
      "[epoch 9, iterations:   205] loss: 6.089\n",
      "[epoch 9, iterations:   210] loss: 5.897\n",
      "[epoch 9, iterations:   215] loss: 5.691\n",
      "[epoch 9, iterations:   220] loss: 5.601\n",
      "[epoch 9, iterations:   225] loss: 5.936\n",
      "[epoch 9, iterations:   230] loss: 5.671\n",
      "[epoch 9, iterations:   235] loss: 5.819\n",
      "[epoch 9, iterations:   240] loss: 5.874\n",
      "[epoch 9, iterations:   245] loss: 5.887\n",
      "[epoch 9, iterations:   250] loss: 5.668\n",
      "[epoch 9, iterations:   255] loss: 5.753\n",
      "[epoch 9, iterations:   260] loss: 5.770\n",
      "[epoch 9, iterations:   265] loss: 5.747\n",
      "[epoch 9, iterations:   270] loss: 5.842\n",
      "[epoch 9, iterations:   275] loss: 5.679\n",
      "[epoch 9, iterations:   280] loss: 5.616\n",
      "[epoch 9, iterations:   285] loss: 5.680\n",
      "[epoch 9, iterations:   290] loss: 5.787\n",
      "[epoch 9, iterations:   295] loss: 5.641\n",
      "[epoch 9, iterations:   300] loss: 5.684\n",
      "[epoch 9, iterations:   305] loss: 5.883\n",
      "[epoch 9, iterations:   310] loss: 5.993\n",
      "[epoch 9, iterations:   315] loss: 5.760\n",
      "[epoch 9, iterations:   320] loss: 5.754\n",
      "[epoch 9, iterations:   325] loss: 6.033\n",
      "[epoch 9, iterations:   330] loss: 5.994\n",
      "[epoch 9, iterations:   335] loss: 5.947\n",
      "[epoch 9, iterations:   340] loss: 5.956\n",
      "[epoch 9, iterations:   345] loss: 5.914\n",
      "[epoch 9, iterations:   350] loss: 5.942\n",
      "[epoch 9, iterations:   355] loss: 5.954\n",
      "[epoch 9, iterations:   360] loss: 5.805\n",
      "[epoch 9, iterations:   365] loss: 5.758\n",
      "[epoch 9, iterations:   370] loss: 5.637\n",
      "[epoch 9, iterations:   375] loss: 5.814\n",
      "[epoch 9, iterations:   380] loss: 5.818\n",
      "[epoch 9, iterations:   385] loss: 5.712\n",
      "[epoch 9, iterations:   390] loss: 5.584\n",
      "[epoch 9, iterations:   395] loss: 5.573\n",
      "[epoch 9, iterations:   400] loss: 5.850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10, iterations:     5] loss: 5.680\n",
      "[epoch 10, iterations:    10] loss: 5.899\n",
      "[epoch 10, iterations:    15] loss: 5.617\n",
      "[epoch 10, iterations:    20] loss: 5.800\n",
      "[epoch 10, iterations:    25] loss: 5.771\n",
      "[epoch 10, iterations:    30] loss: 5.540\n",
      "[epoch 10, iterations:    35] loss: 5.631\n",
      "[epoch 10, iterations:    40] loss: 5.766\n",
      "[epoch 10, iterations:    45] loss: 5.909\n",
      "[epoch 10, iterations:    50] loss: 5.599\n",
      "[epoch 10, iterations:    55] loss: 5.703\n",
      "[epoch 10, iterations:    60] loss: 5.532\n",
      "[epoch 10, iterations:    65] loss: 5.912\n",
      "[epoch 10, iterations:    70] loss: 5.961\n",
      "[epoch 10, iterations:    75] loss: 5.880\n",
      "[epoch 10, iterations:    80] loss: 5.642\n",
      "[epoch 10, iterations:    85] loss: 5.686\n",
      "[epoch 10, iterations:    90] loss: 5.776\n",
      "[epoch 10, iterations:    95] loss: 5.612\n",
      "[epoch 10, iterations:   100] loss: 5.580\n",
      "[epoch 10, iterations:   105] loss: 5.174\n",
      "[epoch 10, iterations:   110] loss: 5.007\n",
      "[epoch 10, iterations:   115] loss: 4.742\n",
      "[epoch 10, iterations:   120] loss: 5.486\n",
      "[epoch 10, iterations:   125] loss: 5.315\n",
      "[epoch 10, iterations:   130] loss: 5.610\n",
      "[epoch 10, iterations:   135] loss: 5.105\n",
      "[epoch 10, iterations:   140] loss: 5.878\n",
      "[epoch 10, iterations:   145] loss: 5.902\n",
      "[epoch 10, iterations:   150] loss: 5.934\n",
      "[epoch 10, iterations:   155] loss: 5.796\n",
      "[epoch 10, iterations:   160] loss: 5.897\n",
      "[epoch 10, iterations:   165] loss: 5.703\n",
      "[epoch 10, iterations:   170] loss: 5.976\n",
      "[epoch 10, iterations:   175] loss: 5.647\n",
      "[epoch 10, iterations:   180] loss: 5.997\n",
      "[epoch 10, iterations:   185] loss: 5.726\n",
      "[epoch 10, iterations:   190] loss: 5.802\n",
      "[epoch 10, iterations:   195] loss: 5.766\n",
      "[epoch 10, iterations:   200] loss: 5.711\n",
      "[epoch 10, iterations:   205] loss: 5.888\n",
      "[epoch 10, iterations:   210] loss: 5.841\n",
      "[epoch 10, iterations:   215] loss: 5.955\n",
      "[epoch 10, iterations:   220] loss: 6.003\n",
      "[epoch 10, iterations:   225] loss: 5.975\n",
      "[epoch 10, iterations:   230] loss: 5.677\n",
      "[epoch 10, iterations:   235] loss: 5.976\n",
      "[epoch 10, iterations:   240] loss: 5.834\n",
      "[epoch 10, iterations:   245] loss: 5.999\n",
      "[epoch 10, iterations:   250] loss: 5.791\n",
      "[epoch 10, iterations:   255] loss: 5.587\n",
      "[epoch 10, iterations:   260] loss: 5.585\n",
      "[epoch 10, iterations:   265] loss: 5.775\n",
      "[epoch 10, iterations:   270] loss: 5.713\n",
      "[epoch 10, iterations:   275] loss: 5.836\n",
      "[epoch 10, iterations:   280] loss: 5.715\n",
      "[epoch 10, iterations:   285] loss: 5.933\n",
      "[epoch 10, iterations:   290] loss: 5.739\n",
      "[epoch 10, iterations:   295] loss: 5.853\n",
      "[epoch 10, iterations:   300] loss: 5.673\n",
      "[epoch 10, iterations:   305] loss: 5.736\n",
      "[epoch 10, iterations:   310] loss: 5.677\n",
      "[epoch 10, iterations:   315] loss: 5.872\n",
      "[epoch 10, iterations:   320] loss: 5.900\n",
      "[epoch 10, iterations:   325] loss: 5.727\n",
      "[epoch 10, iterations:   330] loss: 5.997\n",
      "[epoch 10, iterations:   335] loss: 5.853\n",
      "[epoch 10, iterations:   340] loss: 5.836\n",
      "[epoch 10, iterations:   345] loss: 5.779\n",
      "[epoch 10, iterations:   350] loss: 6.055\n",
      "[epoch 10, iterations:   355] loss: 5.668\n",
      "[epoch 10, iterations:   360] loss: 5.769\n",
      "[epoch 10, iterations:   365] loss: 5.792\n",
      "[epoch 10, iterations:   370] loss: 5.969\n",
      "[epoch 10, iterations:   375] loss: 5.755\n",
      "[epoch 10, iterations:   380] loss: 5.759\n",
      "[epoch 10, iterations:   385] loss: 5.411\n",
      "[epoch 10, iterations:   390] loss: 6.008\n",
      "[epoch 10, iterations:   395] loss: 5.754\n",
      "[epoch 10, iterations:   400] loss: 5.929\n",
      "[epoch 11, iterations:     5] loss: 5.906\n",
      "[epoch 11, iterations:    10] loss: 5.853\n",
      "[epoch 11, iterations:    15] loss: 5.975\n",
      "[epoch 11, iterations:    20] loss: 5.850\n",
      "[epoch 11, iterations:    25] loss: 5.499\n",
      "[epoch 11, iterations:    30] loss: 5.775\n",
      "[epoch 11, iterations:    35] loss: 5.737\n",
      "[epoch 11, iterations:    40] loss: 5.588\n",
      "[epoch 11, iterations:    45] loss: 5.959\n",
      "[epoch 11, iterations:    50] loss: 5.758\n",
      "[epoch 11, iterations:    55] loss: 5.956\n",
      "[epoch 11, iterations:    60] loss: 5.678\n",
      "[epoch 11, iterations:    65] loss: 5.816\n",
      "[epoch 11, iterations:    70] loss: 5.948\n",
      "[epoch 11, iterations:    75] loss: 5.794\n",
      "[epoch 11, iterations:    80] loss: 6.050\n",
      "[epoch 11, iterations:    85] loss: 5.844\n",
      "[epoch 11, iterations:    90] loss: 5.913\n",
      "[epoch 11, iterations:    95] loss: 5.820\n",
      "[epoch 11, iterations:   100] loss: 5.527\n",
      "[epoch 11, iterations:   105] loss: 6.047\n",
      "[epoch 11, iterations:   110] loss: 5.871\n",
      "[epoch 11, iterations:   115] loss: 5.801\n",
      "[epoch 11, iterations:   120] loss: 5.713\n",
      "[epoch 11, iterations:   125] loss: 6.033\n",
      "[epoch 11, iterations:   130] loss: 5.882\n",
      "[epoch 11, iterations:   135] loss: 5.734\n",
      "[epoch 11, iterations:   140] loss: 5.972\n",
      "[epoch 11, iterations:   145] loss: 5.656\n",
      "[epoch 11, iterations:   150] loss: 5.811\n",
      "[epoch 11, iterations:   155] loss: 5.740\n",
      "[epoch 11, iterations:   160] loss: 5.858\n",
      "[epoch 11, iterations:   165] loss: 5.874\n",
      "[epoch 11, iterations:   170] loss: 5.889\n",
      "[epoch 11, iterations:   175] loss: 5.843\n",
      "[epoch 11, iterations:   180] loss: 5.842\n",
      "[epoch 11, iterations:   185] loss: 5.813\n",
      "[epoch 11, iterations:   190] loss: 5.620\n",
      "[epoch 11, iterations:   195] loss: 5.624\n",
      "[epoch 11, iterations:   200] loss: 5.714\n",
      "[epoch 11, iterations:   205] loss: 5.765\n",
      "[epoch 11, iterations:   210] loss: 5.572\n",
      "[epoch 11, iterations:   215] loss: 5.770\n",
      "[epoch 11, iterations:   220] loss: 5.864\n",
      "[epoch 11, iterations:   225] loss: 5.794\n",
      "[epoch 11, iterations:   230] loss: 5.798\n",
      "[epoch 11, iterations:   235] loss: 5.820\n",
      "[epoch 11, iterations:   240] loss: 6.036\n",
      "[epoch 11, iterations:   245] loss: 5.869\n",
      "[epoch 11, iterations:   250] loss: 5.654\n",
      "[epoch 11, iterations:   255] loss: 5.805\n",
      "[epoch 11, iterations:   260] loss: 5.855\n",
      "[epoch 11, iterations:   265] loss: 5.801\n",
      "[epoch 11, iterations:   270] loss: 5.824\n",
      "[epoch 11, iterations:   275] loss: 5.825\n",
      "[epoch 11, iterations:   280] loss: 5.775\n",
      "[epoch 11, iterations:   285] loss: 5.621\n",
      "[epoch 11, iterations:   290] loss: 5.632\n",
      "[epoch 11, iterations:   295] loss: 5.802\n",
      "[epoch 11, iterations:   300] loss: 5.783\n",
      "[epoch 11, iterations:   305] loss: 5.808\n",
      "[epoch 11, iterations:   310] loss: 5.819\n",
      "[epoch 11, iterations:   315] loss: 5.820\n",
      "[epoch 11, iterations:   320] loss: 5.743\n",
      "[epoch 11, iterations:   325] loss: 5.595\n",
      "[epoch 11, iterations:   330] loss: 5.583\n",
      "[epoch 11, iterations:   335] loss: 5.752\n",
      "[epoch 11, iterations:   340] loss: 5.715\n",
      "[epoch 11, iterations:   345] loss: 5.567\n",
      "[epoch 11, iterations:   350] loss: 5.682\n",
      "[epoch 11, iterations:   355] loss: 5.734\n",
      "[epoch 11, iterations:   360] loss: 5.873\n",
      "[epoch 11, iterations:   365] loss: 5.700\n",
      "[epoch 11, iterations:   370] loss: 5.699\n",
      "[epoch 11, iterations:   375] loss: 5.707\n",
      "[epoch 11, iterations:   380] loss: 5.929\n",
      "[epoch 11, iterations:   385] loss: 5.905\n",
      "[epoch 11, iterations:   390] loss: 5.674\n",
      "[epoch 11, iterations:   395] loss: 5.766\n",
      "[epoch 11, iterations:   400] loss: 5.833\n",
      "[epoch 12, iterations:     5] loss: 5.826\n",
      "[epoch 12, iterations:    10] loss: 5.766\n",
      "[epoch 12, iterations:    15] loss: 5.854\n",
      "[epoch 12, iterations:    20] loss: 5.792\n",
      "[epoch 12, iterations:    25] loss: 5.560\n",
      "[epoch 12, iterations:    30] loss: 5.879\n",
      "[epoch 12, iterations:    35] loss: 5.605\n",
      "[epoch 12, iterations:    40] loss: 5.877\n",
      "[epoch 12, iterations:    45] loss: 5.529\n",
      "[epoch 12, iterations:    50] loss: 5.847\n",
      "[epoch 12, iterations:    55] loss: 5.816\n",
      "[epoch 12, iterations:    60] loss: 5.945\n",
      "[epoch 12, iterations:    65] loss: 5.616\n",
      "[epoch 12, iterations:    70] loss: 6.033\n",
      "[epoch 12, iterations:    75] loss: 5.779\n",
      "[epoch 12, iterations:    80] loss: 5.786\n",
      "[epoch 12, iterations:    85] loss: 5.877\n",
      "[epoch 12, iterations:    90] loss: 5.948\n",
      "[epoch 12, iterations:    95] loss: 5.670\n",
      "[epoch 12, iterations:   100] loss: 5.842\n",
      "[epoch 12, iterations:   105] loss: 5.849\n",
      "[epoch 12, iterations:   110] loss: 5.667\n",
      "[epoch 12, iterations:   115] loss: 5.855\n",
      "[epoch 12, iterations:   120] loss: 5.959\n",
      "[epoch 12, iterations:   125] loss: 5.775\n",
      "[epoch 12, iterations:   130] loss: 5.745\n",
      "[epoch 12, iterations:   135] loss: 5.804\n",
      "[epoch 12, iterations:   140] loss: 5.331\n",
      "[epoch 12, iterations:   145] loss: 5.754\n",
      "[epoch 12, iterations:   150] loss: 5.838\n",
      "[epoch 12, iterations:   155] loss: 5.710\n",
      "[epoch 12, iterations:   160] loss: 5.730\n",
      "[epoch 12, iterations:   165] loss: 5.780\n",
      "[epoch 12, iterations:   170] loss: 5.561\n",
      "[epoch 12, iterations:   175] loss: 5.587\n",
      "[epoch 12, iterations:   180] loss: 5.582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12, iterations:   185] loss: 5.523\n",
      "[epoch 12, iterations:   190] loss: 5.752\n",
      "[epoch 12, iterations:   195] loss: 5.620\n",
      "[epoch 12, iterations:   200] loss: 5.920\n",
      "[epoch 12, iterations:   205] loss: 5.910\n",
      "[epoch 12, iterations:   210] loss: 5.500\n",
      "[epoch 12, iterations:   215] loss: 5.768\n",
      "[epoch 12, iterations:   220] loss: 5.494\n",
      "[epoch 12, iterations:   225] loss: 5.755\n",
      "[epoch 12, iterations:   230] loss: 5.117\n",
      "[epoch 12, iterations:   235] loss: 5.491\n",
      "[epoch 12, iterations:   240] loss: 5.324\n",
      "[epoch 12, iterations:   245] loss: 5.570\n",
      "[epoch 12, iterations:   250] loss: 5.850\n",
      "[epoch 12, iterations:   255] loss: 5.483\n",
      "[epoch 12, iterations:   260] loss: 5.162\n",
      "[epoch 12, iterations:   265] loss: 5.857\n",
      "[epoch 12, iterations:   270] loss: 5.851\n",
      "[epoch 12, iterations:   275] loss: 5.835\n",
      "[epoch 12, iterations:   280] loss: 5.641\n",
      "[epoch 12, iterations:   285] loss: 5.816\n",
      "[epoch 12, iterations:   290] loss: 5.696\n",
      "[epoch 12, iterations:   295] loss: 5.786\n",
      "[epoch 12, iterations:   300] loss: 5.752\n",
      "[epoch 12, iterations:   305] loss: 5.870\n",
      "[epoch 12, iterations:   310] loss: 5.762\n",
      "[epoch 12, iterations:   315] loss: 5.806\n",
      "[epoch 12, iterations:   320] loss: 5.821\n",
      "[epoch 12, iterations:   325] loss: 5.689\n",
      "[epoch 12, iterations:   330] loss: 5.757\n",
      "[epoch 12, iterations:   335] loss: 5.932\n",
      "[epoch 12, iterations:   340] loss: 5.772\n",
      "[epoch 12, iterations:   345] loss: 5.882\n",
      "[epoch 12, iterations:   350] loss: 5.826\n",
      "[epoch 12, iterations:   355] loss: 5.750\n",
      "[epoch 12, iterations:   360] loss: 5.885\n",
      "[epoch 12, iterations:   365] loss: 5.684\n",
      "[epoch 12, iterations:   370] loss: 5.856\n",
      "[epoch 12, iterations:   375] loss: 5.711\n",
      "[epoch 12, iterations:   380] loss: 5.700\n",
      "[epoch 12, iterations:   385] loss: 5.817\n",
      "[epoch 12, iterations:   390] loss: 5.778\n",
      "[epoch 12, iterations:   395] loss: 5.753\n",
      "[epoch 12, iterations:   400] loss: 5.645\n",
      "[epoch 13, iterations:     5] loss: 5.721\n",
      "[epoch 13, iterations:    10] loss: 5.549\n",
      "[epoch 13, iterations:    15] loss: 5.613\n",
      "[epoch 13, iterations:    20] loss: 5.671\n",
      "[epoch 13, iterations:    25] loss: 5.845\n",
      "[epoch 13, iterations:    30] loss: 6.087\n",
      "[epoch 13, iterations:    35] loss: 5.683\n",
      "[epoch 13, iterations:    40] loss: 5.939\n",
      "[epoch 13, iterations:    45] loss: 6.057\n",
      "[epoch 13, iterations:    50] loss: 5.883\n",
      "[epoch 13, iterations:    55] loss: 5.866\n",
      "[epoch 13, iterations:    60] loss: 5.909\n",
      "[epoch 13, iterations:    65] loss: 5.975\n",
      "[epoch 13, iterations:    70] loss: 5.567\n",
      "[epoch 13, iterations:    75] loss: 5.766\n",
      "[epoch 13, iterations:    80] loss: 5.688\n",
      "[epoch 13, iterations:    85] loss: 5.844\n",
      "[epoch 13, iterations:    90] loss: 5.813\n",
      "[epoch 13, iterations:    95] loss: 5.785\n",
      "[epoch 13, iterations:   100] loss: 5.734\n",
      "[epoch 13, iterations:   105] loss: 5.858\n",
      "[epoch 13, iterations:   110] loss: 5.776\n",
      "[epoch 13, iterations:   115] loss: 5.600\n",
      "[epoch 13, iterations:   120] loss: 6.021\n",
      "[epoch 13, iterations:   125] loss: 5.857\n",
      "[epoch 13, iterations:   130] loss: 5.731\n",
      "[epoch 13, iterations:   135] loss: 5.893\n",
      "[epoch 13, iterations:   140] loss: 5.641\n",
      "[epoch 13, iterations:   145] loss: 5.830\n",
      "[epoch 13, iterations:   150] loss: 5.791\n",
      "[epoch 13, iterations:   155] loss: 5.632\n",
      "[epoch 13, iterations:   160] loss: 6.037\n",
      "[epoch 13, iterations:   165] loss: 5.500\n",
      "[epoch 13, iterations:   170] loss: 5.694\n",
      "[epoch 13, iterations:   175] loss: 5.689\n",
      "[epoch 13, iterations:   180] loss: 5.566\n",
      "[epoch 13, iterations:   185] loss: 5.727\n",
      "[epoch 13, iterations:   190] loss: 5.955\n",
      "[epoch 13, iterations:   195] loss: 5.845\n",
      "[epoch 13, iterations:   200] loss: 5.815\n",
      "[epoch 13, iterations:   205] loss: 5.817\n",
      "[epoch 13, iterations:   210] loss: 5.923\n",
      "[epoch 13, iterations:   215] loss: 5.670\n",
      "[epoch 13, iterations:   220] loss: 5.695\n",
      "[epoch 13, iterations:   225] loss: 5.829\n",
      "[epoch 13, iterations:   230] loss: 5.691\n",
      "[epoch 13, iterations:   235] loss: 5.866\n",
      "[epoch 13, iterations:   240] loss: 6.060\n",
      "[epoch 13, iterations:   245] loss: 5.846\n",
      "[epoch 13, iterations:   250] loss: 5.825\n",
      "[epoch 13, iterations:   255] loss: 5.949\n",
      "[epoch 13, iterations:   260] loss: 5.734\n",
      "[epoch 13, iterations:   265] loss: 5.925\n",
      "[epoch 13, iterations:   270] loss: 5.681\n",
      "[epoch 13, iterations:   275] loss: 5.471\n",
      "[epoch 13, iterations:   280] loss: 5.475\n",
      "[epoch 13, iterations:   285] loss: 5.839\n",
      "[epoch 13, iterations:   290] loss: 5.787\n",
      "[epoch 13, iterations:   295] loss: 5.579\n",
      "[epoch 13, iterations:   300] loss: 5.592\n",
      "[epoch 13, iterations:   305] loss: 5.698\n",
      "[epoch 13, iterations:   310] loss: 5.758\n",
      "[epoch 13, iterations:   315] loss: 5.776\n",
      "[epoch 13, iterations:   320] loss: 5.850\n",
      "[epoch 13, iterations:   325] loss: 5.795\n",
      "[epoch 13, iterations:   330] loss: 5.851\n",
      "[epoch 13, iterations:   335] loss: 5.721\n",
      "[epoch 13, iterations:   340] loss: 5.894\n",
      "[epoch 13, iterations:   345] loss: 5.616\n",
      "[epoch 13, iterations:   350] loss: 5.676\n",
      "[epoch 13, iterations:   355] loss: 5.886\n",
      "[epoch 13, iterations:   360] loss: 5.758\n",
      "[epoch 13, iterations:   365] loss: 5.772\n",
      "[epoch 13, iterations:   370] loss: 5.669\n",
      "[epoch 13, iterations:   375] loss: 5.841\n",
      "[epoch 13, iterations:   380] loss: 5.635\n",
      "[epoch 13, iterations:   385] loss: 5.896\n",
      "[epoch 13, iterations:   390] loss: 5.570\n",
      "[epoch 13, iterations:   395] loss: 5.674\n",
      "[epoch 13, iterations:   400] loss: 5.683\n",
      "[epoch 14, iterations:     5] loss: 5.523\n",
      "[epoch 14, iterations:    10] loss: 5.739\n",
      "[epoch 14, iterations:    15] loss: 5.487\n",
      "[epoch 14, iterations:    20] loss: 5.697\n",
      "[epoch 14, iterations:    25] loss: 5.899\n",
      "[epoch 14, iterations:    30] loss: 5.616\n",
      "[epoch 14, iterations:    35] loss: 5.737\n",
      "[epoch 14, iterations:    40] loss: 5.696\n",
      "[epoch 14, iterations:    45] loss: 5.851\n",
      "[epoch 14, iterations:    50] loss: 5.707\n",
      "[epoch 14, iterations:    55] loss: 5.733\n",
      "[epoch 14, iterations:    60] loss: 5.887\n",
      "[epoch 14, iterations:    65] loss: 5.637\n",
      "[epoch 14, iterations:    70] loss: 6.036\n",
      "[epoch 14, iterations:    75] loss: 5.683\n",
      "[epoch 14, iterations:    80] loss: 5.603\n",
      "[epoch 14, iterations:    85] loss: 5.943\n",
      "[epoch 14, iterations:    90] loss: 5.693\n",
      "[epoch 14, iterations:    95] loss: 5.673\n",
      "[epoch 14, iterations:   100] loss: 5.555\n",
      "[epoch 14, iterations:   105] loss: 5.783\n",
      "[epoch 14, iterations:   110] loss: 5.913\n",
      "[epoch 14, iterations:   115] loss: 5.617\n",
      "[epoch 14, iterations:   120] loss: 5.831\n",
      "[epoch 14, iterations:   125] loss: 5.607\n",
      "[epoch 14, iterations:   130] loss: 5.789\n",
      "[epoch 14, iterations:   135] loss: 5.783\n",
      "[epoch 14, iterations:   140] loss: 5.768\n",
      "[epoch 14, iterations:   145] loss: 5.645\n",
      "[epoch 14, iterations:   150] loss: 5.822\n",
      "[epoch 14, iterations:   155] loss: 5.586\n",
      "[epoch 14, iterations:   160] loss: 5.587\n",
      "[epoch 14, iterations:   165] loss: 6.033\n",
      "[epoch 14, iterations:   170] loss: 5.626\n",
      "[epoch 14, iterations:   175] loss: 5.570\n",
      "[epoch 14, iterations:   180] loss: 5.819\n",
      "[epoch 14, iterations:   185] loss: 5.930\n",
      "[epoch 14, iterations:   190] loss: 5.833\n",
      "[epoch 14, iterations:   195] loss: 5.910\n",
      "[epoch 14, iterations:   200] loss: 5.720\n",
      "[epoch 14, iterations:   205] loss: 5.588\n",
      "[epoch 14, iterations:   210] loss: 5.703\n",
      "[epoch 14, iterations:   215] loss: 5.705\n",
      "[epoch 14, iterations:   220] loss: 5.729\n",
      "[epoch 14, iterations:   225] loss: 5.931\n",
      "[epoch 14, iterations:   230] loss: 5.689\n",
      "[epoch 14, iterations:   235] loss: 5.685\n",
      "[epoch 14, iterations:   240] loss: 5.762\n",
      "[epoch 14, iterations:   245] loss: 5.808\n",
      "[epoch 14, iterations:   250] loss: 5.636\n",
      "[epoch 14, iterations:   255] loss: 5.761\n",
      "[epoch 14, iterations:   260] loss: 5.668\n",
      "[epoch 14, iterations:   265] loss: 5.753\n",
      "[epoch 14, iterations:   270] loss: 5.845\n",
      "[epoch 14, iterations:   275] loss: 5.681\n",
      "[epoch 14, iterations:   280] loss: 5.910\n",
      "[epoch 14, iterations:   285] loss: 5.792\n",
      "[epoch 14, iterations:   290] loss: 5.644\n",
      "[epoch 14, iterations:   295] loss: 5.671\n",
      "[epoch 14, iterations:   300] loss: 5.367\n",
      "[epoch 14, iterations:   305] loss: 5.855\n",
      "[epoch 14, iterations:   310] loss: 5.665\n",
      "[epoch 14, iterations:   315] loss: 5.924\n",
      "[epoch 14, iterations:   320] loss: 5.578\n",
      "[epoch 14, iterations:   325] loss: 5.607\n",
      "[epoch 14, iterations:   330] loss: 5.848\n",
      "[epoch 14, iterations:   335] loss: 5.603\n",
      "[epoch 14, iterations:   340] loss: 6.002\n",
      "[epoch 14, iterations:   345] loss: 5.959\n",
      "[epoch 14, iterations:   350] loss: 5.758\n",
      "[epoch 14, iterations:   355] loss: 5.837\n",
      "[epoch 14, iterations:   360] loss: 5.600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14, iterations:   365] loss: 5.772\n",
      "[epoch 14, iterations:   370] loss: 5.903\n",
      "[epoch 14, iterations:   375] loss: 5.976\n",
      "[epoch 14, iterations:   380] loss: 5.763\n",
      "[epoch 14, iterations:   385] loss: 5.773\n",
      "[epoch 14, iterations:   390] loss: 5.728\n",
      "[epoch 14, iterations:   395] loss: 5.908\n",
      "[epoch 14, iterations:   400] loss: 5.560\n",
      "[epoch 15, iterations:     5] loss: 5.924\n",
      "[epoch 15, iterations:    10] loss: 5.819\n",
      "[epoch 15, iterations:    15] loss: 5.838\n",
      "[epoch 15, iterations:    20] loss: 5.580\n",
      "[epoch 15, iterations:    25] loss: 5.733\n",
      "[epoch 15, iterations:    30] loss: 5.740\n",
      "[epoch 15, iterations:    35] loss: 5.668\n",
      "[epoch 15, iterations:    40] loss: 5.834\n",
      "[epoch 15, iterations:    45] loss: 5.727\n",
      "[epoch 15, iterations:    50] loss: 5.653\n",
      "[epoch 15, iterations:    55] loss: 5.719\n",
      "[epoch 15, iterations:    60] loss: 5.917\n",
      "[epoch 15, iterations:    65] loss: 5.585\n",
      "[epoch 15, iterations:    70] loss: 5.612\n",
      "[epoch 15, iterations:    75] loss: 5.768\n",
      "[epoch 15, iterations:    80] loss: 5.574\n",
      "[epoch 15, iterations:    85] loss: 5.716\n",
      "[epoch 15, iterations:    90] loss: 5.792\n",
      "[epoch 15, iterations:    95] loss: 5.700\n",
      "[epoch 15, iterations:   100] loss: 5.472\n",
      "[epoch 15, iterations:   105] loss: 5.666\n",
      "[epoch 15, iterations:   110] loss: 5.693\n",
      "[epoch 15, iterations:   115] loss: 5.615\n",
      "[epoch 15, iterations:   120] loss: 5.370\n",
      "[epoch 15, iterations:   125] loss: 5.957\n",
      "[epoch 15, iterations:   130] loss: 5.415\n",
      "[epoch 15, iterations:   135] loss: 5.491\n",
      "[epoch 15, iterations:   140] loss: 5.994\n",
      "[epoch 15, iterations:   145] loss: 5.707\n",
      "[epoch 15, iterations:   150] loss: 5.813\n",
      "[epoch 15, iterations:   155] loss: 5.843\n",
      "[epoch 15, iterations:   160] loss: 5.697\n",
      "[epoch 15, iterations:   165] loss: 5.724\n",
      "[epoch 15, iterations:   170] loss: 5.651\n",
      "[epoch 15, iterations:   175] loss: 5.609\n",
      "[epoch 15, iterations:   180] loss: 5.425\n",
      "[epoch 15, iterations:   185] loss: 5.461\n",
      "[epoch 15, iterations:   190] loss: 5.343\n",
      "[epoch 15, iterations:   195] loss: 4.949\n",
      "[epoch 15, iterations:   200] loss: 5.395\n",
      "[epoch 15, iterations:   205] loss: 5.963\n",
      "[epoch 15, iterations:   210] loss: 5.571\n",
      "[epoch 15, iterations:   215] loss: 5.903\n",
      "[epoch 15, iterations:   220] loss: 5.751\n",
      "[epoch 15, iterations:   225] loss: 5.766\n",
      "[epoch 15, iterations:   230] loss: 5.679\n",
      "[epoch 15, iterations:   235] loss: 5.870\n",
      "[epoch 15, iterations:   240] loss: 5.842\n",
      "[epoch 15, iterations:   245] loss: 5.756\n",
      "[epoch 15, iterations:   250] loss: 5.616\n",
      "[epoch 15, iterations:   255] loss: 5.594\n",
      "[epoch 15, iterations:   260] loss: 5.600\n",
      "[epoch 15, iterations:   265] loss: 5.770\n",
      "[epoch 15, iterations:   270] loss: 5.675\n",
      "[epoch 15, iterations:   275] loss: 5.534\n",
      "[epoch 15, iterations:   280] loss: 5.773\n",
      "[epoch 15, iterations:   285] loss: 5.639\n",
      "[epoch 15, iterations:   290] loss: 5.691\n",
      "[epoch 15, iterations:   295] loss: 5.755\n",
      "[epoch 15, iterations:   300] loss: 5.672\n",
      "[epoch 15, iterations:   305] loss: 5.654\n",
      "[epoch 15, iterations:   310] loss: 5.636\n",
      "[epoch 15, iterations:   315] loss: 5.766\n",
      "[epoch 15, iterations:   320] loss: 5.787\n",
      "[epoch 15, iterations:   325] loss: 5.780\n",
      "[epoch 15, iterations:   330] loss: 5.483\n",
      "[epoch 15, iterations:   335] loss: 5.832\n",
      "[epoch 15, iterations:   340] loss: 5.649\n",
      "[epoch 15, iterations:   345] loss: 5.820\n",
      "[epoch 15, iterations:   350] loss: 5.683\n",
      "[epoch 15, iterations:   355] loss: 5.580\n",
      "[epoch 15, iterations:   360] loss: 5.935\n",
      "[epoch 15, iterations:   365] loss: 5.633\n",
      "[epoch 15, iterations:   370] loss: 5.738\n",
      "[epoch 15, iterations:   375] loss: 5.806\n",
      "[epoch 15, iterations:   380] loss: 5.816\n",
      "[epoch 15, iterations:   385] loss: 5.736\n",
      "[epoch 15, iterations:   390] loss: 5.509\n",
      "[epoch 15, iterations:   395] loss: 5.742\n",
      "[epoch 15, iterations:   400] loss: 5.577\n",
      "[epoch 16, iterations:     5] loss: 5.645\n",
      "[epoch 16, iterations:    10] loss: 5.494\n",
      "[epoch 16, iterations:    15] loss: 5.671\n",
      "[epoch 16, iterations:    20] loss: 5.618\n",
      "[epoch 16, iterations:    25] loss: 5.819\n",
      "[epoch 16, iterations:    30] loss: 5.584\n",
      "[epoch 16, iterations:    35] loss: 5.636\n",
      "[epoch 16, iterations:    40] loss: 5.935\n",
      "[epoch 16, iterations:    45] loss: 5.687\n",
      "[epoch 16, iterations:    50] loss: 5.644\n",
      "[epoch 16, iterations:    55] loss: 5.683\n",
      "[epoch 16, iterations:    60] loss: 5.630\n",
      "[epoch 16, iterations:    65] loss: 5.654\n",
      "[epoch 16, iterations:    70] loss: 5.528\n",
      "[epoch 16, iterations:    75] loss: 5.532\n",
      "[epoch 16, iterations:    80] loss: 5.589\n",
      "[epoch 16, iterations:    85] loss: 5.224\n",
      "[epoch 16, iterations:    90] loss: 5.666\n",
      "[epoch 16, iterations:    95] loss: 5.596\n",
      "[epoch 16, iterations:   100] loss: 5.485\n",
      "[epoch 16, iterations:   105] loss: 5.594\n",
      "[epoch 16, iterations:   110] loss: 5.523\n",
      "[epoch 16, iterations:   115] loss: 5.266\n",
      "[epoch 16, iterations:   120] loss: 5.470\n",
      "[epoch 16, iterations:   125] loss: 5.580\n",
      "[epoch 16, iterations:   130] loss: 5.696\n",
      "[epoch 16, iterations:   135] loss: 5.566\n",
      "[epoch 16, iterations:   140] loss: 5.802\n",
      "[epoch 16, iterations:   145] loss: 5.251\n",
      "[epoch 16, iterations:   150] loss: 5.686\n",
      "[epoch 16, iterations:   155] loss: 5.518\n",
      "[epoch 16, iterations:   160] loss: 5.704\n",
      "[epoch 16, iterations:   165] loss: 5.341\n",
      "[epoch 16, iterations:   170] loss: 5.565\n",
      "[epoch 16, iterations:   175] loss: 5.577\n",
      "[epoch 16, iterations:   180] loss: 5.451\n",
      "[epoch 16, iterations:   185] loss: 5.568\n",
      "[epoch 16, iterations:   190] loss: 5.721\n",
      "[epoch 16, iterations:   195] loss: 5.513\n",
      "[epoch 16, iterations:   200] loss: 5.363\n",
      "[epoch 16, iterations:   205] loss: 5.434\n",
      "[epoch 16, iterations:   210] loss: 5.278\n",
      "[epoch 16, iterations:   215] loss: 5.440\n",
      "[epoch 16, iterations:   220] loss: 4.961\n",
      "[epoch 16, iterations:   225] loss: 5.812\n",
      "[epoch 16, iterations:   230] loss: 5.638\n",
      "[epoch 16, iterations:   235] loss: 5.677\n",
      "[epoch 16, iterations:   240] loss: 5.864\n",
      "[epoch 16, iterations:   245] loss: 5.611\n",
      "[epoch 16, iterations:   250] loss: 5.695\n",
      "[epoch 16, iterations:   255] loss: 5.675\n",
      "[epoch 16, iterations:   260] loss: 5.887\n",
      "[epoch 16, iterations:   265] loss: 5.590\n",
      "[epoch 16, iterations:   270] loss: 5.468\n",
      "[epoch 16, iterations:   275] loss: 5.719\n",
      "[epoch 16, iterations:   280] loss: 5.810\n",
      "[epoch 16, iterations:   285] loss: 5.825\n",
      "[epoch 16, iterations:   290] loss: 5.953\n",
      "[epoch 16, iterations:   295] loss: 5.818\n",
      "[epoch 16, iterations:   300] loss: 5.704\n",
      "[epoch 16, iterations:   305] loss: 5.655\n",
      "[epoch 16, iterations:   310] loss: 5.423\n",
      "[epoch 16, iterations:   315] loss: 5.544\n",
      "[epoch 16, iterations:   320] loss: 5.557\n",
      "[epoch 16, iterations:   325] loss: 5.574\n",
      "[epoch 16, iterations:   330] loss: 5.683\n",
      "[epoch 16, iterations:   335] loss: 5.681\n",
      "[epoch 16, iterations:   340] loss: 5.712\n",
      "[epoch 16, iterations:   345] loss: 5.535\n",
      "[epoch 16, iterations:   350] loss: 5.642\n",
      "[epoch 16, iterations:   355] loss: 5.872\n",
      "[epoch 16, iterations:   360] loss: 5.563\n",
      "[epoch 16, iterations:   365] loss: 5.722\n",
      "[epoch 16, iterations:   370] loss: 5.792\n",
      "[epoch 16, iterations:   375] loss: 5.798\n",
      "[epoch 16, iterations:   380] loss: 5.162\n",
      "[epoch 16, iterations:   385] loss: 5.398\n",
      "[epoch 16, iterations:   390] loss: 5.374\n",
      "[epoch 16, iterations:   395] loss: 5.493\n",
      "[epoch 16, iterations:   400] loss: 5.309\n",
      "[epoch 17, iterations:     5] loss: 5.049\n",
      "[epoch 17, iterations:    10] loss: 5.242\n",
      "[epoch 17, iterations:    15] loss: 5.366\n",
      "[epoch 17, iterations:    20] loss: 4.939\n",
      "[epoch 17, iterations:    25] loss: 5.245\n",
      "[epoch 17, iterations:    30] loss: 5.561\n",
      "[epoch 17, iterations:    35] loss: 5.481\n",
      "[epoch 17, iterations:    40] loss: 5.201\n",
      "[epoch 17, iterations:    45] loss: 5.019\n",
      "[epoch 17, iterations:    50] loss: 5.120\n",
      "[epoch 17, iterations:    55] loss: 4.992\n",
      "[epoch 17, iterations:    60] loss: 5.525\n",
      "[epoch 17, iterations:    65] loss: 5.558\n",
      "[epoch 17, iterations:    70] loss: 5.662\n",
      "[epoch 17, iterations:    75] loss: 5.712\n",
      "[epoch 17, iterations:    80] loss: 5.589\n",
      "[epoch 17, iterations:    85] loss: 5.642\n",
      "[epoch 17, iterations:    90] loss: 5.655\n",
      "[epoch 17, iterations:    95] loss: 5.465\n",
      "[epoch 17, iterations:   100] loss: 5.669\n",
      "[epoch 17, iterations:   105] loss: 5.449\n",
      "[epoch 17, iterations:   110] loss: 5.657\n",
      "[epoch 17, iterations:   115] loss: 5.804\n",
      "[epoch 17, iterations:   120] loss: 5.572\n",
      "[epoch 17, iterations:   125] loss: 5.583\n",
      "[epoch 17, iterations:   130] loss: 5.673\n",
      "[epoch 17, iterations:   135] loss: 5.757\n",
      "[epoch 17, iterations:   140] loss: 5.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 17, iterations:   145] loss: 5.642\n",
      "[epoch 17, iterations:   150] loss: 5.637\n",
      "[epoch 17, iterations:   155] loss: 5.722\n",
      "[epoch 17, iterations:   160] loss: 5.616\n",
      "[epoch 17, iterations:   165] loss: 5.440\n",
      "[epoch 17, iterations:   170] loss: 5.708\n",
      "[epoch 17, iterations:   175] loss: 5.479\n",
      "[epoch 17, iterations:   180] loss: 5.798\n",
      "[epoch 17, iterations:   185] loss: 5.635\n",
      "[epoch 17, iterations:   190] loss: 5.537\n",
      "[epoch 17, iterations:   195] loss: 5.593\n",
      "[epoch 17, iterations:   200] loss: 5.500\n",
      "[epoch 17, iterations:   205] loss: 5.771\n",
      "[epoch 17, iterations:   210] loss: 5.834\n",
      "[epoch 17, iterations:   215] loss: 5.604\n",
      "[epoch 17, iterations:   220] loss: 5.656\n",
      "[epoch 17, iterations:   225] loss: 5.572\n",
      "[epoch 17, iterations:   230] loss: 5.724\n",
      "[epoch 17, iterations:   235] loss: 5.506\n",
      "[epoch 17, iterations:   240] loss: 5.469\n",
      "[epoch 17, iterations:   245] loss: 5.593\n",
      "[epoch 17, iterations:   250] loss: 5.476\n",
      "[epoch 17, iterations:   255] loss: 5.621\n",
      "[epoch 17, iterations:   260] loss: 5.572\n",
      "[epoch 17, iterations:   265] loss: 5.192\n",
      "[epoch 17, iterations:   270] loss: 5.325\n",
      "[epoch 17, iterations:   275] loss: 5.681\n",
      "[epoch 17, iterations:   280] loss: 5.225\n",
      "[epoch 17, iterations:   285] loss: 5.487\n",
      "[epoch 17, iterations:   290] loss: 5.203\n",
      "[epoch 17, iterations:   295] loss: 5.471\n",
      "[epoch 17, iterations:   300] loss: 4.948\n",
      "[epoch 17, iterations:   305] loss: 5.535\n",
      "[epoch 17, iterations:   310] loss: 5.667\n",
      "[epoch 17, iterations:   315] loss: 4.854\n",
      "[epoch 17, iterations:   320] loss: 4.947\n",
      "[epoch 17, iterations:   325] loss: 5.295\n",
      "[epoch 17, iterations:   330] loss: 5.474\n",
      "[epoch 17, iterations:   335] loss: 5.889\n",
      "[epoch 17, iterations:   340] loss: 5.594\n",
      "[epoch 17, iterations:   345] loss: 5.727\n",
      "[epoch 17, iterations:   350] loss: 5.488\n",
      "[epoch 17, iterations:   355] loss: 5.476\n",
      "[epoch 17, iterations:   360] loss: 5.544\n",
      "[epoch 17, iterations:   365] loss: 5.426\n",
      "[epoch 17, iterations:   370] loss: 5.431\n",
      "[epoch 17, iterations:   375] loss: 5.487\n",
      "[epoch 17, iterations:   380] loss: 5.398\n",
      "[epoch 17, iterations:   385] loss: 5.415\n",
      "[epoch 17, iterations:   390] loss: 5.429\n",
      "[epoch 17, iterations:   395] loss: 5.434\n",
      "[epoch 17, iterations:   400] loss: 5.503\n",
      "[epoch 18, iterations:     5] loss: 5.679\n",
      "[epoch 18, iterations:    10] loss: 5.596\n",
      "[epoch 18, iterations:    15] loss: 5.297\n",
      "[epoch 18, iterations:    20] loss: 5.528\n",
      "[epoch 18, iterations:    25] loss: 5.509\n",
      "[epoch 18, iterations:    30] loss: 5.641\n",
      "[epoch 18, iterations:    35] loss: 5.348\n",
      "[epoch 18, iterations:    40] loss: 5.471\n",
      "[epoch 18, iterations:    45] loss: 5.455\n",
      "[epoch 18, iterations:    50] loss: 5.560\n",
      "[epoch 18, iterations:    55] loss: 5.410\n",
      "[epoch 18, iterations:    60] loss: 5.329\n",
      "[epoch 18, iterations:    65] loss: 5.557\n",
      "[epoch 18, iterations:    70] loss: 5.263\n",
      "[epoch 18, iterations:    75] loss: 5.366\n",
      "[epoch 18, iterations:    80] loss: 5.490\n",
      "[epoch 18, iterations:    85] loss: 5.123\n",
      "[epoch 18, iterations:    90] loss: 4.817\n",
      "[epoch 18, iterations:    95] loss: 5.456\n",
      "[epoch 18, iterations:   100] loss: 5.843\n",
      "[epoch 18, iterations:   105] loss: 5.388\n",
      "[epoch 18, iterations:   110] loss: 5.474\n",
      "[epoch 18, iterations:   115] loss: 5.560\n",
      "[epoch 18, iterations:   120] loss: 5.301\n",
      "[epoch 18, iterations:   125] loss: 5.405\n",
      "[epoch 18, iterations:   130] loss: 4.853\n",
      "[epoch 18, iterations:   135] loss: 4.758\n",
      "[epoch 18, iterations:   140] loss: 4.549\n",
      "[epoch 18, iterations:   145] loss: 4.797\n",
      "[epoch 18, iterations:   150] loss: 4.850\n",
      "[epoch 18, iterations:   155] loss: 4.886\n",
      "[epoch 18, iterations:   160] loss: 5.109\n",
      "[epoch 18, iterations:   165] loss: 5.446\n",
      "[epoch 18, iterations:   170] loss: 5.509\n",
      "[epoch 18, iterations:   175] loss: 5.079\n",
      "[epoch 18, iterations:   180] loss: 5.151\n",
      "[epoch 18, iterations:   185] loss: 4.648\n",
      "[epoch 18, iterations:   190] loss: 5.323\n",
      "[epoch 18, iterations:   195] loss: 5.653\n",
      "[epoch 18, iterations:   200] loss: 5.513\n",
      "[epoch 18, iterations:   205] loss: 5.539\n",
      "[epoch 18, iterations:   210] loss: 5.497\n",
      "[epoch 18, iterations:   215] loss: 5.679\n",
      "[epoch 18, iterations:   220] loss: 5.401\n",
      "[epoch 18, iterations:   225] loss: 5.359\n",
      "[epoch 18, iterations:   230] loss: 5.494\n",
      "[epoch 18, iterations:   235] loss: 5.584\n",
      "[epoch 18, iterations:   240] loss: 5.338\n",
      "[epoch 18, iterations:   245] loss: 5.491\n",
      "[epoch 18, iterations:   250] loss: 5.524\n",
      "[epoch 18, iterations:   255] loss: 5.390\n",
      "[epoch 18, iterations:   260] loss: 5.396\n",
      "[epoch 18, iterations:   265] loss: 5.702\n",
      "[epoch 18, iterations:   270] loss: 5.426\n",
      "[epoch 18, iterations:   275] loss: 5.337\n",
      "[epoch 18, iterations:   280] loss: 5.545\n",
      "[epoch 18, iterations:   285] loss: 5.303\n",
      "[epoch 18, iterations:   290] loss: 5.307\n",
      "[epoch 18, iterations:   295] loss: 5.423\n",
      "[epoch 18, iterations:   300] loss: 5.415\n",
      "[epoch 18, iterations:   305] loss: 5.593\n",
      "[epoch 18, iterations:   310] loss: 5.406\n",
      "[epoch 18, iterations:   315] loss: 5.391\n",
      "[epoch 18, iterations:   320] loss: 5.244\n",
      "[epoch 18, iterations:   325] loss: 5.602\n",
      "[epoch 18, iterations:   330] loss: 5.376\n",
      "[epoch 18, iterations:   335] loss: 5.298\n",
      "[epoch 18, iterations:   340] loss: 5.351\n",
      "[epoch 18, iterations:   345] loss: 5.253\n",
      "[epoch 18, iterations:   350] loss: 5.139\n",
      "[epoch 18, iterations:   355] loss: 5.280\n",
      "[epoch 18, iterations:   360] loss: 5.592\n",
      "[epoch 18, iterations:   365] loss: 5.561\n",
      "[epoch 18, iterations:   370] loss: 5.181\n",
      "[epoch 18, iterations:   375] loss: 5.249\n",
      "[epoch 18, iterations:   380] loss: 4.940\n",
      "[epoch 18, iterations:   385] loss: 5.224\n",
      "[epoch 18, iterations:   390] loss: 5.218\n",
      "[epoch 18, iterations:   395] loss: 5.071\n",
      "[epoch 18, iterations:   400] loss: 5.160\n",
      "[epoch 19, iterations:     5] loss: 4.995\n",
      "[epoch 19, iterations:    10] loss: 4.467\n",
      "[epoch 19, iterations:    15] loss: 5.099\n",
      "[epoch 19, iterations:    20] loss: 5.290\n",
      "[epoch 19, iterations:    25] loss: 5.175\n",
      "[epoch 19, iterations:    30] loss: 5.260\n",
      "[epoch 19, iterations:    35] loss: 5.258\n",
      "[epoch 19, iterations:    40] loss: 5.469\n",
      "[epoch 19, iterations:    45] loss: 5.499\n",
      "[epoch 19, iterations:    50] loss: 5.407\n",
      "[epoch 19, iterations:    55] loss: 5.529\n",
      "[epoch 19, iterations:    60] loss: 5.072\n",
      "[epoch 19, iterations:    65] loss: 5.324\n",
      "[epoch 19, iterations:    70] loss: 5.436\n",
      "[epoch 19, iterations:    75] loss: 5.403\n",
      "[epoch 19, iterations:    80] loss: 5.621\n",
      "[epoch 19, iterations:    85] loss: 5.787\n",
      "[epoch 19, iterations:    90] loss: 5.624\n",
      "[epoch 19, iterations:    95] loss: 5.479\n",
      "[epoch 19, iterations:   100] loss: 5.246\n",
      "[epoch 19, iterations:   105] loss: 5.371\n",
      "[epoch 19, iterations:   110] loss: 5.455\n",
      "[epoch 19, iterations:   115] loss: 5.404\n",
      "[epoch 19, iterations:   120] loss: 5.396\n",
      "[epoch 19, iterations:   125] loss: 5.295\n",
      "[epoch 19, iterations:   130] loss: 5.297\n",
      "[epoch 19, iterations:   135] loss: 5.216\n",
      "[epoch 19, iterations:   140] loss: 5.466\n",
      "[epoch 19, iterations:   145] loss: 5.298\n",
      "[epoch 19, iterations:   150] loss: 5.464\n",
      "[epoch 19, iterations:   155] loss: 5.554\n",
      "[epoch 19, iterations:   160] loss: 5.187\n",
      "[epoch 19, iterations:   165] loss: 5.180\n",
      "[epoch 19, iterations:   170] loss: 5.170\n",
      "[epoch 19, iterations:   175] loss: 5.184\n",
      "[epoch 19, iterations:   180] loss: 5.279\n",
      "[epoch 19, iterations:   185] loss: 5.284\n",
      "[epoch 19, iterations:   190] loss: 5.037\n",
      "[epoch 19, iterations:   195] loss: 5.156\n",
      "[epoch 19, iterations:   200] loss: 5.230\n",
      "[epoch 19, iterations:   205] loss: 5.683\n",
      "[epoch 19, iterations:   210] loss: 5.589\n",
      "[epoch 19, iterations:   215] loss: 5.671\n",
      "[epoch 19, iterations:   220] loss: 5.563\n",
      "[epoch 19, iterations:   225] loss: 5.903\n",
      "[epoch 19, iterations:   230] loss: 5.673\n",
      "[epoch 19, iterations:   235] loss: 5.534\n",
      "[epoch 19, iterations:   240] loss: 5.492\n",
      "[epoch 19, iterations:   245] loss: 5.629\n",
      "[epoch 19, iterations:   250] loss: 5.524\n",
      "[epoch 19, iterations:   255] loss: 5.319\n",
      "[epoch 19, iterations:   260] loss: 5.779\n",
      "[epoch 19, iterations:   265] loss: 5.613\n",
      "[epoch 19, iterations:   270] loss: 5.416\n",
      "[epoch 19, iterations:   275] loss: 5.489\n",
      "[epoch 19, iterations:   280] loss: 5.483\n",
      "[epoch 19, iterations:   285] loss: 5.537\n",
      "[epoch 19, iterations:   290] loss: 5.519\n",
      "[epoch 19, iterations:   295] loss: 5.614\n",
      "[epoch 19, iterations:   300] loss: 5.579\n",
      "[epoch 19, iterations:   305] loss: 5.519\n",
      "[epoch 19, iterations:   310] loss: 5.510\n",
      "[epoch 19, iterations:   315] loss: 5.452\n",
      "[epoch 19, iterations:   320] loss: 5.578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19, iterations:   325] loss: 5.361\n",
      "[epoch 19, iterations:   330] loss: 4.915\n",
      "[epoch 19, iterations:   335] loss: 5.234\n",
      "[epoch 19, iterations:   340] loss: 5.643\n",
      "[epoch 19, iterations:   345] loss: 5.311\n",
      "[epoch 19, iterations:   350] loss: 5.263\n",
      "[epoch 19, iterations:   355] loss: 5.387\n",
      "[epoch 19, iterations:   360] loss: 5.537\n",
      "[epoch 19, iterations:   365] loss: 5.792\n",
      "[epoch 19, iterations:   370] loss: 5.296\n",
      "[epoch 19, iterations:   375] loss: 5.190\n",
      "[epoch 19, iterations:   380] loss: 5.497\n",
      "[epoch 19, iterations:   385] loss: 5.601\n",
      "[epoch 19, iterations:   390] loss: 5.214\n",
      "[epoch 19, iterations:   395] loss: 5.568\n",
      "[epoch 19, iterations:   400] loss: 5.692\n",
      "[epoch 20, iterations:     5] loss: 5.461\n",
      "[epoch 20, iterations:    10] loss: 5.416\n",
      "[epoch 20, iterations:    15] loss: 5.212\n",
      "[epoch 20, iterations:    20] loss: 5.869\n",
      "[epoch 20, iterations:    25] loss: 5.588\n",
      "[epoch 20, iterations:    30] loss: 5.583\n",
      "[epoch 20, iterations:    35] loss: 5.429\n",
      "[epoch 20, iterations:    40] loss: 5.454\n",
      "[epoch 20, iterations:    45] loss: 5.606\n",
      "[epoch 20, iterations:    50] loss: 5.575\n",
      "[epoch 20, iterations:    55] loss: 5.254\n",
      "[epoch 20, iterations:    60] loss: 5.488\n",
      "[epoch 20, iterations:    65] loss: 5.270\n",
      "[epoch 20, iterations:    70] loss: 5.363\n",
      "[epoch 20, iterations:    75] loss: 5.448\n",
      "[epoch 20, iterations:    80] loss: 5.536\n",
      "[epoch 20, iterations:    85] loss: 5.324\n",
      "[epoch 20, iterations:    90] loss: 5.259\n",
      "[epoch 20, iterations:    95] loss: 5.401\n",
      "[epoch 20, iterations:   100] loss: 5.425\n",
      "[epoch 20, iterations:   105] loss: 5.160\n",
      "[epoch 20, iterations:   110] loss: 5.534\n",
      "[epoch 20, iterations:   115] loss: 5.270\n",
      "[epoch 20, iterations:   120] loss: 5.271\n",
      "[epoch 20, iterations:   125] loss: 5.591\n",
      "[epoch 20, iterations:   130] loss: 5.459\n",
      "[epoch 20, iterations:   135] loss: 5.161\n",
      "[epoch 20, iterations:   140] loss: 5.456\n",
      "[epoch 20, iterations:   145] loss: 5.358\n",
      "[epoch 20, iterations:   150] loss: 5.461\n",
      "[epoch 20, iterations:   155] loss: 5.145\n",
      "[epoch 20, iterations:   160] loss: 5.315\n",
      "[epoch 20, iterations:   165] loss: 5.438\n",
      "[epoch 20, iterations:   170] loss: 5.252\n",
      "[epoch 20, iterations:   175] loss: 5.598\n",
      "[epoch 20, iterations:   180] loss: 5.404\n",
      "[epoch 20, iterations:   185] loss: 5.137\n",
      "[epoch 20, iterations:   190] loss: 5.553\n",
      "[epoch 20, iterations:   195] loss: 5.356\n",
      "[epoch 20, iterations:   200] loss: 5.462\n",
      "[epoch 20, iterations:   205] loss: 5.407\n",
      "[epoch 20, iterations:   210] loss: 5.370\n",
      "[epoch 20, iterations:   215] loss: 5.327\n",
      "[epoch 20, iterations:   220] loss: 5.454\n",
      "[epoch 20, iterations:   225] loss: 5.374\n",
      "[epoch 20, iterations:   230] loss: 5.460\n",
      "[epoch 20, iterations:   235] loss: 5.242\n",
      "[epoch 20, iterations:   240] loss: 5.336\n",
      "[epoch 20, iterations:   245] loss: 5.574\n",
      "[epoch 20, iterations:   250] loss: 5.537\n",
      "[epoch 20, iterations:   255] loss: 5.283\n",
      "[epoch 20, iterations:   260] loss: 5.267\n",
      "[epoch 20, iterations:   265] loss: 5.582\n",
      "[epoch 20, iterations:   270] loss: 5.349\n",
      "[epoch 20, iterations:   275] loss: 5.464\n",
      "[epoch 20, iterations:   280] loss: 5.349\n",
      "[epoch 20, iterations:   285] loss: 5.455\n",
      "[epoch 20, iterations:   290] loss: 5.511\n",
      "[epoch 20, iterations:   295] loss: 5.156\n",
      "[epoch 20, iterations:   300] loss: 5.026\n",
      "[epoch 20, iterations:   305] loss: 5.253\n",
      "[epoch 20, iterations:   310] loss: 5.294\n",
      "[epoch 20, iterations:   315] loss: 5.312\n",
      "[epoch 20, iterations:   320] loss: 5.231\n",
      "[epoch 20, iterations:   325] loss: 5.312\n",
      "[epoch 20, iterations:   330] loss: 5.190\n",
      "[epoch 20, iterations:   335] loss: 5.196\n",
      "[epoch 20, iterations:   340] loss: 5.127\n",
      "[epoch 20, iterations:   345] loss: 4.876\n",
      "[epoch 20, iterations:   350] loss: 4.797\n",
      "[epoch 20, iterations:   355] loss: 4.138\n",
      "[epoch 20, iterations:   360] loss: 5.017\n",
      "[epoch 20, iterations:   365] loss: 5.854\n",
      "[epoch 20, iterations:   370] loss: 5.576\n",
      "[epoch 20, iterations:   375] loss: 5.307\n",
      "[epoch 20, iterations:   380] loss: 5.500\n",
      "[epoch 20, iterations:   385] loss: 5.375\n",
      "[epoch 20, iterations:   390] loss: 5.312\n",
      "[epoch 20, iterations:   395] loss: 5.014\n",
      "[epoch 20, iterations:   400] loss: 4.912\n",
      "[epoch 21, iterations:     5] loss: 4.195\n",
      "[epoch 21, iterations:    10] loss: 4.388\n",
      "[epoch 21, iterations:    15] loss: 4.269\n",
      "[epoch 21, iterations:    20] loss: 5.149\n",
      "[epoch 21, iterations:    25] loss: 4.849\n",
      "[epoch 21, iterations:    30] loss: 4.290\n",
      "[epoch 21, iterations:    35] loss: 5.025\n",
      "[epoch 21, iterations:    40] loss: 5.405\n",
      "[epoch 21, iterations:    45] loss: 5.095\n",
      "[epoch 21, iterations:    50] loss: 5.285\n",
      "[epoch 21, iterations:    55] loss: 5.211\n",
      "[epoch 21, iterations:    60] loss: 5.081\n",
      "[epoch 21, iterations:    65] loss: 5.230\n",
      "[epoch 21, iterations:    70] loss: 5.078\n",
      "[epoch 21, iterations:    75] loss: 5.171\n",
      "[epoch 21, iterations:    80] loss: 5.397\n",
      "[epoch 21, iterations:    85] loss: 5.253\n",
      "[epoch 21, iterations:    90] loss: 5.120\n",
      "[epoch 21, iterations:    95] loss: 5.038\n",
      "[epoch 21, iterations:   100] loss: 5.112\n",
      "[epoch 21, iterations:   105] loss: 5.209\n",
      "[epoch 21, iterations:   110] loss: 5.118\n",
      "[epoch 21, iterations:   115] loss: 4.857\n",
      "[epoch 21, iterations:   120] loss: 5.001\n",
      "[epoch 21, iterations:   125] loss: 4.225\n",
      "[epoch 21, iterations:   130] loss: 4.100\n",
      "[epoch 21, iterations:   135] loss: 4.313\n",
      "[epoch 21, iterations:   140] loss: 4.033\n",
      "[epoch 21, iterations:   145] loss: 4.771\n",
      "[epoch 21, iterations:   150] loss: 5.232\n",
      "[epoch 21, iterations:   155] loss: 5.281\n",
      "[epoch 21, iterations:   160] loss: 5.199\n",
      "[epoch 21, iterations:   165] loss: 5.057\n",
      "[epoch 21, iterations:   170] loss: 5.125\n",
      "[epoch 21, iterations:   175] loss: 5.184\n",
      "[epoch 21, iterations:   180] loss: 5.314\n",
      "[epoch 21, iterations:   185] loss: 5.407\n",
      "[epoch 21, iterations:   190] loss: 5.054\n",
      "[epoch 21, iterations:   195] loss: 5.214\n",
      "[epoch 21, iterations:   200] loss: 4.891\n",
      "[epoch 21, iterations:   205] loss: 4.462\n",
      "[epoch 21, iterations:   210] loss: 4.016\n",
      "[epoch 21, iterations:   215] loss: 4.255\n",
      "[epoch 21, iterations:   220] loss: 4.962\n",
      "[epoch 21, iterations:   225] loss: 4.350\n",
      "[epoch 21, iterations:   230] loss: 4.693\n",
      "[epoch 21, iterations:   235] loss: 4.955\n",
      "[epoch 21, iterations:   240] loss: 5.206\n",
      "[epoch 21, iterations:   245] loss: 5.350\n",
      "[epoch 21, iterations:   250] loss: 5.098\n",
      "[epoch 21, iterations:   255] loss: 5.324\n",
      "[epoch 21, iterations:   260] loss: 5.048\n",
      "[epoch 21, iterations:   265] loss: 5.096\n",
      "[epoch 21, iterations:   270] loss: 5.254\n",
      "[epoch 21, iterations:   275] loss: 4.802\n",
      "[epoch 21, iterations:   280] loss: 4.737\n",
      "[epoch 21, iterations:   285] loss: 3.849\n",
      "[epoch 21, iterations:   290] loss: 5.311\n",
      "[epoch 21, iterations:   295] loss: 4.166\n",
      "[epoch 21, iterations:   300] loss: 4.383\n",
      "[epoch 21, iterations:   305] loss: 4.881\n",
      "[epoch 21, iterations:   310] loss: 4.514\n",
      "[epoch 21, iterations:   315] loss: 4.136\n",
      "[epoch 21, iterations:   320] loss: 4.127\n",
      "[epoch 21, iterations:   325] loss: 4.028\n",
      "[epoch 21, iterations:   330] loss: 4.211\n",
      "[epoch 21, iterations:   335] loss: 4.019\n",
      "[epoch 21, iterations:   340] loss: 4.764\n",
      "[epoch 21, iterations:   345] loss: 4.829\n",
      "[epoch 21, iterations:   350] loss: 4.557\n",
      "[epoch 21, iterations:   355] loss: 3.398\n",
      "[epoch 21, iterations:   360] loss: 4.575\n",
      "[epoch 21, iterations:   365] loss: 5.317\n",
      "[epoch 21, iterations:   370] loss: 5.119\n",
      "[epoch 21, iterations:   375] loss: 4.967\n",
      "[epoch 21, iterations:   380] loss: 4.879\n",
      "[epoch 21, iterations:   385] loss: 4.806\n",
      "[epoch 21, iterations:   390] loss: 4.730\n",
      "[epoch 21, iterations:   395] loss: 4.799\n",
      "[epoch 21, iterations:   400] loss: 3.881\n",
      "[epoch 22, iterations:     5] loss: 4.713\n",
      "[epoch 22, iterations:    10] loss: 4.723\n",
      "[epoch 22, iterations:    15] loss: 4.749\n",
      "[epoch 22, iterations:    20] loss: 3.956\n",
      "[epoch 22, iterations:    25] loss: 3.718\n",
      "[epoch 22, iterations:    30] loss: 4.534\n",
      "[epoch 22, iterations:    35] loss: 4.762\n",
      "[epoch 22, iterations:    40] loss: 4.574\n",
      "[epoch 22, iterations:    45] loss: 3.766\n",
      "[epoch 22, iterations:    50] loss: 2.899\n",
      "[epoch 22, iterations:    55] loss: 3.052\n",
      "[epoch 22, iterations:    60] loss: 2.700\n",
      "[epoch 22, iterations:    65] loss: 3.175\n",
      "[epoch 22, iterations:    70] loss: 4.691\n",
      "[epoch 22, iterations:    75] loss: 5.017\n",
      "[epoch 22, iterations:    80] loss: 4.639\n",
      "[epoch 22, iterations:    85] loss: 4.858\n",
      "[epoch 22, iterations:    90] loss: 4.897\n",
      "[epoch 22, iterations:    95] loss: 4.359\n",
      "[epoch 22, iterations:   100] loss: 3.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 22, iterations:   105] loss: 3.639\n",
      "[epoch 22, iterations:   110] loss: 4.377\n",
      "[epoch 22, iterations:   115] loss: 4.397\n",
      "[epoch 22, iterations:   120] loss: 3.222\n",
      "[epoch 22, iterations:   125] loss: 3.363\n",
      "[epoch 22, iterations:   130] loss: 4.930\n",
      "[epoch 22, iterations:   135] loss: 3.269\n",
      "[epoch 22, iterations:   140] loss: 3.495\n",
      "[epoch 22, iterations:   145] loss: 3.293\n",
      "[epoch 22, iterations:   150] loss: 3.589\n",
      "[epoch 22, iterations:   155] loss: 2.585\n",
      "[epoch 22, iterations:   160] loss: 2.888\n",
      "[epoch 22, iterations:   165] loss: 3.096\n",
      "[epoch 22, iterations:   170] loss: 2.816\n",
      "[epoch 22, iterations:   175] loss: 2.577\n",
      "[epoch 22, iterations:   180] loss: 3.552\n",
      "[epoch 22, iterations:   185] loss: 4.665\n",
      "[epoch 22, iterations:   190] loss: 4.687\n",
      "[epoch 22, iterations:   195] loss: 4.972\n",
      "[epoch 22, iterations:   200] loss: 4.054\n",
      "[epoch 22, iterations:   205] loss: 4.706\n",
      "[epoch 22, iterations:   210] loss: 3.925\n",
      "[epoch 22, iterations:   215] loss: 3.296\n",
      "[epoch 22, iterations:   220] loss: 2.734\n",
      "[epoch 22, iterations:   225] loss: 3.075\n",
      "[epoch 22, iterations:   230] loss: 4.378\n",
      "[epoch 22, iterations:   235] loss: 4.690\n",
      "[epoch 22, iterations:   240] loss: 4.349\n",
      "[epoch 22, iterations:   245] loss: 4.197\n",
      "[epoch 22, iterations:   250] loss: 3.563\n",
      "[epoch 22, iterations:   255] loss: 3.302\n",
      "[epoch 22, iterations:   260] loss: 2.535\n",
      "[epoch 22, iterations:   265] loss: 2.561\n",
      "[epoch 22, iterations:   270] loss: 3.840\n",
      "[epoch 22, iterations:   275] loss: 3.372\n",
      "[epoch 22, iterations:   280] loss: 4.847\n",
      "[epoch 22, iterations:   285] loss: 3.783\n",
      "[epoch 22, iterations:   290] loss: 3.083\n",
      "[epoch 22, iterations:   295] loss: 3.490\n",
      "[epoch 22, iterations:   300] loss: 3.237\n",
      "[epoch 22, iterations:   305] loss: 2.541\n",
      "[epoch 22, iterations:   310] loss: 3.130\n",
      "[epoch 22, iterations:   315] loss: 3.604\n",
      "[epoch 22, iterations:   320] loss: 3.922\n",
      "[epoch 22, iterations:   325] loss: 3.078\n",
      "[epoch 22, iterations:   330] loss: 3.059\n",
      "[epoch 22, iterations:   335] loss: 4.379\n",
      "[epoch 22, iterations:   340] loss: 4.099\n",
      "[epoch 22, iterations:   345] loss: 3.724\n",
      "[epoch 22, iterations:   350] loss: 3.369\n",
      "[epoch 22, iterations:   355] loss: 3.474\n",
      "[epoch 22, iterations:   360] loss: 2.924\n",
      "[epoch 22, iterations:   365] loss: 3.489\n",
      "[epoch 22, iterations:   370] loss: 3.724\n",
      "[epoch 22, iterations:   375] loss: 4.571\n",
      "[epoch 22, iterations:   380] loss: 4.996\n",
      "[epoch 22, iterations:   385] loss: 4.645\n",
      "[epoch 22, iterations:   390] loss: 3.962\n",
      "[epoch 22, iterations:   395] loss: 3.673\n",
      "[epoch 22, iterations:   400] loss: 4.629\n",
      "[epoch 23, iterations:     5] loss: 4.597\n",
      "[epoch 23, iterations:    10] loss: 4.008\n",
      "[epoch 23, iterations:    15] loss: 3.878\n",
      "[epoch 23, iterations:    20] loss: 3.340\n",
      "[epoch 23, iterations:    25] loss: 2.957\n",
      "[epoch 23, iterations:    30] loss: 3.937\n",
      "[epoch 23, iterations:    35] loss: 3.699\n",
      "[epoch 23, iterations:    40] loss: 4.349\n",
      "[epoch 23, iterations:    45] loss: 4.800\n",
      "[epoch 23, iterations:    50] loss: 4.094\n",
      "[epoch 23, iterations:    55] loss: 4.717\n",
      "[epoch 23, iterations:    60] loss: 4.943\n",
      "[epoch 23, iterations:    65] loss: 4.700\n",
      "[epoch 23, iterations:    70] loss: 5.105\n",
      "[epoch 23, iterations:    75] loss: 4.943\n",
      "[epoch 23, iterations:    80] loss: 4.760\n",
      "[epoch 23, iterations:    85] loss: 4.963\n",
      "[epoch 23, iterations:    90] loss: 4.707\n",
      "[epoch 23, iterations:    95] loss: 4.883\n",
      "[epoch 23, iterations:   100] loss: 4.802\n",
      "[epoch 23, iterations:   105] loss: 4.894\n",
      "[epoch 23, iterations:   110] loss: 4.768\n",
      "[epoch 23, iterations:   115] loss: 4.590\n",
      "[epoch 23, iterations:   120] loss: 3.497\n",
      "[epoch 23, iterations:   125] loss: 4.041\n",
      "[epoch 23, iterations:   130] loss: 3.896\n",
      "[epoch 23, iterations:   135] loss: 2.730\n",
      "[epoch 23, iterations:   140] loss: 1.880\n",
      "[epoch 23, iterations:   145] loss: 2.322\n",
      "[epoch 23, iterations:   150] loss: 2.582\n",
      "[epoch 23, iterations:   155] loss: 3.497\n",
      "[epoch 23, iterations:   160] loss: 3.799\n",
      "[epoch 23, iterations:   165] loss: 3.075\n",
      "[epoch 23, iterations:   170] loss: 2.426\n",
      "[epoch 23, iterations:   175] loss: 3.903\n",
      "[epoch 23, iterations:   180] loss: 2.626\n",
      "[epoch 23, iterations:   185] loss: 4.021\n",
      "[epoch 23, iterations:   190] loss: 3.468\n",
      "[epoch 23, iterations:   195] loss: 2.724\n",
      "[epoch 23, iterations:   200] loss: 2.841\n",
      "[epoch 23, iterations:   205] loss: 3.450\n",
      "[epoch 23, iterations:   210] loss: 4.433\n",
      "[epoch 23, iterations:   215] loss: 4.321\n",
      "[epoch 23, iterations:   220] loss: 3.775\n",
      "[epoch 23, iterations:   225] loss: 3.208\n",
      "[epoch 23, iterations:   230] loss: 3.408\n",
      "[epoch 23, iterations:   235] loss: 3.212\n",
      "[epoch 23, iterations:   240] loss: 3.082\n",
      "[epoch 23, iterations:   245] loss: 2.769\n",
      "[epoch 23, iterations:   250] loss: 2.731\n",
      "[epoch 23, iterations:   255] loss: 2.771\n",
      "[epoch 23, iterations:   260] loss: 3.092\n",
      "[epoch 23, iterations:   265] loss: 2.914\n",
      "[epoch 23, iterations:   270] loss: 3.561\n",
      "[epoch 23, iterations:   275] loss: 3.550\n",
      "[epoch 23, iterations:   280] loss: 3.862\n",
      "[epoch 23, iterations:   285] loss: 4.701\n",
      "[epoch 23, iterations:   290] loss: 4.420\n",
      "[epoch 23, iterations:   295] loss: 4.609\n",
      "[epoch 23, iterations:   300] loss: 3.476\n",
      "[epoch 23, iterations:   305] loss: 3.376\n",
      "[epoch 23, iterations:   310] loss: 3.507\n",
      "[epoch 23, iterations:   315] loss: 2.807\n",
      "[epoch 23, iterations:   320] loss: 3.220\n",
      "[epoch 23, iterations:   325] loss: 3.405\n",
      "[epoch 23, iterations:   330] loss: 3.019\n",
      "[epoch 23, iterations:   335] loss: 2.612\n",
      "[epoch 23, iterations:   340] loss: 3.114\n",
      "[epoch 23, iterations:   345] loss: 4.147\n",
      "[epoch 23, iterations:   350] loss: 3.214\n",
      "[epoch 23, iterations:   355] loss: 4.484\n",
      "[epoch 23, iterations:   360] loss: 4.391\n",
      "[epoch 23, iterations:   365] loss: 3.848\n",
      "[epoch 23, iterations:   370] loss: 3.442\n",
      "[epoch 23, iterations:   375] loss: 2.577\n",
      "[epoch 23, iterations:   380] loss: 2.673\n",
      "[epoch 23, iterations:   385] loss: 2.270\n",
      "[epoch 23, iterations:   390] loss: 4.056\n",
      "[epoch 23, iterations:   395] loss: 3.171\n",
      "[epoch 23, iterations:   400] loss: 3.830\n",
      "[epoch 24, iterations:     5] loss: 3.099\n",
      "[epoch 24, iterations:    10] loss: 3.209\n",
      "[epoch 24, iterations:    15] loss: 2.900\n",
      "[epoch 24, iterations:    20] loss: 2.595\n",
      "[epoch 24, iterations:    25] loss: 2.649\n",
      "[epoch 24, iterations:    30] loss: 2.265\n",
      "[epoch 24, iterations:    35] loss: 1.991\n",
      "[epoch 24, iterations:    40] loss: 2.549\n",
      "[epoch 24, iterations:    45] loss: 2.628\n",
      "[epoch 24, iterations:    50] loss: 2.723\n",
      "[epoch 24, iterations:    55] loss: 2.108\n",
      "[epoch 24, iterations:    60] loss: 1.860\n",
      "[epoch 24, iterations:    65] loss: 1.660\n",
      "[epoch 24, iterations:    70] loss: 1.979\n",
      "[epoch 24, iterations:    75] loss: 1.654\n",
      "[epoch 24, iterations:    80] loss: 2.011\n",
      "[epoch 24, iterations:    85] loss: 2.204\n",
      "[epoch 24, iterations:    90] loss: 2.161\n",
      "[epoch 24, iterations:    95] loss: 3.335\n",
      "[epoch 24, iterations:   100] loss: 1.936\n",
      "[epoch 24, iterations:   105] loss: 1.687\n",
      "[epoch 24, iterations:   110] loss: 2.395\n",
      "[epoch 24, iterations:   115] loss: 3.028\n",
      "[epoch 24, iterations:   120] loss: 2.920\n",
      "[epoch 24, iterations:   125] loss: 2.458\n",
      "[epoch 24, iterations:   130] loss: 2.049\n",
      "[epoch 24, iterations:   135] loss: 1.961\n",
      "[epoch 24, iterations:   140] loss: 2.069\n",
      "[epoch 24, iterations:   145] loss: 1.878\n",
      "[epoch 24, iterations:   150] loss: 1.712\n",
      "[epoch 24, iterations:   155] loss: 2.092\n",
      "[epoch 24, iterations:   160] loss: 1.933\n",
      "[epoch 24, iterations:   165] loss: 1.761\n",
      "[epoch 24, iterations:   170] loss: 3.638\n",
      "[epoch 24, iterations:   175] loss: 2.864\n",
      "[epoch 24, iterations:   180] loss: 2.699\n",
      "[epoch 24, iterations:   185] loss: 2.740\n",
      "[epoch 24, iterations:   190] loss: 2.072\n",
      "[epoch 24, iterations:   195] loss: 1.961\n",
      "[epoch 24, iterations:   200] loss: 2.831\n",
      "[epoch 24, iterations:   205] loss: 2.177\n",
      "[epoch 24, iterations:   210] loss: 2.881\n",
      "[epoch 24, iterations:   215] loss: 2.956\n",
      "[epoch 24, iterations:   220] loss: 3.381\n",
      "[epoch 24, iterations:   225] loss: 2.603\n",
      "[epoch 24, iterations:   230] loss: 1.712\n",
      "[epoch 24, iterations:   235] loss: 2.213\n",
      "[epoch 24, iterations:   240] loss: 2.393\n",
      "[epoch 24, iterations:   245] loss: 2.905\n",
      "[epoch 24, iterations:   250] loss: 3.825\n",
      "[epoch 24, iterations:   255] loss: 2.331\n",
      "[epoch 24, iterations:   260] loss: 2.093\n",
      "[epoch 24, iterations:   265] loss: 2.272\n",
      "[epoch 24, iterations:   270] loss: 1.890\n",
      "[epoch 24, iterations:   275] loss: 1.469\n",
      "[epoch 24, iterations:   280] loss: 1.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24, iterations:   285] loss: 3.499\n",
      "[epoch 24, iterations:   290] loss: 2.693\n",
      "[epoch 24, iterations:   295] loss: 3.968\n",
      "[epoch 24, iterations:   300] loss: 2.902\n",
      "[epoch 24, iterations:   305] loss: 3.021\n",
      "[epoch 24, iterations:   310] loss: 2.921\n",
      "[epoch 24, iterations:   315] loss: 2.391\n",
      "[epoch 24, iterations:   320] loss: 2.000\n",
      "[epoch 24, iterations:   325] loss: 1.550\n",
      "[epoch 24, iterations:   330] loss: 1.857\n",
      "[epoch 24, iterations:   335] loss: 2.249\n",
      "[epoch 24, iterations:   340] loss: 3.683\n",
      "[epoch 24, iterations:   345] loss: 4.295\n",
      "[epoch 24, iterations:   350] loss: 2.998\n",
      "[epoch 24, iterations:   355] loss: 4.588\n",
      "[epoch 24, iterations:   360] loss: 4.545\n",
      "[epoch 24, iterations:   365] loss: 4.087\n",
      "[epoch 24, iterations:   370] loss: 4.047\n",
      "[epoch 24, iterations:   375] loss: 3.278\n",
      "[epoch 24, iterations:   380] loss: 3.931\n",
      "[epoch 24, iterations:   385] loss: 3.517\n",
      "[epoch 24, iterations:   390] loss: 3.394\n",
      "[epoch 24, iterations:   395] loss: 2.832\n",
      "[epoch 24, iterations:   400] loss: 1.782\n",
      "[epoch 25, iterations:     5] loss: 2.189\n",
      "[epoch 25, iterations:    10] loss: 2.246\n",
      "[epoch 25, iterations:    15] loss: 2.835\n",
      "[epoch 25, iterations:    20] loss: 2.326\n",
      "[epoch 25, iterations:    25] loss: 3.016\n",
      "[epoch 25, iterations:    30] loss: 2.085\n",
      "[epoch 25, iterations:    35] loss: 2.325\n",
      "[epoch 25, iterations:    40] loss: 2.568\n",
      "[epoch 25, iterations:    45] loss: 1.473\n",
      "[epoch 25, iterations:    50] loss: 2.157\n",
      "[epoch 25, iterations:    55] loss: 2.036\n",
      "[epoch 25, iterations:    60] loss: 1.714\n",
      "[epoch 25, iterations:    65] loss: 1.331\n",
      "[epoch 25, iterations:    70] loss: 1.642\n",
      "[epoch 25, iterations:    75] loss: 1.887\n",
      "[epoch 25, iterations:    80] loss: 1.617\n",
      "[epoch 25, iterations:    85] loss: 1.733\n",
      "[epoch 25, iterations:    90] loss: 1.913\n",
      "[epoch 25, iterations:    95] loss: 2.062\n",
      "[epoch 25, iterations:   100] loss: 2.986\n",
      "[epoch 25, iterations:   105] loss: 2.621\n",
      "[epoch 25, iterations:   110] loss: 3.085\n",
      "[epoch 25, iterations:   115] loss: 2.967\n",
      "[epoch 25, iterations:   120] loss: 2.186\n",
      "[epoch 25, iterations:   125] loss: 2.060\n",
      "[epoch 25, iterations:   130] loss: 3.155\n",
      "[epoch 25, iterations:   135] loss: 3.615\n",
      "[epoch 25, iterations:   140] loss: 2.171\n",
      "[epoch 25, iterations:   145] loss: 2.859\n",
      "[epoch 25, iterations:   150] loss: 2.543\n",
      "[epoch 25, iterations:   155] loss: 2.071\n",
      "[epoch 25, iterations:   160] loss: 2.237\n",
      "[epoch 25, iterations:   165] loss: 3.823\n",
      "[epoch 25, iterations:   170] loss: 3.687\n",
      "[epoch 25, iterations:   175] loss: 2.473\n",
      "[epoch 25, iterations:   180] loss: 3.440\n",
      "[epoch 25, iterations:   185] loss: 2.188\n",
      "[epoch 25, iterations:   190] loss: 2.549\n",
      "[epoch 25, iterations:   195] loss: 1.855\n",
      "[epoch 25, iterations:   200] loss: 1.740\n",
      "[epoch 25, iterations:   205] loss: 1.529\n",
      "[epoch 25, iterations:   210] loss: 1.825\n",
      "[epoch 25, iterations:   215] loss: 2.649\n",
      "[epoch 25, iterations:   220] loss: 2.099\n",
      "[epoch 25, iterations:   225] loss: 2.837\n",
      "[epoch 25, iterations:   230] loss: 2.355\n",
      "[epoch 25, iterations:   235] loss: 2.835\n",
      "[epoch 25, iterations:   240] loss: 2.995\n",
      "[epoch 25, iterations:   245] loss: 1.710\n",
      "[epoch 25, iterations:   250] loss: 1.986\n",
      "[epoch 25, iterations:   255] loss: 1.348\n",
      "[epoch 25, iterations:   260] loss: 1.965\n",
      "[epoch 25, iterations:   265] loss: 1.394\n",
      "[epoch 25, iterations:   270] loss: 2.004\n",
      "[epoch 25, iterations:   275] loss: 2.005\n",
      "[epoch 25, iterations:   280] loss: 1.376\n",
      "[epoch 25, iterations:   285] loss: 1.228\n",
      "[epoch 25, iterations:   290] loss: 1.881\n",
      "[epoch 25, iterations:   295] loss: 1.247\n",
      "[epoch 25, iterations:   300] loss: 3.010\n",
      "[epoch 25, iterations:   305] loss: 3.584\n",
      "[epoch 25, iterations:   310] loss: 1.598\n",
      "[epoch 25, iterations:   315] loss: 2.164\n",
      "[epoch 25, iterations:   320] loss: 2.097\n",
      "[epoch 25, iterations:   325] loss: 1.476\n",
      "[epoch 25, iterations:   330] loss: 1.678\n",
      "[epoch 25, iterations:   335] loss: 2.441\n",
      "[epoch 25, iterations:   340] loss: 2.338\n",
      "[epoch 25, iterations:   345] loss: 2.857\n",
      "[epoch 25, iterations:   350] loss: 1.816\n",
      "[epoch 25, iterations:   355] loss: 1.863\n",
      "[epoch 25, iterations:   360] loss: 1.778\n",
      "[epoch 25, iterations:   365] loss: 1.892\n",
      "[epoch 25, iterations:   370] loss: 1.667\n",
      "[epoch 25, iterations:   375] loss: 2.289\n",
      "[epoch 25, iterations:   380] loss: 1.954\n",
      "[epoch 25, iterations:   385] loss: 1.890\n",
      "[epoch 25, iterations:   390] loss: 1.347\n",
      "[epoch 25, iterations:   395] loss: 2.122\n",
      "[epoch 25, iterations:   400] loss: 1.776\n",
      "[epoch 26, iterations:     5] loss: 1.576\n",
      "[epoch 26, iterations:    10] loss: 1.543\n",
      "[epoch 26, iterations:    15] loss: 1.803\n",
      "[epoch 26, iterations:    20] loss: 1.862\n",
      "[epoch 26, iterations:    25] loss: 1.912\n",
      "[epoch 26, iterations:    30] loss: 2.219\n",
      "[epoch 26, iterations:    35] loss: 2.445\n",
      "[epoch 26, iterations:    40] loss: 2.307\n",
      "[epoch 26, iterations:    45] loss: 2.132\n",
      "[epoch 26, iterations:    50] loss: 1.672\n",
      "[epoch 26, iterations:    55] loss: 1.915\n",
      "[epoch 26, iterations:    60] loss: 1.776\n",
      "[epoch 26, iterations:    65] loss: 1.456\n",
      "[epoch 26, iterations:    70] loss: 1.836\n",
      "[epoch 26, iterations:    75] loss: 1.691\n",
      "[epoch 26, iterations:    80] loss: 2.938\n",
      "[epoch 26, iterations:    85] loss: 4.619\n",
      "[epoch 26, iterations:    90] loss: 4.495\n",
      "[epoch 26, iterations:    95] loss: 4.755\n",
      "[epoch 26, iterations:   100] loss: 4.925\n",
      "[epoch 26, iterations:   105] loss: 4.560\n",
      "[epoch 26, iterations:   110] loss: 4.431\n",
      "[epoch 26, iterations:   115] loss: 4.394\n",
      "[epoch 26, iterations:   120] loss: 4.270\n",
      "[epoch 26, iterations:   125] loss: 3.740\n",
      "[epoch 26, iterations:   130] loss: 2.593\n",
      "[epoch 26, iterations:   135] loss: 3.765\n",
      "[epoch 26, iterations:   140] loss: 3.633\n",
      "[epoch 26, iterations:   145] loss: 2.843\n",
      "[epoch 26, iterations:   150] loss: 2.426\n",
      "[epoch 26, iterations:   155] loss: 2.026\n",
      "[epoch 26, iterations:   160] loss: 2.133\n",
      "[epoch 26, iterations:   165] loss: 1.963\n",
      "[epoch 26, iterations:   170] loss: 2.015\n",
      "[epoch 26, iterations:   175] loss: 1.489\n",
      "[epoch 26, iterations:   180] loss: 1.351\n",
      "[epoch 26, iterations:   185] loss: 1.529\n",
      "[epoch 26, iterations:   190] loss: 1.376\n",
      "[epoch 26, iterations:   195] loss: 1.123\n",
      "[epoch 26, iterations:   200] loss: 2.236\n",
      "[epoch 26, iterations:   205] loss: 4.397\n",
      "[epoch 26, iterations:   210] loss: 4.529\n",
      "[epoch 26, iterations:   215] loss: 4.475\n",
      "[epoch 26, iterations:   220] loss: 4.188\n",
      "[epoch 26, iterations:   225] loss: 2.621\n",
      "[epoch 26, iterations:   230] loss: 3.424\n",
      "[epoch 26, iterations:   235] loss: 2.932\n",
      "[epoch 26, iterations:   240] loss: 2.492\n",
      "[epoch 26, iterations:   245] loss: 1.426\n",
      "[epoch 26, iterations:   250] loss: 1.775\n",
      "[epoch 26, iterations:   255] loss: 1.544\n",
      "[epoch 26, iterations:   260] loss: 1.463\n",
      "[epoch 26, iterations:   265] loss: 1.787\n",
      "[epoch 26, iterations:   270] loss: 1.227\n",
      "[epoch 26, iterations:   275] loss: 1.455\n",
      "[epoch 26, iterations:   280] loss: 1.548\n",
      "[epoch 26, iterations:   285] loss: 1.282\n",
      "[epoch 26, iterations:   290] loss: 1.186\n",
      "[epoch 26, iterations:   295] loss: 1.604\n",
      "[epoch 26, iterations:   300] loss: 1.893\n",
      "[epoch 26, iterations:   305] loss: 1.810\n",
      "[epoch 26, iterations:   310] loss: 2.216\n",
      "[epoch 26, iterations:   315] loss: 1.528\n",
      "[epoch 26, iterations:   320] loss: 1.408\n",
      "[epoch 26, iterations:   325] loss: 1.190\n",
      "[epoch 26, iterations:   330] loss: 1.274\n",
      "[epoch 26, iterations:   335] loss: 1.497\n",
      "[epoch 26, iterations:   340] loss: 1.698\n",
      "[epoch 26, iterations:   345] loss: 3.298\n",
      "[epoch 26, iterations:   350] loss: 3.531\n",
      "[epoch 26, iterations:   355] loss: 4.572\n",
      "[epoch 26, iterations:   360] loss: 4.074\n",
      "[epoch 26, iterations:   365] loss: 4.237\n",
      "[epoch 26, iterations:   370] loss: 3.516\n",
      "[epoch 26, iterations:   375] loss: 2.190\n",
      "[epoch 26, iterations:   380] loss: 1.712\n",
      "[epoch 26, iterations:   385] loss: 1.091\n",
      "[epoch 26, iterations:   390] loss: 1.374\n",
      "[epoch 26, iterations:   395] loss: 1.203\n",
      "[epoch 26, iterations:   400] loss: 1.257\n",
      "[epoch 27, iterations:     5] loss: 1.072\n",
      "[epoch 27, iterations:    10] loss: 1.955\n",
      "[epoch 27, iterations:    15] loss: 1.653\n",
      "[epoch 27, iterations:    20] loss: 1.695\n",
      "[epoch 27, iterations:    25] loss: 1.381\n",
      "[epoch 27, iterations:    30] loss: 1.868\n",
      "[epoch 27, iterations:    35] loss: 2.176\n",
      "[epoch 27, iterations:    40] loss: 2.300\n",
      "[epoch 27, iterations:    45] loss: 1.803\n",
      "[epoch 27, iterations:    50] loss: 1.632\n",
      "[epoch 27, iterations:    55] loss: 2.332\n",
      "[epoch 27, iterations:    60] loss: 2.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 27, iterations:    65] loss: 2.239\n",
      "[epoch 27, iterations:    70] loss: 1.899\n",
      "[epoch 27, iterations:    75] loss: 1.496\n",
      "[epoch 27, iterations:    80] loss: 1.801\n",
      "[epoch 27, iterations:    85] loss: 1.851\n",
      "[epoch 27, iterations:    90] loss: 1.324\n",
      "[epoch 27, iterations:    95] loss: 1.625\n",
      "[epoch 27, iterations:   100] loss: 1.553\n",
      "[epoch 27, iterations:   105] loss: 1.791\n",
      "[epoch 27, iterations:   110] loss: 1.875\n",
      "[epoch 27, iterations:   115] loss: 1.539\n",
      "[epoch 27, iterations:   120] loss: 1.314\n",
      "[epoch 27, iterations:   125] loss: 1.104\n",
      "[epoch 27, iterations:   130] loss: 1.662\n",
      "[epoch 27, iterations:   135] loss: 2.124\n",
      "[epoch 27, iterations:   140] loss: 1.073\n",
      "[epoch 27, iterations:   145] loss: 1.741\n",
      "[epoch 27, iterations:   150] loss: 1.855\n",
      "[epoch 27, iterations:   155] loss: 1.566\n",
      "[epoch 27, iterations:   160] loss: 1.131\n",
      "[epoch 27, iterations:   165] loss: 2.053\n",
      "[epoch 27, iterations:   170] loss: 1.795\n",
      "[epoch 27, iterations:   175] loss: 1.128\n",
      "[epoch 27, iterations:   180] loss: 1.587\n",
      "[epoch 27, iterations:   185] loss: 1.573\n",
      "[epoch 27, iterations:   190] loss: 1.338\n",
      "[epoch 27, iterations:   195] loss: 1.384\n",
      "[epoch 27, iterations:   200] loss: 1.154\n",
      "[epoch 27, iterations:   205] loss: 1.437\n",
      "[epoch 27, iterations:   210] loss: 1.464\n",
      "[epoch 27, iterations:   215] loss: 1.773\n",
      "[epoch 27, iterations:   220] loss: 1.894\n",
      "[epoch 27, iterations:   225] loss: 1.494\n",
      "[epoch 27, iterations:   230] loss: 1.695\n",
      "[epoch 27, iterations:   235] loss: 1.512\n",
      "[epoch 27, iterations:   240] loss: 1.024\n",
      "[epoch 27, iterations:   245] loss: 1.281\n",
      "[epoch 27, iterations:   250] loss: 1.088\n",
      "[epoch 27, iterations:   255] loss: 1.254\n",
      "[epoch 27, iterations:   260] loss: 4.407\n",
      "[epoch 27, iterations:   265] loss: 5.181\n",
      "[epoch 27, iterations:   270] loss: 1.485\n",
      "[epoch 27, iterations:   275] loss: 1.881\n",
      "[epoch 27, iterations:   280] loss: 1.824\n",
      "[epoch 27, iterations:   285] loss: 1.304\n",
      "[epoch 27, iterations:   290] loss: 1.853\n",
      "[epoch 27, iterations:   295] loss: 1.697\n",
      "[epoch 27, iterations:   300] loss: 1.440\n",
      "[epoch 27, iterations:   305] loss: 1.540\n",
      "[epoch 27, iterations:   310] loss: 0.991\n",
      "[epoch 27, iterations:   315] loss: 0.850\n",
      "[epoch 27, iterations:   320] loss: 0.965\n",
      "[epoch 27, iterations:   325] loss: 1.638\n",
      "[epoch 27, iterations:   330] loss: 1.298\n",
      "[epoch 27, iterations:   335] loss: 1.675\n",
      "[epoch 27, iterations:   340] loss: 2.594\n",
      "[epoch 27, iterations:   345] loss: 1.075\n",
      "[epoch 27, iterations:   350] loss: 1.133\n",
      "[epoch 27, iterations:   355] loss: 1.190\n",
      "[epoch 27, iterations:   360] loss: 1.206\n",
      "[epoch 27, iterations:   365] loss: 1.448\n",
      "[epoch 27, iterations:   370] loss: 1.996\n",
      "[epoch 27, iterations:   375] loss: 1.487\n",
      "[epoch 27, iterations:   380] loss: 2.414\n",
      "[epoch 27, iterations:   385] loss: 1.634\n",
      "[epoch 27, iterations:   390] loss: 2.268\n",
      "[epoch 27, iterations:   395] loss: 1.067\n",
      "[epoch 27, iterations:   400] loss: 0.876\n",
      "[epoch 28, iterations:     5] loss: 1.336\n",
      "[epoch 28, iterations:    10] loss: 1.654\n",
      "[epoch 28, iterations:    15] loss: 1.021\n",
      "[epoch 28, iterations:    20] loss: 1.444\n",
      "[epoch 28, iterations:    25] loss: 1.073\n",
      "[epoch 28, iterations:    30] loss: 1.693\n",
      "[epoch 28, iterations:    35] loss: 0.984\n",
      "[epoch 28, iterations:    40] loss: 1.512\n",
      "[epoch 28, iterations:    45] loss: 1.170\n",
      "[epoch 28, iterations:    50] loss: 1.389\n",
      "[epoch 28, iterations:    55] loss: 1.152\n",
      "[epoch 28, iterations:    60] loss: 1.645\n",
      "[epoch 28, iterations:    65] loss: 1.917\n",
      "[epoch 28, iterations:    70] loss: 1.785\n",
      "[epoch 28, iterations:    75] loss: 2.623\n",
      "[epoch 28, iterations:    80] loss: 2.039\n",
      "[epoch 28, iterations:    85] loss: 1.771\n",
      "[epoch 28, iterations:    90] loss: 1.740\n",
      "[epoch 28, iterations:    95] loss: 1.365\n",
      "[epoch 28, iterations:   100] loss: 1.135\n",
      "[epoch 28, iterations:   105] loss: 1.181\n",
      "[epoch 28, iterations:   110] loss: 1.917\n",
      "[epoch 28, iterations:   115] loss: 1.067\n",
      "[epoch 28, iterations:   120] loss: 0.899\n",
      "[epoch 28, iterations:   125] loss: 1.663\n",
      "[epoch 28, iterations:   130] loss: 1.737\n",
      "[epoch 28, iterations:   135] loss: 1.981\n",
      "[epoch 28, iterations:   140] loss: 1.963\n",
      "[epoch 28, iterations:   145] loss: 1.205\n",
      "[epoch 28, iterations:   150] loss: 1.207\n",
      "[epoch 28, iterations:   155] loss: 1.225\n",
      "[epoch 28, iterations:   160] loss: 1.870\n",
      "[epoch 28, iterations:   165] loss: 2.855\n",
      "[epoch 28, iterations:   170] loss: 2.023\n",
      "[epoch 28, iterations:   175] loss: 2.475\n",
      "[epoch 28, iterations:   180] loss: 1.801\n",
      "[epoch 28, iterations:   185] loss: 2.337\n",
      "[epoch 28, iterations:   190] loss: 1.771\n",
      "[epoch 28, iterations:   195] loss: 1.675\n",
      "[epoch 28, iterations:   200] loss: 1.101\n",
      "[epoch 28, iterations:   205] loss: 1.317\n",
      "[epoch 28, iterations:   210] loss: 0.964\n",
      "[epoch 28, iterations:   215] loss: 1.462\n",
      "[epoch 28, iterations:   220] loss: 2.520\n",
      "[epoch 28, iterations:   225] loss: 2.220\n",
      "[epoch 28, iterations:   230] loss: 1.041\n",
      "[epoch 28, iterations:   235] loss: 1.330\n",
      "[epoch 28, iterations:   240] loss: 1.459\n",
      "[epoch 28, iterations:   245] loss: 1.891\n",
      "[epoch 28, iterations:   250] loss: 1.254\n",
      "[epoch 28, iterations:   255] loss: 1.201\n",
      "[epoch 28, iterations:   260] loss: 1.446\n",
      "[epoch 28, iterations:   265] loss: 1.196\n",
      "[epoch 28, iterations:   270] loss: 1.161\n",
      "[epoch 28, iterations:   275] loss: 0.922\n",
      "[epoch 28, iterations:   280] loss: 1.507\n",
      "[epoch 28, iterations:   285] loss: 1.406\n",
      "[epoch 28, iterations:   290] loss: 1.379\n",
      "[epoch 28, iterations:   295] loss: 0.965\n",
      "[epoch 28, iterations:   300] loss: 2.095\n",
      "[epoch 28, iterations:   305] loss: 1.818\n",
      "[epoch 28, iterations:   310] loss: 2.020\n",
      "[epoch 28, iterations:   315] loss: 2.013\n",
      "[epoch 28, iterations:   320] loss: 1.503\n",
      "[epoch 28, iterations:   325] loss: 0.704\n",
      "[epoch 28, iterations:   330] loss: 1.136\n",
      "[epoch 28, iterations:   335] loss: 2.089\n",
      "[epoch 28, iterations:   340] loss: 1.333\n",
      "[epoch 28, iterations:   345] loss: 1.271\n",
      "[epoch 28, iterations:   350] loss: 1.940\n",
      "[epoch 28, iterations:   355] loss: 1.116\n",
      "[epoch 28, iterations:   360] loss: 0.884\n",
      "[epoch 28, iterations:   365] loss: 0.464\n",
      "[epoch 28, iterations:   370] loss: 1.026\n",
      "[epoch 28, iterations:   375] loss: 0.991\n",
      "[epoch 28, iterations:   380] loss: 0.820\n",
      "[epoch 28, iterations:   385] loss: 1.214\n",
      "[epoch 28, iterations:   390] loss: 1.196\n",
      "[epoch 28, iterations:   395] loss: 1.249\n",
      "[epoch 28, iterations:   400] loss: 1.396\n",
      "[epoch 29, iterations:     5] loss: 1.520\n",
      "[epoch 29, iterations:    10] loss: 1.201\n",
      "[epoch 29, iterations:    15] loss: 1.074\n",
      "[epoch 29, iterations:    20] loss: 1.243\n",
      "[epoch 29, iterations:    25] loss: 1.428\n",
      "[epoch 29, iterations:    30] loss: 1.726\n",
      "[epoch 29, iterations:    35] loss: 0.949\n",
      "[epoch 29, iterations:    40] loss: 1.326\n",
      "[epoch 29, iterations:    45] loss: 1.569\n",
      "[epoch 29, iterations:    50] loss: 1.550\n",
      "[epoch 29, iterations:    55] loss: 1.629\n",
      "[epoch 29, iterations:    60] loss: 1.238\n",
      "[epoch 29, iterations:    65] loss: 1.130\n",
      "[epoch 29, iterations:    70] loss: 1.196\n",
      "[epoch 29, iterations:    75] loss: 0.894\n",
      "[epoch 29, iterations:    80] loss: 1.089\n",
      "[epoch 29, iterations:    85] loss: 1.556\n",
      "[epoch 29, iterations:    90] loss: 0.629\n",
      "[epoch 29, iterations:    95] loss: 0.911\n",
      "[epoch 29, iterations:   100] loss: 0.464\n",
      "[epoch 29, iterations:   105] loss: 1.609\n",
      "[epoch 29, iterations:   110] loss: 1.152\n",
      "[epoch 29, iterations:   115] loss: 0.933\n",
      "[epoch 29, iterations:   120] loss: 0.950\n",
      "[epoch 29, iterations:   125] loss: 1.058\n",
      "[epoch 29, iterations:   130] loss: 0.648\n",
      "[epoch 29, iterations:   135] loss: 1.735\n",
      "[epoch 29, iterations:   140] loss: 1.826\n",
      "[epoch 29, iterations:   145] loss: 1.453\n",
      "[epoch 29, iterations:   150] loss: 1.703\n",
      "[epoch 29, iterations:   155] loss: 2.071\n",
      "[epoch 29, iterations:   160] loss: 1.854\n",
      "[epoch 29, iterations:   165] loss: 0.891\n",
      "[epoch 29, iterations:   170] loss: 0.543\n",
      "[epoch 29, iterations:   175] loss: 0.794\n",
      "[epoch 29, iterations:   180] loss: 2.178\n",
      "[epoch 29, iterations:   185] loss: 1.613\n",
      "[epoch 29, iterations:   190] loss: 1.661\n",
      "[epoch 29, iterations:   195] loss: 2.286\n",
      "[epoch 29, iterations:   200] loss: 1.862\n",
      "[epoch 29, iterations:   205] loss: 1.227\n",
      "[epoch 29, iterations:   210] loss: 0.780\n",
      "[epoch 29, iterations:   215] loss: 1.304\n",
      "[epoch 29, iterations:   220] loss: 1.262\n",
      "[epoch 29, iterations:   225] loss: 1.968\n",
      "[epoch 29, iterations:   230] loss: 1.362\n",
      "[epoch 29, iterations:   235] loss: 1.781\n",
      "[epoch 29, iterations:   240] loss: 1.401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 29, iterations:   245] loss: 1.861\n",
      "[epoch 29, iterations:   250] loss: 1.787\n",
      "[epoch 29, iterations:   255] loss: 1.111\n",
      "[epoch 29, iterations:   260] loss: 0.901\n",
      "[epoch 29, iterations:   265] loss: 0.963\n",
      "[epoch 29, iterations:   270] loss: 0.974\n",
      "[epoch 29, iterations:   275] loss: 1.920\n",
      "[epoch 29, iterations:   280] loss: 2.238\n",
      "[epoch 29, iterations:   285] loss: 2.798\n",
      "[epoch 29, iterations:   290] loss: 1.236\n",
      "[epoch 29, iterations:   295] loss: 1.721\n",
      "[epoch 29, iterations:   300] loss: 0.975\n",
      "[epoch 29, iterations:   305] loss: 1.279\n",
      "[epoch 29, iterations:   310] loss: 1.310\n",
      "[epoch 29, iterations:   315] loss: 1.555\n",
      "[epoch 29, iterations:   320] loss: 1.085\n",
      "[epoch 29, iterations:   325] loss: 0.587\n",
      "[epoch 29, iterations:   330] loss: 0.644\n",
      "[epoch 29, iterations:   335] loss: 1.506\n",
      "[epoch 29, iterations:   340] loss: 1.088\n",
      "[epoch 29, iterations:   345] loss: 0.982\n",
      "[epoch 29, iterations:   350] loss: 1.217\n",
      "[epoch 29, iterations:   355] loss: 1.111\n",
      "[epoch 29, iterations:   360] loss: 1.035\n",
      "[epoch 29, iterations:   365] loss: 1.208\n",
      "[epoch 29, iterations:   370] loss: 1.421\n",
      "[epoch 29, iterations:   375] loss: 0.708\n",
      "[epoch 29, iterations:   380] loss: 0.963\n",
      "[epoch 29, iterations:   385] loss: 0.871\n",
      "[epoch 29, iterations:   390] loss: 0.905\n",
      "[epoch 29, iterations:   395] loss: 1.247\n",
      "[epoch 29, iterations:   400] loss: 0.914\n",
      "[epoch 30, iterations:     5] loss: 1.623\n",
      "[epoch 30, iterations:    10] loss: 0.907\n",
      "[epoch 30, iterations:    15] loss: 1.247\n",
      "[epoch 30, iterations:    20] loss: 1.853\n",
      "[epoch 30, iterations:    25] loss: 1.318\n",
      "[epoch 30, iterations:    30] loss: 1.588\n",
      "[epoch 30, iterations:    35] loss: 1.843\n",
      "[epoch 30, iterations:    40] loss: 1.247\n",
      "[epoch 30, iterations:    45] loss: 1.046\n",
      "[epoch 30, iterations:    50] loss: 1.288\n",
      "[epoch 30, iterations:    55] loss: 2.405\n",
      "[epoch 30, iterations:    60] loss: 1.238\n",
      "[epoch 30, iterations:    65] loss: 0.780\n",
      "[epoch 30, iterations:    70] loss: 0.909\n",
      "[epoch 30, iterations:    75] loss: 0.850\n",
      "[epoch 30, iterations:    80] loss: 1.479\n",
      "[epoch 30, iterations:    85] loss: 0.871\n",
      "[epoch 30, iterations:    90] loss: 1.052\n",
      "[epoch 30, iterations:    95] loss: 1.085\n",
      "[epoch 30, iterations:   100] loss: 0.803\n",
      "[epoch 30, iterations:   105] loss: 0.840\n",
      "[epoch 30, iterations:   110] loss: 1.091\n",
      "[epoch 30, iterations:   115] loss: 0.727\n",
      "[epoch 30, iterations:   120] loss: 1.828\n",
      "[epoch 30, iterations:   125] loss: 1.963\n",
      "[epoch 30, iterations:   130] loss: 0.889\n",
      "[epoch 30, iterations:   135] loss: 1.332\n",
      "[epoch 30, iterations:   140] loss: 0.889\n",
      "[epoch 30, iterations:   145] loss: 0.997\n",
      "[epoch 30, iterations:   150] loss: 0.821\n",
      "[epoch 30, iterations:   155] loss: 1.178\n",
      "[epoch 30, iterations:   160] loss: 0.796\n",
      "[epoch 30, iterations:   165] loss: 1.203\n",
      "[epoch 30, iterations:   170] loss: 0.581\n",
      "[epoch 30, iterations:   175] loss: 1.254\n",
      "[epoch 30, iterations:   180] loss: 1.717\n",
      "[epoch 30, iterations:   185] loss: 0.722\n",
      "[epoch 30, iterations:   190] loss: 0.977\n",
      "[epoch 30, iterations:   195] loss: 1.336\n",
      "[epoch 30, iterations:   200] loss: 1.058\n",
      "[epoch 30, iterations:   205] loss: 1.561\n",
      "[epoch 30, iterations:   210] loss: 0.959\n",
      "[epoch 30, iterations:   215] loss: 1.677\n",
      "[epoch 30, iterations:   220] loss: 1.468\n",
      "[epoch 30, iterations:   225] loss: 1.255\n",
      "[epoch 30, iterations:   230] loss: 0.742\n",
      "[epoch 30, iterations:   235] loss: 1.032\n",
      "[epoch 30, iterations:   240] loss: 1.245\n",
      "[epoch 30, iterations:   245] loss: 0.691\n",
      "[epoch 30, iterations:   250] loss: 1.026\n",
      "[epoch 30, iterations:   255] loss: 1.279\n",
      "[epoch 30, iterations:   260] loss: 1.359\n",
      "[epoch 30, iterations:   265] loss: 1.354\n",
      "[epoch 30, iterations:   270] loss: 0.730\n",
      "[epoch 30, iterations:   275] loss: 0.604\n",
      "[epoch 30, iterations:   280] loss: 1.125\n",
      "[epoch 30, iterations:   285] loss: 1.194\n",
      "[epoch 30, iterations:   290] loss: 1.122\n",
      "[epoch 30, iterations:   295] loss: 0.893\n",
      "[epoch 30, iterations:   300] loss: 1.182\n",
      "[epoch 30, iterations:   305] loss: 0.654\n",
      "[epoch 30, iterations:   310] loss: 1.475\n",
      "[epoch 30, iterations:   315] loss: 2.829\n",
      "[epoch 30, iterations:   320] loss: 2.871\n",
      "[epoch 30, iterations:   325] loss: 1.602\n",
      "[epoch 30, iterations:   330] loss: 1.409\n",
      "[epoch 30, iterations:   335] loss: 1.033\n",
      "[epoch 30, iterations:   340] loss: 0.967\n",
      "[epoch 30, iterations:   345] loss: 0.873\n",
      "[epoch 30, iterations:   350] loss: 0.723\n",
      "[epoch 30, iterations:   355] loss: 0.921\n",
      "[epoch 30, iterations:   360] loss: 0.844\n",
      "[epoch 30, iterations:   365] loss: 1.213\n",
      "[epoch 30, iterations:   370] loss: 1.618\n",
      "[epoch 30, iterations:   375] loss: 3.048\n",
      "[epoch 30, iterations:   380] loss: 3.029\n",
      "[epoch 30, iterations:   385] loss: 1.411\n",
      "[epoch 30, iterations:   390] loss: 2.036\n",
      "[epoch 30, iterations:   395] loss: 2.512\n",
      "[epoch 30, iterations:   400] loss: 2.458\n",
      "[epoch 31, iterations:     5] loss: 2.785\n",
      "[epoch 31, iterations:    10] loss: 2.494\n",
      "[epoch 31, iterations:    15] loss: 1.633\n",
      "[epoch 31, iterations:    20] loss: 2.366\n",
      "[epoch 31, iterations:    25] loss: 1.324\n",
      "[epoch 31, iterations:    30] loss: 0.784\n",
      "[epoch 31, iterations:    35] loss: 0.990\n",
      "[epoch 31, iterations:    40] loss: 0.955\n",
      "[epoch 31, iterations:    45] loss: 1.090\n",
      "[epoch 31, iterations:    50] loss: 1.527\n",
      "[epoch 31, iterations:    55] loss: 0.709\n",
      "[epoch 31, iterations:    60] loss: 0.893\n",
      "[epoch 31, iterations:    65] loss: 1.315\n",
      "[epoch 31, iterations:    70] loss: 0.916\n",
      "[epoch 31, iterations:    75] loss: 1.242\n",
      "[epoch 31, iterations:    80] loss: 2.019\n",
      "[epoch 31, iterations:    85] loss: 2.175\n",
      "[epoch 31, iterations:    90] loss: 2.556\n",
      "[epoch 31, iterations:    95] loss: 1.766\n",
      "[epoch 31, iterations:   100] loss: 1.528\n",
      "[epoch 31, iterations:   105] loss: 1.129\n",
      "[epoch 31, iterations:   110] loss: 1.401\n",
      "[epoch 31, iterations:   115] loss: 0.939\n",
      "[epoch 31, iterations:   120] loss: 2.138\n",
      "[epoch 31, iterations:   125] loss: 1.897\n",
      "[epoch 31, iterations:   130] loss: 2.109\n",
      "[epoch 31, iterations:   135] loss: 3.607\n",
      "[epoch 31, iterations:   140] loss: 3.182\n",
      "[epoch 31, iterations:   145] loss: 1.571\n",
      "[epoch 31, iterations:   150] loss: 1.539\n",
      "[epoch 31, iterations:   155] loss: 1.308\n",
      "[epoch 31, iterations:   160] loss: 1.190\n",
      "[epoch 31, iterations:   165] loss: 1.262\n",
      "[epoch 31, iterations:   170] loss: 1.158\n",
      "[epoch 31, iterations:   175] loss: 1.100\n",
      "[epoch 31, iterations:   180] loss: 1.137\n",
      "[epoch 31, iterations:   185] loss: 1.141\n",
      "[epoch 31, iterations:   190] loss: 1.581\n",
      "[epoch 31, iterations:   195] loss: 1.113\n",
      "[epoch 31, iterations:   200] loss: 0.734\n",
      "[epoch 31, iterations:   205] loss: 1.224\n",
      "[epoch 31, iterations:   210] loss: 1.125\n",
      "[epoch 31, iterations:   215] loss: 0.994\n",
      "[epoch 31, iterations:   220] loss: 1.104\n",
      "[epoch 31, iterations:   225] loss: 1.343\n",
      "[epoch 31, iterations:   230] loss: 1.928\n",
      "[epoch 31, iterations:   235] loss: 1.955\n",
      "[epoch 31, iterations:   240] loss: 1.610\n",
      "[epoch 31, iterations:   245] loss: 1.973\n",
      "[epoch 31, iterations:   250] loss: 1.669\n",
      "[epoch 31, iterations:   255] loss: 1.564\n",
      "[epoch 31, iterations:   260] loss: 1.188\n",
      "[epoch 31, iterations:   265] loss: 0.916\n",
      "[epoch 31, iterations:   270] loss: 0.685\n",
      "[epoch 31, iterations:   275] loss: 0.954\n",
      "[epoch 31, iterations:   280] loss: 1.019\n",
      "[epoch 31, iterations:   285] loss: 0.747\n",
      "[epoch 31, iterations:   290] loss: 1.012\n",
      "[epoch 31, iterations:   295] loss: 1.417\n",
      "[epoch 31, iterations:   300] loss: 0.873\n",
      "[epoch 31, iterations:   305] loss: 0.955\n",
      "[epoch 31, iterations:   310] loss: 1.686\n",
      "[epoch 31, iterations:   315] loss: 1.727\n",
      "[epoch 31, iterations:   320] loss: 1.522\n",
      "[epoch 31, iterations:   325] loss: 1.094\n",
      "[epoch 31, iterations:   330] loss: 0.912\n",
      "[epoch 31, iterations:   335] loss: 1.046\n",
      "[epoch 31, iterations:   340] loss: 1.276\n",
      "[epoch 31, iterations:   345] loss: 1.034\n",
      "[epoch 31, iterations:   350] loss: 1.673\n",
      "[epoch 31, iterations:   355] loss: 1.680\n",
      "[epoch 31, iterations:   360] loss: 2.910\n",
      "[epoch 31, iterations:   365] loss: 1.638\n",
      "[epoch 31, iterations:   370] loss: 1.078\n",
      "[epoch 31, iterations:   375] loss: 1.131\n",
      "[epoch 31, iterations:   380] loss: 1.540\n",
      "[epoch 31, iterations:   385] loss: 1.048\n",
      "[epoch 31, iterations:   390] loss: 0.990\n",
      "[epoch 31, iterations:   395] loss: 0.961\n",
      "[epoch 31, iterations:   400] loss: 3.335\n",
      "[epoch 32, iterations:     5] loss: 3.311\n",
      "[epoch 32, iterations:    10] loss: 1.994\n",
      "[epoch 32, iterations:    15] loss: 1.253\n",
      "[epoch 32, iterations:    20] loss: 1.103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 32, iterations:    25] loss: 1.131\n",
      "[epoch 32, iterations:    30] loss: 0.984\n",
      "[epoch 32, iterations:    35] loss: 0.963\n",
      "[epoch 32, iterations:    40] loss: 0.803\n",
      "[epoch 32, iterations:    45] loss: 0.839\n",
      "[epoch 32, iterations:    50] loss: 0.769\n",
      "[epoch 32, iterations:    55] loss: 1.305\n",
      "[epoch 32, iterations:    60] loss: 0.682\n",
      "[epoch 32, iterations:    65] loss: 0.683\n",
      "[epoch 32, iterations:    70] loss: 0.982\n",
      "[epoch 32, iterations:    75] loss: 0.789\n",
      "[epoch 32, iterations:    80] loss: 1.775\n",
      "[epoch 32, iterations:    85] loss: 1.207\n",
      "[epoch 32, iterations:    90] loss: 0.844\n",
      "[epoch 32, iterations:    95] loss: 1.401\n",
      "[epoch 32, iterations:   100] loss: 0.663\n",
      "[epoch 32, iterations:   105] loss: 1.176\n",
      "[epoch 32, iterations:   110] loss: 1.118\n",
      "[epoch 32, iterations:   115] loss: 1.322\n",
      "[epoch 32, iterations:   120] loss: 0.957\n",
      "[epoch 32, iterations:   125] loss: 0.728\n",
      "[epoch 32, iterations:   130] loss: 0.605\n",
      "[epoch 32, iterations:   135] loss: 0.585\n",
      "[epoch 32, iterations:   140] loss: 1.072\n",
      "[epoch 32, iterations:   145] loss: 1.041\n",
      "[epoch 32, iterations:   150] loss: 0.894\n",
      "[epoch 32, iterations:   155] loss: 0.899\n",
      "[epoch 32, iterations:   160] loss: 0.704\n",
      "[epoch 32, iterations:   165] loss: 0.914\n",
      "[epoch 32, iterations:   170] loss: 0.631\n",
      "[epoch 32, iterations:   175] loss: 0.576\n",
      "[epoch 32, iterations:   180] loss: 0.899\n",
      "[epoch 32, iterations:   185] loss: 1.491\n",
      "[epoch 32, iterations:   190] loss: 0.775\n",
      "[epoch 32, iterations:   195] loss: 0.867\n",
      "[epoch 32, iterations:   200] loss: 0.318\n",
      "[epoch 32, iterations:   205] loss: 1.122\n",
      "[epoch 32, iterations:   210] loss: 1.753\n",
      "[epoch 32, iterations:   215] loss: 1.208\n",
      "[epoch 32, iterations:   220] loss: 0.744\n",
      "[epoch 32, iterations:   225] loss: 0.541\n",
      "[epoch 32, iterations:   230] loss: 0.853\n",
      "[epoch 32, iterations:   235] loss: 0.510\n",
      "[epoch 32, iterations:   240] loss: 0.962\n",
      "[epoch 32, iterations:   245] loss: 0.439\n",
      "[epoch 32, iterations:   250] loss: 0.396\n",
      "[epoch 32, iterations:   255] loss: 0.572\n",
      "[epoch 32, iterations:   260] loss: 0.601\n",
      "[epoch 32, iterations:   265] loss: 0.680\n",
      "[epoch 32, iterations:   270] loss: 0.595\n",
      "[epoch 32, iterations:   275] loss: 0.819\n",
      "[epoch 32, iterations:   280] loss: 0.673\n",
      "[epoch 32, iterations:   285] loss: 0.741\n",
      "[epoch 32, iterations:   290] loss: 0.850\n",
      "[epoch 32, iterations:   295] loss: 0.823\n",
      "[epoch 32, iterations:   300] loss: 0.702\n",
      "[epoch 32, iterations:   305] loss: 1.303\n",
      "[epoch 32, iterations:   310] loss: 1.033\n",
      "[epoch 32, iterations:   315] loss: 1.458\n",
      "[epoch 32, iterations:   320] loss: 1.509\n",
      "[epoch 32, iterations:   325] loss: 0.749\n",
      "[epoch 32, iterations:   330] loss: 0.630\n",
      "[epoch 32, iterations:   335] loss: 0.639\n",
      "[epoch 32, iterations:   340] loss: 0.951\n",
      "[epoch 32, iterations:   345] loss: 0.454\n",
      "[epoch 32, iterations:   350] loss: 0.501\n",
      "[epoch 32, iterations:   355] loss: 0.871\n",
      "[epoch 32, iterations:   360] loss: 1.227\n",
      "[epoch 32, iterations:   365] loss: 0.871\n",
      "[epoch 32, iterations:   370] loss: 0.774\n",
      "[epoch 32, iterations:   375] loss: 0.639\n",
      "[epoch 32, iterations:   380] loss: 1.251\n",
      "[epoch 32, iterations:   385] loss: 0.493\n",
      "[epoch 32, iterations:   390] loss: 0.637\n",
      "[epoch 32, iterations:   395] loss: 1.600\n",
      "[epoch 32, iterations:   400] loss: 1.080\n",
      "[epoch 33, iterations:     5] loss: 1.060\n",
      "[epoch 33, iterations:    10] loss: 0.499\n",
      "[epoch 33, iterations:    15] loss: 1.316\n",
      "[epoch 33, iterations:    20] loss: 0.923\n",
      "[epoch 33, iterations:    25] loss: 0.445\n",
      "[epoch 33, iterations:    30] loss: 0.987\n",
      "[epoch 33, iterations:    35] loss: 1.282\n",
      "[epoch 33, iterations:    40] loss: 1.644\n",
      "[epoch 33, iterations:    45] loss: 0.482\n",
      "[epoch 33, iterations:    50] loss: 0.832\n",
      "[epoch 33, iterations:    55] loss: 1.420\n",
      "[epoch 33, iterations:    60] loss: 0.935\n",
      "[epoch 33, iterations:    65] loss: 0.852\n",
      "[epoch 33, iterations:    70] loss: 0.511\n",
      "[epoch 33, iterations:    75] loss: 0.798\n",
      "[epoch 33, iterations:    80] loss: 0.642\n",
      "[epoch 33, iterations:    85] loss: 0.384\n",
      "[epoch 33, iterations:    90] loss: 0.490\n",
      "[epoch 33, iterations:    95] loss: 0.670\n",
      "[epoch 33, iterations:   100] loss: 2.996\n",
      "[epoch 33, iterations:   105] loss: 2.365\n",
      "[epoch 33, iterations:   110] loss: 1.989\n",
      "[epoch 33, iterations:   115] loss: 1.851\n",
      "[epoch 33, iterations:   120] loss: 1.970\n",
      "[epoch 33, iterations:   125] loss: 0.772\n",
      "[epoch 33, iterations:   130] loss: 1.488\n",
      "[epoch 33, iterations:   135] loss: 1.542\n",
      "[epoch 33, iterations:   140] loss: 0.958\n",
      "[epoch 33, iterations:   145] loss: 0.671\n",
      "[epoch 33, iterations:   150] loss: 0.581\n",
      "[epoch 33, iterations:   155] loss: 1.320\n",
      "[epoch 33, iterations:   160] loss: 0.993\n",
      "[epoch 33, iterations:   165] loss: 0.715\n",
      "[epoch 33, iterations:   170] loss: 0.675\n",
      "[epoch 33, iterations:   175] loss: 0.549\n",
      "[epoch 33, iterations:   180] loss: 0.517\n",
      "[epoch 33, iterations:   185] loss: 0.702\n",
      "[epoch 33, iterations:   190] loss: 0.618\n",
      "[epoch 33, iterations:   195] loss: 0.674\n",
      "[epoch 33, iterations:   200] loss: 0.437\n",
      "[epoch 33, iterations:   205] loss: 1.105\n",
      "[epoch 33, iterations:   210] loss: 0.946\n",
      "[epoch 33, iterations:   215] loss: 1.163\n",
      "[epoch 33, iterations:   220] loss: 0.669\n",
      "[epoch 33, iterations:   225] loss: 1.122\n",
      "[epoch 33, iterations:   230] loss: 0.894\n",
      "[epoch 33, iterations:   235] loss: 1.190\n",
      "[epoch 33, iterations:   240] loss: 1.439\n",
      "[epoch 33, iterations:   245] loss: 1.095\n",
      "[epoch 33, iterations:   250] loss: 0.831\n",
      "[epoch 33, iterations:   255] loss: 0.519\n",
      "[epoch 33, iterations:   260] loss: 0.422\n",
      "[epoch 33, iterations:   265] loss: 0.466\n",
      "[epoch 33, iterations:   270] loss: 0.363\n",
      "[epoch 33, iterations:   275] loss: 0.354\n",
      "[epoch 33, iterations:   280] loss: 0.405\n",
      "[epoch 33, iterations:   285] loss: 0.665\n",
      "[epoch 33, iterations:   290] loss: 0.679\n",
      "[epoch 33, iterations:   295] loss: 1.020\n",
      "[epoch 33, iterations:   300] loss: 0.671\n",
      "[epoch 33, iterations:   305] loss: 1.149\n",
      "[epoch 33, iterations:   310] loss: 1.169\n",
      "[epoch 33, iterations:   315] loss: 1.785\n",
      "[epoch 33, iterations:   320] loss: 0.540\n",
      "[epoch 33, iterations:   325] loss: 1.165\n",
      "[epoch 33, iterations:   330] loss: 1.529\n",
      "[epoch 33, iterations:   335] loss: 0.776\n",
      "[epoch 33, iterations:   340] loss: 0.983\n",
      "[epoch 33, iterations:   345] loss: 0.857\n",
      "[epoch 33, iterations:   350] loss: 1.404\n",
      "[epoch 33, iterations:   355] loss: 1.102\n",
      "[epoch 33, iterations:   360] loss: 1.461\n",
      "[epoch 33, iterations:   365] loss: 1.665\n",
      "[epoch 33, iterations:   370] loss: 0.897\n",
      "[epoch 33, iterations:   375] loss: 1.406\n",
      "[epoch 33, iterations:   380] loss: 1.414\n",
      "[epoch 33, iterations:   385] loss: 2.092\n",
      "[epoch 33, iterations:   390] loss: 0.788\n",
      "[epoch 33, iterations:   395] loss: 0.608\n",
      "[epoch 33, iterations:   400] loss: 0.710\n",
      "[epoch 34, iterations:     5] loss: 0.755\n",
      "[epoch 34, iterations:    10] loss: 0.662\n",
      "[epoch 34, iterations:    15] loss: 0.514\n",
      "[epoch 34, iterations:    20] loss: 0.771\n",
      "[epoch 34, iterations:    25] loss: 1.087\n",
      "[epoch 34, iterations:    30] loss: 0.689\n",
      "[epoch 34, iterations:    35] loss: 0.645\n",
      "[epoch 34, iterations:    40] loss: 0.723\n",
      "[epoch 34, iterations:    45] loss: 0.643\n",
      "[epoch 34, iterations:    50] loss: 0.677\n",
      "[epoch 34, iterations:    55] loss: 0.522\n",
      "[epoch 34, iterations:    60] loss: 0.718\n",
      "[epoch 34, iterations:    65] loss: 0.889\n",
      "[epoch 34, iterations:    70] loss: 0.831\n",
      "[epoch 34, iterations:    75] loss: 0.493\n",
      "[epoch 34, iterations:    80] loss: 0.862\n",
      "[epoch 34, iterations:    85] loss: 1.023\n",
      "[epoch 34, iterations:    90] loss: 0.754\n",
      "[epoch 34, iterations:    95] loss: 0.584\n",
      "[epoch 34, iterations:   100] loss: 0.932\n",
      "[epoch 34, iterations:   105] loss: 1.104\n",
      "[epoch 34, iterations:   110] loss: 0.849\n",
      "[epoch 34, iterations:   115] loss: 0.543\n",
      "[epoch 34, iterations:   120] loss: 0.445\n",
      "[epoch 34, iterations:   125] loss: 0.703\n",
      "[epoch 34, iterations:   130] loss: 1.132\n",
      "[epoch 34, iterations:   135] loss: 1.008\n",
      "[epoch 34, iterations:   140] loss: 0.990\n",
      "[epoch 34, iterations:   145] loss: 0.491\n",
      "[epoch 34, iterations:   150] loss: 0.634\n",
      "[epoch 34, iterations:   155] loss: 0.532\n",
      "[epoch 34, iterations:   160] loss: 0.892\n",
      "[epoch 34, iterations:   165] loss: 1.143\n",
      "[epoch 34, iterations:   170] loss: 1.934\n",
      "[epoch 34, iterations:   175] loss: 0.579\n",
      "[epoch 34, iterations:   180] loss: 0.584\n",
      "[epoch 34, iterations:   185] loss: 0.349\n",
      "[epoch 34, iterations:   190] loss: 1.024\n",
      "[epoch 34, iterations:   195] loss: 0.878\n",
      "[epoch 34, iterations:   200] loss: 0.846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 34, iterations:   205] loss: 0.569\n",
      "[epoch 34, iterations:   210] loss: 0.453\n",
      "[epoch 34, iterations:   215] loss: 0.860\n",
      "[epoch 34, iterations:   220] loss: 0.349\n",
      "[epoch 34, iterations:   225] loss: 0.652\n",
      "[epoch 34, iterations:   230] loss: 0.606\n",
      "[epoch 34, iterations:   235] loss: 0.931\n",
      "[epoch 34, iterations:   240] loss: 0.899\n",
      "[epoch 34, iterations:   245] loss: 0.919\n",
      "[epoch 34, iterations:   250] loss: 0.614\n",
      "[epoch 34, iterations:   255] loss: 1.288\n",
      "[epoch 34, iterations:   260] loss: 1.468\n",
      "[epoch 34, iterations:   265] loss: 1.441\n",
      "[epoch 34, iterations:   270] loss: 1.414\n",
      "[epoch 34, iterations:   275] loss: 1.905\n",
      "[epoch 34, iterations:   280] loss: 1.532\n",
      "[epoch 34, iterations:   285] loss: 1.470\n",
      "[epoch 34, iterations:   290] loss: 1.238\n",
      "[epoch 34, iterations:   295] loss: 0.916\n",
      "[epoch 34, iterations:   300] loss: 0.848\n",
      "[epoch 34, iterations:   305] loss: 1.220\n",
      "[epoch 34, iterations:   310] loss: 1.327\n",
      "[epoch 34, iterations:   315] loss: 0.675\n",
      "[epoch 34, iterations:   320] loss: 0.911\n",
      "[epoch 34, iterations:   325] loss: 1.452\n",
      "[epoch 34, iterations:   330] loss: 0.855\n",
      "[epoch 34, iterations:   335] loss: 0.915\n",
      "[epoch 34, iterations:   340] loss: 1.396\n",
      "[epoch 34, iterations:   345] loss: 1.254\n",
      "[epoch 34, iterations:   350] loss: 0.680\n",
      "[epoch 34, iterations:   355] loss: 0.561\n",
      "[epoch 34, iterations:   360] loss: 0.358\n",
      "[epoch 34, iterations:   365] loss: 0.725\n",
      "[epoch 34, iterations:   370] loss: 0.670\n",
      "[epoch 34, iterations:   375] loss: 0.618\n",
      "[epoch 34, iterations:   380] loss: 0.748\n",
      "[epoch 34, iterations:   385] loss: 1.193\n",
      "[epoch 34, iterations:   390] loss: 0.868\n",
      "[epoch 34, iterations:   395] loss: 0.671\n",
      "[epoch 34, iterations:   400] loss: 0.537\n",
      "[epoch 35, iterations:     5] loss: 1.437\n",
      "[epoch 35, iterations:    10] loss: 1.459\n",
      "[epoch 35, iterations:    15] loss: 1.560\n",
      "[epoch 35, iterations:    20] loss: 1.595\n",
      "[epoch 35, iterations:    25] loss: 1.451\n",
      "[epoch 35, iterations:    30] loss: 1.225\n",
      "[epoch 35, iterations:    35] loss: 1.216\n",
      "[epoch 35, iterations:    40] loss: 1.090\n",
      "[epoch 35, iterations:    45] loss: 0.943\n",
      "[epoch 35, iterations:    50] loss: 0.638\n",
      "[epoch 35, iterations:    55] loss: 0.935\n",
      "[epoch 35, iterations:    60] loss: 1.106\n",
      "[epoch 35, iterations:    65] loss: 2.758\n",
      "[epoch 35, iterations:    70] loss: 0.882\n",
      "[epoch 35, iterations:    75] loss: 1.409\n",
      "[epoch 35, iterations:    80] loss: 2.615\n",
      "[epoch 35, iterations:    85] loss: 1.582\n",
      "[epoch 35, iterations:    90] loss: 1.070\n",
      "[epoch 35, iterations:    95] loss: 0.866\n",
      "[epoch 35, iterations:   100] loss: 0.833\n",
      "[epoch 35, iterations:   105] loss: 1.007\n",
      "[epoch 35, iterations:   110] loss: 0.704\n",
      "[epoch 35, iterations:   115] loss: 0.553\n",
      "[epoch 35, iterations:   120] loss: 0.889\n",
      "[epoch 35, iterations:   125] loss: 1.287\n",
      "[epoch 35, iterations:   130] loss: 0.601\n",
      "[epoch 35, iterations:   135] loss: 0.780\n",
      "[epoch 35, iterations:   140] loss: 0.493\n",
      "[epoch 35, iterations:   145] loss: 0.622\n",
      "[epoch 35, iterations:   150] loss: 0.585\n",
      "[epoch 35, iterations:   155] loss: 0.486\n",
      "[epoch 35, iterations:   160] loss: 0.712\n",
      "[epoch 35, iterations:   165] loss: 0.711\n",
      "[epoch 35, iterations:   170] loss: 0.795\n",
      "[epoch 35, iterations:   175] loss: 0.888\n",
      "[epoch 35, iterations:   180] loss: 1.219\n",
      "[epoch 35, iterations:   185] loss: 1.480\n",
      "[epoch 35, iterations:   190] loss: 0.918\n",
      "[epoch 35, iterations:   195] loss: 0.745\n",
      "[epoch 35, iterations:   200] loss: 0.593\n",
      "[epoch 35, iterations:   205] loss: 0.488\n",
      "[epoch 35, iterations:   210] loss: 0.664\n",
      "[epoch 35, iterations:   215] loss: 0.533\n",
      "[epoch 35, iterations:   220] loss: 1.169\n",
      "[epoch 35, iterations:   225] loss: 0.782\n",
      "[epoch 35, iterations:   230] loss: 0.567\n",
      "[epoch 35, iterations:   235] loss: 0.882\n",
      "[epoch 35, iterations:   240] loss: 0.749\n",
      "[epoch 35, iterations:   245] loss: 0.312\n",
      "[epoch 35, iterations:   250] loss: 1.871\n",
      "[epoch 35, iterations:   255] loss: 1.876\n",
      "[epoch 35, iterations:   260] loss: 0.685\n",
      "[epoch 35, iterations:   265] loss: 1.089\n",
      "[epoch 35, iterations:   270] loss: 0.853\n",
      "[epoch 35, iterations:   275] loss: 1.004\n",
      "[epoch 35, iterations:   280] loss: 0.831\n",
      "[epoch 35, iterations:   285] loss: 0.459\n",
      "[epoch 35, iterations:   290] loss: 0.529\n",
      "[epoch 35, iterations:   295] loss: 0.616\n",
      "[epoch 35, iterations:   300] loss: 1.094\n",
      "[epoch 35, iterations:   305] loss: 0.877\n",
      "[epoch 35, iterations:   310] loss: 0.788\n",
      "[epoch 35, iterations:   315] loss: 0.580\n",
      "[epoch 35, iterations:   320] loss: 0.576\n",
      "[epoch 35, iterations:   325] loss: 0.518\n",
      "[epoch 35, iterations:   330] loss: 0.661\n",
      "[epoch 35, iterations:   335] loss: 0.651\n",
      "[epoch 35, iterations:   340] loss: 0.253\n",
      "[epoch 35, iterations:   345] loss: 0.935\n",
      "[epoch 35, iterations:   350] loss: 0.370\n",
      "[epoch 35, iterations:   355] loss: 0.260\n",
      "[epoch 35, iterations:   360] loss: 0.162\n",
      "[epoch 35, iterations:   365] loss: 0.436\n",
      "[epoch 35, iterations:   370] loss: 0.571\n",
      "[epoch 35, iterations:   375] loss: 0.812\n",
      "[epoch 35, iterations:   380] loss: 0.902\n",
      "[epoch 35, iterations:   385] loss: 0.203\n",
      "[epoch 35, iterations:   390] loss: 0.500\n",
      "[epoch 35, iterations:   395] loss: 0.467\n",
      "[epoch 35, iterations:   400] loss: 1.267\n",
      "[epoch 36, iterations:     5] loss: 2.131\n",
      "[epoch 36, iterations:    10] loss: 2.361\n",
      "[epoch 36, iterations:    15] loss: 1.800\n",
      "[epoch 36, iterations:    20] loss: 0.501\n",
      "[epoch 36, iterations:    25] loss: 1.817\n",
      "[epoch 36, iterations:    30] loss: 1.187\n",
      "[epoch 36, iterations:    35] loss: 0.372\n",
      "[epoch 36, iterations:    40] loss: 0.864\n",
      "[epoch 36, iterations:    45] loss: 0.553\n",
      "[epoch 36, iterations:    50] loss: 0.585\n",
      "[epoch 36, iterations:    55] loss: 0.477\n",
      "[epoch 36, iterations:    60] loss: 0.654\n",
      "[epoch 36, iterations:    65] loss: 1.208\n",
      "[epoch 36, iterations:    70] loss: 0.910\n",
      "[epoch 36, iterations:    75] loss: 0.934\n",
      "[epoch 36, iterations:    80] loss: 0.401\n",
      "[epoch 36, iterations:    85] loss: 0.356\n",
      "[epoch 36, iterations:    90] loss: 0.479\n",
      "[epoch 36, iterations:    95] loss: 0.899\n",
      "[epoch 36, iterations:   100] loss: 0.991\n",
      "[epoch 36, iterations:   105] loss: 1.019\n",
      "[epoch 36, iterations:   110] loss: 1.115\n",
      "[epoch 36, iterations:   115] loss: 0.533\n",
      "[epoch 36, iterations:   120] loss: 0.799\n",
      "[epoch 36, iterations:   125] loss: 0.922\n",
      "[epoch 36, iterations:   130] loss: 0.578\n",
      "[epoch 36, iterations:   135] loss: 0.776\n",
      "[epoch 36, iterations:   140] loss: 0.619\n",
      "[epoch 36, iterations:   145] loss: 0.870\n",
      "[epoch 36, iterations:   150] loss: 0.787\n",
      "[epoch 36, iterations:   155] loss: 1.085\n",
      "[epoch 36, iterations:   160] loss: 2.878\n",
      "[epoch 36, iterations:   165] loss: 1.395\n",
      "[epoch 36, iterations:   170] loss: 1.854\n",
      "[epoch 36, iterations:   175] loss: 1.831\n",
      "[epoch 36, iterations:   180] loss: 1.680\n",
      "[epoch 36, iterations:   185] loss: 1.085\n",
      "[epoch 36, iterations:   190] loss: 1.317\n",
      "[epoch 36, iterations:   195] loss: 0.956\n",
      "[epoch 36, iterations:   200] loss: 0.824\n",
      "[epoch 36, iterations:   205] loss: 0.630\n",
      "[epoch 36, iterations:   210] loss: 0.452\n",
      "[epoch 36, iterations:   215] loss: 0.949\n",
      "[epoch 36, iterations:   220] loss: 1.449\n",
      "[epoch 36, iterations:   225] loss: 0.527\n",
      "[epoch 36, iterations:   230] loss: 1.066\n",
      "[epoch 36, iterations:   235] loss: 0.506\n",
      "[epoch 36, iterations:   240] loss: 0.869\n",
      "[epoch 36, iterations:   245] loss: 0.452\n",
      "[epoch 36, iterations:   250] loss: 0.626\n",
      "[epoch 36, iterations:   255] loss: 0.817\n",
      "[epoch 36, iterations:   260] loss: 1.056\n",
      "[epoch 36, iterations:   265] loss: 0.862\n",
      "[epoch 36, iterations:   270] loss: 0.410\n",
      "[epoch 36, iterations:   275] loss: 0.611\n",
      "[epoch 36, iterations:   280] loss: 0.679\n",
      "[epoch 36, iterations:   285] loss: 0.588\n",
      "[epoch 36, iterations:   290] loss: 0.830\n",
      "[epoch 36, iterations:   295] loss: 0.889\n",
      "[epoch 36, iterations:   300] loss: 1.457\n",
      "[epoch 36, iterations:   305] loss: 0.873\n",
      "[epoch 36, iterations:   310] loss: 0.667\n",
      "[epoch 36, iterations:   315] loss: 0.673\n",
      "[epoch 36, iterations:   320] loss: 0.857\n",
      "[epoch 36, iterations:   325] loss: 0.530\n",
      "[epoch 36, iterations:   330] loss: 0.914\n",
      "[epoch 36, iterations:   335] loss: 1.214\n",
      "[epoch 36, iterations:   340] loss: 1.046\n",
      "[epoch 36, iterations:   345] loss: 0.953\n",
      "[epoch 36, iterations:   350] loss: 1.919\n",
      "[epoch 36, iterations:   355] loss: 1.123\n",
      "[epoch 36, iterations:   360] loss: 0.806\n",
      "[epoch 36, iterations:   365] loss: 0.800\n",
      "[epoch 36, iterations:   370] loss: 0.557\n",
      "[epoch 36, iterations:   375] loss: 0.577\n",
      "[epoch 36, iterations:   380] loss: 0.798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 36, iterations:   385] loss: 0.410\n",
      "[epoch 36, iterations:   390] loss: 0.423\n",
      "[epoch 36, iterations:   395] loss: 0.458\n",
      "[epoch 36, iterations:   400] loss: 0.610\n",
      "[epoch 37, iterations:     5] loss: 0.656\n",
      "[epoch 37, iterations:    10] loss: 0.449\n",
      "[epoch 37, iterations:    15] loss: 0.384\n",
      "[epoch 37, iterations:    20] loss: 0.706\n",
      "[epoch 37, iterations:    25] loss: 0.537\n",
      "[epoch 37, iterations:    30] loss: 0.341\n",
      "[epoch 37, iterations:    35] loss: 1.072\n",
      "[epoch 37, iterations:    40] loss: 1.159\n",
      "[epoch 37, iterations:    45] loss: 1.193\n",
      "[epoch 37, iterations:    50] loss: 0.978\n",
      "[epoch 37, iterations:    55] loss: 1.991\n",
      "[epoch 37, iterations:    60] loss: 1.741\n",
      "[epoch 37, iterations:    65] loss: 1.811\n",
      "[epoch 37, iterations:    70] loss: 2.029\n",
      "[epoch 37, iterations:    75] loss: 0.379\n",
      "[epoch 37, iterations:    80] loss: 0.624\n",
      "[epoch 37, iterations:    85] loss: 0.664\n",
      "[epoch 37, iterations:    90] loss: 0.644\n",
      "[epoch 37, iterations:    95] loss: 0.662\n",
      "[epoch 37, iterations:   100] loss: 0.842\n",
      "[epoch 37, iterations:   105] loss: 0.543\n",
      "[epoch 37, iterations:   110] loss: 0.750\n",
      "[epoch 37, iterations:   115] loss: 0.950\n",
      "[epoch 37, iterations:   120] loss: 0.738\n",
      "[epoch 37, iterations:   125] loss: 1.003\n",
      "[epoch 37, iterations:   130] loss: 0.457\n",
      "[epoch 37, iterations:   135] loss: 0.523\n",
      "[epoch 37, iterations:   140] loss: 0.765\n",
      "[epoch 37, iterations:   145] loss: 0.975\n",
      "[epoch 37, iterations:   150] loss: 0.760\n",
      "[epoch 37, iterations:   155] loss: 1.114\n",
      "[epoch 37, iterations:   160] loss: 0.650\n",
      "[epoch 37, iterations:   165] loss: 0.451\n",
      "[epoch 37, iterations:   170] loss: 0.456\n",
      "[epoch 37, iterations:   175] loss: 0.305\n",
      "[epoch 37, iterations:   180] loss: 0.330\n",
      "[epoch 37, iterations:   185] loss: 0.281\n",
      "[epoch 37, iterations:   190] loss: 0.434\n",
      "[epoch 37, iterations:   195] loss: 0.731\n",
      "[epoch 37, iterations:   200] loss: 0.448\n",
      "[epoch 37, iterations:   205] loss: 0.702\n",
      "[epoch 37, iterations:   210] loss: 0.667\n",
      "[epoch 37, iterations:   215] loss: 0.610\n",
      "[epoch 37, iterations:   220] loss: 1.489\n",
      "[epoch 37, iterations:   225] loss: 0.961\n",
      "[epoch 37, iterations:   230] loss: 0.629\n",
      "[epoch 37, iterations:   235] loss: 0.861\n",
      "[epoch 37, iterations:   240] loss: 1.583\n",
      "[epoch 37, iterations:   245] loss: 1.268\n",
      "[epoch 37, iterations:   250] loss: 1.208\n",
      "[epoch 37, iterations:   255] loss: 0.526\n",
      "[epoch 37, iterations:   260] loss: 0.885\n",
      "[epoch 37, iterations:   265] loss: 1.065\n",
      "[epoch 37, iterations:   270] loss: 1.099\n",
      "[epoch 37, iterations:   275] loss: 1.053\n",
      "[epoch 37, iterations:   280] loss: 0.917\n",
      "[epoch 37, iterations:   285] loss: 0.880\n",
      "[epoch 37, iterations:   290] loss: 0.718\n",
      "[epoch 37, iterations:   295] loss: 0.490\n",
      "[epoch 37, iterations:   300] loss: 0.283\n",
      "[epoch 37, iterations:   305] loss: 0.666\n",
      "[epoch 37, iterations:   310] loss: 0.317\n",
      "[epoch 37, iterations:   315] loss: 0.558\n",
      "[epoch 37, iterations:   320] loss: 0.697\n",
      "[epoch 37, iterations:   325] loss: 0.775\n",
      "[epoch 37, iterations:   330] loss: 0.638\n",
      "[epoch 37, iterations:   335] loss: 0.582\n",
      "[epoch 37, iterations:   340] loss: 0.333\n",
      "[epoch 37, iterations:   345] loss: 1.013\n",
      "[epoch 37, iterations:   350] loss: 1.405\n",
      "[epoch 37, iterations:   355] loss: 0.931\n",
      "[epoch 37, iterations:   360] loss: 0.629\n",
      "[epoch 37, iterations:   365] loss: 0.658\n",
      "[epoch 37, iterations:   370] loss: 0.619\n",
      "[epoch 37, iterations:   375] loss: 1.342\n",
      "[epoch 37, iterations:   380] loss: 1.602\n",
      "[epoch 37, iterations:   385] loss: 0.732\n",
      "[epoch 37, iterations:   390] loss: 0.384\n",
      "[epoch 37, iterations:   395] loss: 0.425\n",
      "[epoch 37, iterations:   400] loss: 0.365\n",
      "[epoch 38, iterations:     5] loss: 0.610\n",
      "[epoch 38, iterations:    10] loss: 0.725\n",
      "[epoch 38, iterations:    15] loss: 0.568\n",
      "[epoch 38, iterations:    20] loss: 0.471\n",
      "[epoch 38, iterations:    25] loss: 1.148\n",
      "[epoch 38, iterations:    30] loss: 1.160\n",
      "[epoch 38, iterations:    35] loss: 0.967\n",
      "[epoch 38, iterations:    40] loss: 0.881\n",
      "[epoch 38, iterations:    45] loss: 0.605\n",
      "[epoch 38, iterations:    50] loss: 0.737\n",
      "[epoch 38, iterations:    55] loss: 0.352\n",
      "[epoch 38, iterations:    60] loss: 0.421\n",
      "[epoch 38, iterations:    65] loss: 0.227\n",
      "[epoch 38, iterations:    70] loss: 0.420\n",
      "[epoch 38, iterations:    75] loss: 1.172\n",
      "[epoch 38, iterations:    80] loss: 1.122\n",
      "[epoch 38, iterations:    85] loss: 0.559\n",
      "[epoch 38, iterations:    90] loss: 1.638\n",
      "[epoch 38, iterations:    95] loss: 0.784\n",
      "[epoch 38, iterations:   100] loss: 0.314\n",
      "[epoch 38, iterations:   105] loss: 0.483\n",
      "[epoch 38, iterations:   110] loss: 0.320\n",
      "[epoch 38, iterations:   115] loss: 0.756\n",
      "[epoch 38, iterations:   120] loss: 1.100\n",
      "[epoch 38, iterations:   125] loss: 0.603\n",
      "[epoch 38, iterations:   130] loss: 0.907\n",
      "[epoch 38, iterations:   135] loss: 0.749\n",
      "[epoch 38, iterations:   140] loss: 0.869\n",
      "[epoch 38, iterations:   145] loss: 1.242\n",
      "[epoch 38, iterations:   150] loss: 1.041\n",
      "[epoch 38, iterations:   155] loss: 0.476\n",
      "[epoch 38, iterations:   160] loss: 0.783\n",
      "[epoch 38, iterations:   165] loss: 0.356\n",
      "[epoch 38, iterations:   170] loss: 0.611\n",
      "[epoch 38, iterations:   175] loss: 2.513\n",
      "[epoch 38, iterations:   180] loss: 3.197\n",
      "[epoch 38, iterations:   185] loss: 2.202\n",
      "[epoch 38, iterations:   190] loss: 1.316\n",
      "[epoch 38, iterations:   195] loss: 1.214\n",
      "[epoch 38, iterations:   200] loss: 0.952\n",
      "[epoch 38, iterations:   205] loss: 0.998\n",
      "[epoch 38, iterations:   210] loss: 0.830\n",
      "[epoch 38, iterations:   215] loss: 0.830\n",
      "[epoch 38, iterations:   220] loss: 1.174\n",
      "[epoch 38, iterations:   225] loss: 1.396\n",
      "[epoch 38, iterations:   230] loss: 1.108\n",
      "[epoch 38, iterations:   235] loss: 1.235\n",
      "[epoch 38, iterations:   240] loss: 0.597\n",
      "[epoch 38, iterations:   245] loss: 0.477\n",
      "[epoch 38, iterations:   250] loss: 0.750\n",
      "[epoch 38, iterations:   255] loss: 1.031\n",
      "[epoch 38, iterations:   260] loss: 1.285\n",
      "[epoch 38, iterations:   265] loss: 0.610\n",
      "[epoch 38, iterations:   270] loss: 0.806\n",
      "[epoch 38, iterations:   275] loss: 0.667\n",
      "[epoch 38, iterations:   280] loss: 1.184\n",
      "[epoch 38, iterations:   285] loss: 1.726\n",
      "[epoch 38, iterations:   290] loss: 0.963\n",
      "[epoch 38, iterations:   295] loss: 1.133\n",
      "[epoch 38, iterations:   300] loss: 1.365\n",
      "[epoch 38, iterations:   305] loss: 0.528\n",
      "[epoch 38, iterations:   310] loss: 0.389\n",
      "[epoch 38, iterations:   315] loss: 0.687\n",
      "[epoch 38, iterations:   320] loss: 0.568\n",
      "[epoch 38, iterations:   325] loss: 0.549\n",
      "[epoch 38, iterations:   330] loss: 0.163\n",
      "[epoch 38, iterations:   335] loss: 0.375\n",
      "[epoch 38, iterations:   340] loss: 0.267\n",
      "[epoch 38, iterations:   345] loss: 0.552\n",
      "[epoch 38, iterations:   350] loss: 0.812\n",
      "[epoch 38, iterations:   355] loss: 1.360\n",
      "[epoch 38, iterations:   360] loss: 0.776\n",
      "[epoch 38, iterations:   365] loss: 0.813\n",
      "[epoch 38, iterations:   370] loss: 0.938\n",
      "[epoch 38, iterations:   375] loss: 0.449\n",
      "[epoch 38, iterations:   380] loss: 0.569\n",
      "[epoch 38, iterations:   385] loss: 0.332\n",
      "[epoch 38, iterations:   390] loss: 0.260\n",
      "[epoch 38, iterations:   395] loss: 0.321\n",
      "[epoch 38, iterations:   400] loss: 0.253\n",
      "[epoch 39, iterations:     5] loss: 0.179\n",
      "[epoch 39, iterations:    10] loss: 0.333\n",
      "[epoch 39, iterations:    15] loss: 1.615\n",
      "[epoch 39, iterations:    20] loss: 1.049\n",
      "[epoch 39, iterations:    25] loss: 0.609\n",
      "[epoch 39, iterations:    30] loss: 0.268\n",
      "[epoch 39, iterations:    35] loss: 0.563\n",
      "[epoch 39, iterations:    40] loss: 0.286\n",
      "[epoch 39, iterations:    45] loss: 0.427\n",
      "[epoch 39, iterations:    50] loss: 0.422\n",
      "[epoch 39, iterations:    55] loss: 0.448\n",
      "[epoch 39, iterations:    60] loss: 0.268\n",
      "[epoch 39, iterations:    65] loss: 0.195\n",
      "[epoch 39, iterations:    70] loss: 0.929\n",
      "[epoch 39, iterations:    75] loss: 0.697\n",
      "[epoch 39, iterations:    80] loss: 0.548\n",
      "[epoch 39, iterations:    85] loss: 0.989\n",
      "[epoch 39, iterations:    90] loss: 0.381\n",
      "[epoch 39, iterations:    95] loss: 0.274\n",
      "[epoch 39, iterations:   100] loss: 0.501\n",
      "[epoch 39, iterations:   105] loss: 0.617\n",
      "[epoch 39, iterations:   110] loss: 0.958\n",
      "[epoch 39, iterations:   115] loss: 1.062\n",
      "[epoch 39, iterations:   120] loss: 0.338\n",
      "[epoch 39, iterations:   125] loss: 0.629\n",
      "[epoch 39, iterations:   130] loss: 0.663\n",
      "[epoch 39, iterations:   135] loss: 0.490\n",
      "[epoch 39, iterations:   140] loss: 0.555\n",
      "[epoch 39, iterations:   145] loss: 0.435\n",
      "[epoch 39, iterations:   150] loss: 0.735\n",
      "[epoch 39, iterations:   155] loss: 0.700\n",
      "[epoch 39, iterations:   160] loss: 0.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 39, iterations:   165] loss: 0.792\n",
      "[epoch 39, iterations:   170] loss: 0.228\n",
      "[epoch 39, iterations:   175] loss: 0.365\n",
      "[epoch 39, iterations:   180] loss: 0.437\n",
      "[epoch 39, iterations:   185] loss: 1.277\n",
      "[epoch 39, iterations:   190] loss: 0.376\n",
      "[epoch 39, iterations:   195] loss: 0.636\n",
      "[epoch 39, iterations:   200] loss: 0.460\n",
      "[epoch 39, iterations:   205] loss: 0.592\n",
      "[epoch 39, iterations:   210] loss: 0.901\n",
      "[epoch 39, iterations:   215] loss: 1.269\n",
      "[epoch 39, iterations:   220] loss: 1.062\n",
      "[epoch 39, iterations:   225] loss: 0.905\n",
      "[epoch 39, iterations:   230] loss: 1.496\n",
      "[epoch 39, iterations:   235] loss: 1.185\n",
      "[epoch 39, iterations:   240] loss: 1.299\n",
      "[epoch 39, iterations:   245] loss: 0.845\n",
      "[epoch 39, iterations:   250] loss: 0.521\n",
      "[epoch 39, iterations:   255] loss: 0.358\n",
      "[epoch 39, iterations:   260] loss: 0.195\n",
      "[epoch 39, iterations:   265] loss: 0.568\n",
      "[epoch 39, iterations:   270] loss: 0.820\n",
      "[epoch 39, iterations:   275] loss: 0.779\n",
      "[epoch 39, iterations:   280] loss: 0.291\n",
      "[epoch 39, iterations:   285] loss: 0.143\n",
      "[epoch 39, iterations:   290] loss: 0.520\n",
      "[epoch 39, iterations:   295] loss: 0.195\n",
      "[epoch 39, iterations:   300] loss: 0.665\n",
      "[epoch 39, iterations:   305] loss: 0.445\n",
      "[epoch 39, iterations:   310] loss: 0.585\n",
      "[epoch 39, iterations:   315] loss: 1.362\n",
      "[epoch 39, iterations:   320] loss: 0.319\n",
      "[epoch 39, iterations:   325] loss: 0.392\n",
      "[epoch 39, iterations:   330] loss: 0.302\n",
      "[epoch 39, iterations:   335] loss: 0.549\n",
      "[epoch 39, iterations:   340] loss: 0.202\n",
      "[epoch 39, iterations:   345] loss: 0.451\n",
      "[epoch 39, iterations:   350] loss: 0.501\n",
      "[epoch 39, iterations:   355] loss: 0.464\n",
      "[epoch 39, iterations:   360] loss: 0.487\n",
      "[epoch 39, iterations:   365] loss: 0.609\n",
      "[epoch 39, iterations:   370] loss: 0.287\n",
      "[epoch 39, iterations:   375] loss: 0.822\n",
      "[epoch 39, iterations:   380] loss: 0.345\n",
      "[epoch 39, iterations:   385] loss: 0.451\n",
      "[epoch 39, iterations:   390] loss: 0.175\n",
      "[epoch 39, iterations:   395] loss: 0.321\n",
      "[epoch 39, iterations:   400] loss: 0.123\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "# print every 5th sequence\n",
    "print_running_loss = 5\n",
    "\n",
    "# Store training and validation accuracy over time\n",
    "train_acc=[]\n",
    "val_acc=[]\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct_predictions=[]\n",
    "    \n",
    "    for i, batch in enumerate(trainloader, 0):\n",
    "        # get the inputs; batch is a list of [inputs, labels]\n",
    "        sequences, labels = batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # set hidden states to zero after each sequence\n",
    "        hidden_states = lstm.init_hidden(batch_size)\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        label_scores = lstm(sequences,hidden_states)\n",
    "        last_label = label_scores[:,len(label_scores[0])-1] # only the last element of each sequence!\n",
    "        loss = loss_fn(last_label, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # memorize training accuracy\n",
    "        decoded=decode_labels(last_label.detach())\n",
    "        correct_predictions=correct_predictions+(list(labels.numpy()==decoded.numpy()))\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % print_running_loss == print_running_loss-1:    # print 10 times during an epoch\n",
    "            print('[epoch %d, iterations: %5d] loss: %.3f' %\n",
    "                  (overall_epochs, i + 1, running_loss / print_running_loss))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    ## save model every epoch\n",
    "    val_accuracy= validate()\n",
    "    file_name=\"weights-a\"+str(round(val_accuracy,4))+\"-e\"+str(overall_epochs)+\".pth\"\n",
    "    torch.save(lstm.state_dict(), folder_path+\"/\"+file_name)\n",
    "    \n",
    "    # save training and validation accuracy\n",
    "    train_acc.append(sum(correct_predictions)/len(correct_predictions))\n",
    "    val_acc.append(val_accuracy)\n",
    "    \n",
    "    overall_epochs+=1\n",
    "\n",
    "np.save(folder_path+'train_acc.npy', train_acc)\n",
    "np.save(folder_path+'val_acc.npy',val_acc)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34dcbb",
   "metadata": {},
   "source": [
    "## Save accuracies over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1a411ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(folder_path+'train_acc.npy', train_acc)\n",
    "np.save(folder_path+'val_acc.npy',val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "647cd4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3199999928474426, 0.3100000023841858, 0.36000001430511475, 0.3499999940395355, 0.3499999940395355, 0.3499999940395355, 0.3700000047683716, 0.3700000047683716, 0.38999998569488525, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.38999998569488525, 0.38999998569488525, 0.44999998807907104, 0.44999998807907104, 0.41999998688697815, 0.44999998807907104, 0.41999998688697815, 0.36000001430511475, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.36000001430511475, 0.3799999952316284, 0.3700000047683716, 0.3400000035762787, 0.3700000047683716, 0.3499999940395355, 0.36000001430511475, 0.3700000047683716, 0.3199999928474426, 0.3400000035762787, 0.3499999940395355, 0.36000001430511475, 0.3499999940395355, 0.3499999940395355, 0.3400000035762787, 0.33000001311302185, 0.3199999928474426]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2bed582970>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(val_acc)\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ebe4b",
   "metadata": {},
   "source": [
    "## Training and Test Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b9fae",
   "metadata": {},
   "source": [
    "## Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37609af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4375])\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(train_testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3bbf21",
   "metadata": {},
   "source": [
    "## Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d901d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4700])\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
    "assert prediction_test.ndim == 1\n",
    "assert prediction_test.shape[0] == 250\n",
    "\n",
    "# AND SAVE EXACTLY AS SHOWN BELOW\n",
    "np.save('prediction.npy', prediction.astype(int))\n",
    "\n",
    "# MAKE SURE THAT THE FILE HAS THE CORRECT FORMAT\n",
    "def validate_prediction_format():\n",
    "    loaded = np.load('prediction.npy')\n",
    "    assert loaded.shape == (250, )\n",
    "    assert loaded.dtype == int\n",
    "    assert (loaded <= 4).all()\n",
    "    assert (loaded >= 0).all()\n",
    "validate_prediction_format()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
