{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1142c020",
   "metadata": {},
   "source": [
    "## Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd38af38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) <U400\n",
      "(400,) int64\n",
      "(100,) <U1200\n",
      "(100,) int64\n",
      "(250,) <U2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('rnn-challenge-data.npz', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "    data_x = X['data_x']\n",
    "    data_y = X['data_y']\n",
    "    val_x = X['val_x']\n",
    "    val_y = X['val_y']\n",
    "    test_x = X['test_x']\n",
    "\n",
    "# TRAINING DATA: INPUT (x) AND OUTPUT (y)\n",
    "print(data_x.shape, data_x.dtype)\n",
    "print(data_y.shape, data_y.dtype)\n",
    "\n",
    "# VALIDATION DATA: INPUT (x) AND OUTPUT (y)\n",
    "print(val_x.shape, val_x.dtype)\n",
    "print(val_y.shape, val_y.dtype)\n",
    "\n",
    "# TEST DATA: INPUT (x) ONLY\n",
    "print(test_x.shape, test_x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354bea5",
   "metadata": {},
   "source": [
    "## Encode genome sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e87cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "\n",
    "def encode_genome_sequence(genome_sequence):\n",
    "    # convert string to list of chars\n",
    "    char_array =  np.array(list(genome_sequence))\n",
    "    \n",
    "    # encode characters using one-hot-encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(char_array)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    \n",
    "    # one hot encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    encoded=onehot_encoder.fit_transform(integer_encoded)\n",
    "    return encoded\n",
    "    \n",
    "encoded_x = encode_genome_sequence(data_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2fad0",
   "metadata": {},
   "source": [
    "## Custom Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b24bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomSequenceDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, transform=None, target_transform=None):\n",
    "        self.sequences = x_data\n",
    "        self.labels = y_data\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence=self.sequences[idx]\n",
    "        label=self.labels[idx]\n",
    "        if self.transform:\n",
    "            sequence = self.transform(sequence)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label,len(sequence))\n",
    "        # make y as large as x \n",
    "        return sequence, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474e7f0",
   "metadata": {},
   "source": [
    "## Create Dataloader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8278a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dataset=CustomSequenceDataset(data_x,data_y,transform = encode_genome_sequence)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e5d57",
   "metadata": {},
   "source": [
    "## Create Dataloader for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a04245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=CustomSequenceDataset(val_x,val_y,transform = encode_genome_sequence)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c77ec6",
   "metadata": {},
   "source": [
    "## Check Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe3f347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 400, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Layer expects the format (sequence_length,batch-size,feature_size) or (batch,sequence,feature) if param batch_first\n",
    "x,y=next(iter(trainloader))\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6119b",
   "metadata": {},
   "source": [
    "Ok, batch seems to be first, I'll set the parameter batch_first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08ce96",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e72ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size=4\n",
    "        self.n_layers=1\n",
    "        ## gets One-Hot-encoded genome element and returns the hidden values\n",
    "        self.lstm = nn.LSTM(input_size=4, hidden_size=self.hidden_size,batch_first=True)\n",
    "\n",
    "        # Classifier to make prediction from hidden layer\n",
    "        self.classify = nn.Linear(self.hidden_size, 5)\n",
    "\n",
    "    def forward(self, sequence, hidden_states):\n",
    "        lstm_out, _ = self.lstm(sequence.float(),hidden_states)\n",
    "        class_space = self.classify(lstm_out)\n",
    "        logit = F.log_softmax(class_space, dim=1)\n",
    "        return logit\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "        \"\"\" Set hidden states (h,c) to zero. Can be used for initialization \"\"\"\n",
    "        weight = next(self.parameters()).data\n",
    "        h = weight.new(self.n_layers, batch_size, self.hidden_size).zero_()\n",
    "        c= weight.new(self.n_layers, batch_size, self.hidden_size).zero_()\n",
    "        return h,c\n",
    "    \n",
    "lstm = LSTM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07e722",
   "metadata": {},
   "source": [
    "## Optional: Load weights from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4cd73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.load_state_dict(torch.load('models/weights-e40.pth'))\n",
    "lstm.eval()\n",
    "overall_epochs=40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425ad21",
   "metadata": {},
   "source": [
    "## Training and Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1208fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "def decode_label(encoded_label):\n",
    "    return argmax(encoded_label)\n",
    "\n",
    "def get_accuracy(dataloader):\n",
    "    predictions=[]\n",
    "    correct_or_wrong=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequence,label in dataloader:\n",
    "            hidden_states=lstm.init_hidden(batch_size)\n",
    "            pred_label = lstm(sequence,hidden_states)\n",
    "            last_label = pred_label[0][len(pred_label[0])-1]\n",
    "            prediction= decode_label(last_label)\n",
    "            predictions.append(prediction)\n",
    "            correct_or_wrong.append(prediction == label)\n",
    "    return sum(correct_or_wrong)/len(correct_or_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80cc86f",
   "metadata": {},
   "source": [
    "## Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e380642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    return(get_accuracy(testloader).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fba7e7",
   "metadata": {},
   "source": [
    "## Define Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec52d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.NLLLoss() # Negative Log Likelihood because classification\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95677087",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c7de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_epochs=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84bc901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 40, iterations:     5] loss: 5.217\n",
      "[epoch 40, iterations:    10] loss: 5.719\n",
      "[epoch 40, iterations:    15] loss: 5.525\n",
      "[epoch 40, iterations:    20] loss: 5.508\n",
      "[epoch 40, iterations:    25] loss: 6.006\n",
      "[epoch 40, iterations:    30] loss: 5.803\n",
      "[epoch 40, iterations:    35] loss: 5.804\n",
      "[epoch 40, iterations:    40] loss: 5.935\n",
      "[epoch 40, iterations:    45] loss: 5.168\n",
      "[epoch 40, iterations:    50] loss: 6.285\n",
      "[epoch 40, iterations:    55] loss: 5.372\n",
      "[epoch 40, iterations:    60] loss: 5.410\n",
      "[epoch 40, iterations:    65] loss: 5.959\n",
      "[epoch 40, iterations:    70] loss: 5.962\n",
      "[epoch 40, iterations:    75] loss: 5.702\n",
      "[epoch 40, iterations:    80] loss: 5.786\n",
      "[epoch 40, iterations:    85] loss: 5.414\n",
      "[epoch 40, iterations:    90] loss: 5.589\n",
      "[epoch 40, iterations:    95] loss: 5.978\n",
      "[epoch 40, iterations:   100] loss: 5.456\n",
      "[epoch 40, iterations:   105] loss: 5.734\n",
      "[epoch 40, iterations:   110] loss: 5.885\n",
      "[epoch 40, iterations:   115] loss: 5.984\n",
      "[epoch 40, iterations:   120] loss: 5.760\n",
      "[epoch 40, iterations:   125] loss: 5.912\n",
      "[epoch 40, iterations:   130] loss: 6.285\n",
      "[epoch 40, iterations:   135] loss: 5.459\n",
      "[epoch 40, iterations:   140] loss: 6.072\n",
      "[epoch 40, iterations:   145] loss: 5.281\n",
      "[epoch 40, iterations:   150] loss: 5.673\n",
      "[epoch 40, iterations:   155] loss: 5.429\n",
      "[epoch 40, iterations:   160] loss: 5.612\n",
      "[epoch 40, iterations:   165] loss: 5.581\n",
      "[epoch 40, iterations:   170] loss: 5.945\n",
      "[epoch 40, iterations:   175] loss: 5.660\n",
      "[epoch 40, iterations:   180] loss: 5.388\n",
      "[epoch 40, iterations:   185] loss: 5.779\n",
      "[epoch 40, iterations:   190] loss: 5.721\n",
      "[epoch 40, iterations:   195] loss: 5.813\n",
      "[epoch 40, iterations:   200] loss: 5.563\n",
      "[epoch 40, iterations:   205] loss: 5.731\n",
      "[epoch 40, iterations:   210] loss: 5.564\n",
      "[epoch 40, iterations:   215] loss: 5.490\n",
      "[epoch 40, iterations:   220] loss: 5.398\n",
      "[epoch 40, iterations:   225] loss: 5.426\n",
      "[epoch 40, iterations:   230] loss: 5.680\n",
      "[epoch 40, iterations:   235] loss: 5.353\n",
      "[epoch 40, iterations:   240] loss: 5.600\n",
      "[epoch 40, iterations:   245] loss: 5.544\n",
      "[epoch 40, iterations:   250] loss: 5.561\n",
      "[epoch 40, iterations:   255] loss: 5.598\n",
      "[epoch 40, iterations:   260] loss: 5.449\n",
      "[epoch 40, iterations:   265] loss: 5.726\n",
      "[epoch 40, iterations:   270] loss: 5.501\n",
      "[epoch 40, iterations:   275] loss: 5.574\n",
      "[epoch 40, iterations:   280] loss: 5.851\n",
      "[epoch 40, iterations:   285] loss: 6.049\n",
      "[epoch 40, iterations:   290] loss: 5.742\n",
      "[epoch 40, iterations:   295] loss: 5.744\n",
      "[epoch 40, iterations:   300] loss: 5.394\n",
      "[epoch 40, iterations:   305] loss: 5.393\n",
      "[epoch 40, iterations:   310] loss: 5.531\n",
      "[epoch 40, iterations:   315] loss: 5.753\n",
      "[epoch 40, iterations:   320] loss: 5.366\n",
      "[epoch 40, iterations:   325] loss: 6.062\n",
      "[epoch 40, iterations:   330] loss: 5.449\n",
      "[epoch 40, iterations:   335] loss: 5.988\n",
      "[epoch 40, iterations:   340] loss: 5.920\n",
      "[epoch 40, iterations:   345] loss: 5.355\n",
      "[epoch 40, iterations:   350] loss: 5.630\n",
      "[epoch 40, iterations:   355] loss: 5.625\n",
      "[epoch 40, iterations:   360] loss: 5.308\n",
      "[epoch 40, iterations:   365] loss: 5.397\n",
      "[epoch 40, iterations:   370] loss: 6.066\n",
      "[epoch 40, iterations:   375] loss: 5.800\n",
      "[epoch 40, iterations:   380] loss: 5.094\n",
      "[epoch 40, iterations:   385] loss: 6.286\n",
      "[epoch 40, iterations:   390] loss: 6.420\n",
      "[epoch 40, iterations:   395] loss: 5.606\n",
      "[epoch 40, iterations:   400] loss: 5.291\n",
      "[epoch 41, iterations:     5] loss: 5.564\n",
      "[epoch 41, iterations:    10] loss: 5.857\n",
      "[epoch 41, iterations:    15] loss: 6.315\n",
      "[epoch 41, iterations:    20] loss: 5.450\n",
      "[epoch 41, iterations:    25] loss: 5.805\n",
      "[epoch 41, iterations:    30] loss: 5.436\n",
      "[epoch 41, iterations:    35] loss: 6.105\n",
      "[epoch 41, iterations:    40] loss: 5.918\n",
      "[epoch 41, iterations:    45] loss: 5.316\n",
      "[epoch 41, iterations:    50] loss: 5.888\n",
      "[epoch 41, iterations:    55] loss: 5.635\n",
      "[epoch 41, iterations:    60] loss: 5.603\n",
      "[epoch 41, iterations:    65] loss: 5.103\n",
      "[epoch 41, iterations:    70] loss: 5.335\n",
      "[epoch 41, iterations:    75] loss: 5.902\n",
      "[epoch 41, iterations:    80] loss: 5.861\n",
      "[epoch 41, iterations:    85] loss: 5.528\n",
      "[epoch 41, iterations:    90] loss: 5.446\n",
      "[epoch 41, iterations:    95] loss: 5.419\n",
      "[epoch 41, iterations:   100] loss: 5.373\n",
      "[epoch 41, iterations:   105] loss: 5.372\n",
      "[epoch 41, iterations:   110] loss: 5.679\n",
      "[epoch 41, iterations:   115] loss: 5.562\n",
      "[epoch 41, iterations:   120] loss: 5.501\n",
      "[epoch 41, iterations:   125] loss: 5.406\n",
      "[epoch 41, iterations:   130] loss: 5.635\n",
      "[epoch 41, iterations:   135] loss: 5.413\n",
      "[epoch 41, iterations:   140] loss: 5.407\n",
      "[epoch 41, iterations:   145] loss: 5.460\n",
      "[epoch 41, iterations:   150] loss: 5.717\n",
      "[epoch 41, iterations:   155] loss: 5.576\n",
      "[epoch 41, iterations:   160] loss: 5.330\n",
      "[epoch 41, iterations:   165] loss: 5.146\n",
      "[epoch 41, iterations:   170] loss: 5.802\n",
      "[epoch 41, iterations:   175] loss: 5.448\n",
      "[epoch 41, iterations:   180] loss: 5.899\n",
      "[epoch 41, iterations:   185] loss: 5.664\n",
      "[epoch 41, iterations:   190] loss: 5.862\n",
      "[epoch 41, iterations:   195] loss: 5.661\n",
      "[epoch 41, iterations:   200] loss: 5.227\n",
      "[epoch 41, iterations:   205] loss: 5.366\n",
      "[epoch 41, iterations:   210] loss: 5.471\n",
      "[epoch 41, iterations:   215] loss: 5.950\n",
      "[epoch 41, iterations:   220] loss: 6.418\n",
      "[epoch 41, iterations:   225] loss: 5.330\n",
      "[epoch 41, iterations:   230] loss: 5.919\n",
      "[epoch 41, iterations:   235] loss: 4.737\n",
      "[epoch 41, iterations:   240] loss: 5.003\n",
      "[epoch 41, iterations:   245] loss: 4.968\n",
      "[epoch 41, iterations:   250] loss: 4.451\n",
      "[epoch 41, iterations:   255] loss: 4.601\n",
      "[epoch 41, iterations:   260] loss: 4.699\n",
      "[epoch 41, iterations:   265] loss: 4.530\n",
      "[epoch 41, iterations:   270] loss: 4.572\n",
      "[epoch 41, iterations:   275] loss: 4.307\n",
      "[epoch 41, iterations:   280] loss: 4.515\n",
      "[epoch 41, iterations:   285] loss: 4.135\n",
      "[epoch 41, iterations:   290] loss: 4.140\n",
      "[epoch 41, iterations:   295] loss: 3.912\n",
      "[epoch 41, iterations:   300] loss: 3.854\n",
      "[epoch 41, iterations:   305] loss: 4.541\n",
      "[epoch 41, iterations:   310] loss: 4.738\n",
      "[epoch 41, iterations:   315] loss: 5.079\n",
      "[epoch 41, iterations:   320] loss: 4.958\n",
      "[epoch 41, iterations:   325] loss: 4.903\n",
      "[epoch 41, iterations:   330] loss: 4.860\n",
      "[epoch 41, iterations:   335] loss: 4.925\n",
      "[epoch 41, iterations:   340] loss: 5.334\n",
      "[epoch 41, iterations:   345] loss: 5.051\n",
      "[epoch 41, iterations:   350] loss: 5.052\n",
      "[epoch 41, iterations:   355] loss: 4.823\n",
      "[epoch 41, iterations:   360] loss: 4.797\n",
      "[epoch 41, iterations:   365] loss: 4.858\n",
      "[epoch 41, iterations:   370] loss: 5.043\n",
      "[epoch 41, iterations:   375] loss: 4.950\n",
      "[epoch 41, iterations:   380] loss: 4.756\n",
      "[epoch 41, iterations:   385] loss: 4.760\n",
      "[epoch 41, iterations:   390] loss: 4.972\n",
      "[epoch 41, iterations:   395] loss: 4.972\n",
      "[epoch 41, iterations:   400] loss: 4.871\n",
      "[epoch 42, iterations:     5] loss: 4.974\n",
      "[epoch 42, iterations:    10] loss: 4.270\n",
      "[epoch 42, iterations:    15] loss: 4.271\n",
      "[epoch 42, iterations:    20] loss: 5.359\n",
      "[epoch 42, iterations:    25] loss: 4.489\n",
      "[epoch 42, iterations:    30] loss: 4.726\n",
      "[epoch 42, iterations:    35] loss: 4.410\n",
      "[epoch 42, iterations:    40] loss: 4.528\n",
      "[epoch 42, iterations:    45] loss: 4.350\n",
      "[epoch 42, iterations:    50] loss: 5.200\n",
      "[epoch 42, iterations:    55] loss: 4.230\n",
      "[epoch 42, iterations:    60] loss: 4.264\n",
      "[epoch 42, iterations:    65] loss: 4.406\n",
      "[epoch 42, iterations:    70] loss: 4.407\n",
      "[epoch 42, iterations:    75] loss: 3.883\n",
      "[epoch 42, iterations:    80] loss: 4.309\n",
      "[epoch 42, iterations:    85] loss: 4.891\n",
      "[epoch 42, iterations:    90] loss: 4.209\n",
      "[epoch 42, iterations:    95] loss: 4.584\n",
      "[epoch 42, iterations:   100] loss: 3.771\n",
      "[epoch 42, iterations:   105] loss: 4.425\n",
      "[epoch 42, iterations:   110] loss: 4.134\n",
      "[epoch 42, iterations:   115] loss: 4.083\n",
      "[epoch 42, iterations:   120] loss: 4.402\n",
      "[epoch 42, iterations:   125] loss: 4.184\n",
      "[epoch 42, iterations:   130] loss: 6.100\n",
      "[epoch 42, iterations:   135] loss: 5.797\n",
      "[epoch 42, iterations:   140] loss: 5.860\n",
      "[epoch 42, iterations:   145] loss: 4.942\n",
      "[epoch 42, iterations:   150] loss: 5.401\n",
      "[epoch 42, iterations:   155] loss: 4.452\n",
      "[epoch 42, iterations:   160] loss: 4.287\n",
      "[epoch 42, iterations:   165] loss: 4.418\n",
      "[epoch 42, iterations:   170] loss: 3.686\n",
      "[epoch 42, iterations:   175] loss: 4.010\n",
      "[epoch 42, iterations:   180] loss: 4.446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 42, iterations:   185] loss: 4.032\n",
      "[epoch 42, iterations:   190] loss: 4.074\n",
      "[epoch 42, iterations:   195] loss: 4.391\n",
      "[epoch 42, iterations:   200] loss: 4.281\n",
      "[epoch 42, iterations:   205] loss: 4.528\n",
      "[epoch 42, iterations:   210] loss: 4.203\n",
      "[epoch 42, iterations:   215] loss: 4.396\n",
      "[epoch 42, iterations:   220] loss: 4.956\n",
      "[epoch 42, iterations:   225] loss: 5.132\n",
      "[epoch 42, iterations:   230] loss: 5.124\n",
      "[epoch 42, iterations:   235] loss: 4.941\n",
      "[epoch 42, iterations:   240] loss: 4.981\n",
      "[epoch 42, iterations:   245] loss: 5.268\n",
      "[epoch 42, iterations:   250] loss: 5.343\n",
      "[epoch 42, iterations:   255] loss: 5.181\n",
      "[epoch 42, iterations:   260] loss: 5.023\n",
      "[epoch 42, iterations:   265] loss: 5.401\n",
      "[epoch 42, iterations:   270] loss: 4.930\n",
      "[epoch 42, iterations:   275] loss: 4.768\n",
      "[epoch 42, iterations:   280] loss: 5.156\n",
      "[epoch 42, iterations:   285] loss: 4.943\n",
      "[epoch 42, iterations:   290] loss: 4.994\n",
      "[epoch 42, iterations:   295] loss: 4.637\n",
      "[epoch 42, iterations:   300] loss: 5.112\n",
      "[epoch 42, iterations:   305] loss: 4.622\n",
      "[epoch 42, iterations:   310] loss: 4.711\n",
      "[epoch 42, iterations:   315] loss: 4.576\n",
      "[epoch 42, iterations:   320] loss: 4.658\n",
      "[epoch 42, iterations:   325] loss: 4.092\n",
      "[epoch 42, iterations:   330] loss: 3.929\n",
      "[epoch 42, iterations:   335] loss: 4.309\n",
      "[epoch 42, iterations:   340] loss: 3.694\n",
      "[epoch 42, iterations:   345] loss: 3.928\n",
      "[epoch 42, iterations:   350] loss: 4.199\n",
      "[epoch 42, iterations:   355] loss: 4.509\n",
      "[epoch 42, iterations:   360] loss: 4.342\n",
      "[epoch 42, iterations:   365] loss: 4.558\n",
      "[epoch 42, iterations:   370] loss: 4.411\n",
      "[epoch 42, iterations:   375] loss: 4.176\n",
      "[epoch 42, iterations:   380] loss: 4.586\n",
      "[epoch 42, iterations:   385] loss: 4.281\n",
      "[epoch 42, iterations:   390] loss: 4.537\n",
      "[epoch 42, iterations:   395] loss: 4.726\n",
      "[epoch 42, iterations:   400] loss: 5.152\n",
      "[epoch 43, iterations:     5] loss: 4.902\n",
      "[epoch 43, iterations:    10] loss: 5.228\n",
      "[epoch 43, iterations:    15] loss: 4.805\n",
      "[epoch 43, iterations:    20] loss: 4.926\n",
      "[epoch 43, iterations:    25] loss: 4.849\n",
      "[epoch 43, iterations:    30] loss: 4.909\n",
      "[epoch 43, iterations:    35] loss: 4.430\n",
      "[epoch 43, iterations:    40] loss: 4.282\n",
      "[epoch 43, iterations:    45] loss: 5.338\n",
      "[epoch 43, iterations:    50] loss: 4.241\n",
      "[epoch 43, iterations:    55] loss: 4.215\n",
      "[epoch 43, iterations:    60] loss: 4.514\n",
      "[epoch 43, iterations:    65] loss: 4.946\n",
      "[epoch 43, iterations:    70] loss: 4.114\n",
      "[epoch 43, iterations:    75] loss: 5.035\n",
      "[epoch 43, iterations:    80] loss: 4.204\n",
      "[epoch 43, iterations:    85] loss: 3.691\n",
      "[epoch 43, iterations:    90] loss: 5.341\n",
      "[epoch 43, iterations:    95] loss: 5.442\n",
      "[epoch 43, iterations:   100] loss: 5.159\n",
      "[epoch 43, iterations:   105] loss: 5.626\n",
      "[epoch 43, iterations:   110] loss: 3.869\n",
      "[epoch 43, iterations:   115] loss: 4.292\n",
      "[epoch 43, iterations:   120] loss: 3.544\n",
      "[epoch 43, iterations:   125] loss: 4.252\n",
      "[epoch 43, iterations:   130] loss: 4.078\n",
      "[epoch 43, iterations:   135] loss: 4.487\n",
      "[epoch 43, iterations:   140] loss: 3.910\n",
      "[epoch 43, iterations:   145] loss: 4.383\n",
      "[epoch 43, iterations:   150] loss: 4.165\n",
      "[epoch 43, iterations:   155] loss: 4.769\n",
      "[epoch 43, iterations:   160] loss: 4.188\n",
      "[epoch 43, iterations:   165] loss: 3.792\n",
      "[epoch 43, iterations:   170] loss: 4.036\n",
      "[epoch 43, iterations:   175] loss: 3.963\n",
      "[epoch 43, iterations:   180] loss: 4.048\n",
      "[epoch 43, iterations:   185] loss: 3.808\n",
      "[epoch 43, iterations:   190] loss: 5.636\n",
      "[epoch 43, iterations:   195] loss: 4.933\n",
      "[epoch 43, iterations:   200] loss: 4.157\n",
      "[epoch 43, iterations:   205] loss: 4.059\n",
      "[epoch 43, iterations:   210] loss: 4.405\n",
      "[epoch 43, iterations:   215] loss: 4.109\n",
      "[epoch 43, iterations:   220] loss: 3.729\n",
      "[epoch 43, iterations:   225] loss: 3.976\n",
      "[epoch 43, iterations:   230] loss: 4.899\n",
      "[epoch 43, iterations:   235] loss: 5.477\n",
      "[epoch 43, iterations:   240] loss: 4.975\n",
      "[epoch 43, iterations:   245] loss: 5.086\n",
      "[epoch 43, iterations:   250] loss: 4.752\n",
      "[epoch 43, iterations:   255] loss: 4.894\n",
      "[epoch 43, iterations:   260] loss: 4.934\n",
      "[epoch 43, iterations:   265] loss: 5.043\n",
      "[epoch 43, iterations:   270] loss: 4.973\n",
      "[epoch 43, iterations:   275] loss: 4.992\n",
      "[epoch 43, iterations:   280] loss: 4.756\n",
      "[epoch 43, iterations:   285] loss: 5.010\n",
      "[epoch 43, iterations:   290] loss: 4.890\n",
      "[epoch 43, iterations:   295] loss: 5.194\n",
      "[epoch 43, iterations:   300] loss: 5.147\n",
      "[epoch 43, iterations:   305] loss: 5.335\n",
      "[epoch 43, iterations:   310] loss: 5.636\n",
      "[epoch 43, iterations:   315] loss: 5.475\n",
      "[epoch 43, iterations:   320] loss: 4.853\n",
      "[epoch 43, iterations:   325] loss: 5.122\n",
      "[epoch 43, iterations:   330] loss: 4.952\n",
      "[epoch 43, iterations:   335] loss: 4.973\n",
      "[epoch 43, iterations:   340] loss: 5.138\n",
      "[epoch 43, iterations:   345] loss: 5.024\n",
      "[epoch 43, iterations:   350] loss: 5.521\n",
      "[epoch 43, iterations:   355] loss: 4.889\n",
      "[epoch 43, iterations:   360] loss: 5.068\n",
      "[epoch 43, iterations:   365] loss: 5.133\n",
      "[epoch 43, iterations:   370] loss: 5.448\n",
      "[epoch 43, iterations:   375] loss: 4.853\n",
      "[epoch 43, iterations:   380] loss: 5.006\n",
      "[epoch 43, iterations:   385] loss: 4.836\n",
      "[epoch 43, iterations:   390] loss: 4.605\n",
      "[epoch 43, iterations:   395] loss: 5.294\n",
      "[epoch 43, iterations:   400] loss: 5.371\n",
      "[epoch 44, iterations:     5] loss: 5.035\n",
      "[epoch 44, iterations:    10] loss: 4.996\n",
      "[epoch 44, iterations:    15] loss: 5.062\n",
      "[epoch 44, iterations:    20] loss: 4.874\n",
      "[epoch 44, iterations:    25] loss: 4.906\n",
      "[epoch 44, iterations:    30] loss: 4.789\n",
      "[epoch 44, iterations:    35] loss: 4.785\n",
      "[epoch 44, iterations:    40] loss: 5.063\n",
      "[epoch 44, iterations:    45] loss: 4.963\n",
      "[epoch 44, iterations:    50] loss: 4.753\n",
      "[epoch 44, iterations:    55] loss: 5.014\n",
      "[epoch 44, iterations:    60] loss: 4.828\n",
      "[epoch 44, iterations:    65] loss: 5.390\n",
      "[epoch 44, iterations:    70] loss: 4.851\n",
      "[epoch 44, iterations:    75] loss: 5.147\n",
      "[epoch 44, iterations:    80] loss: 4.910\n",
      "[epoch 44, iterations:    85] loss: 4.917\n",
      "[epoch 44, iterations:    90] loss: 4.507\n",
      "[epoch 44, iterations:    95] loss: 5.161\n",
      "[epoch 44, iterations:   100] loss: 4.852\n",
      "[epoch 44, iterations:   105] loss: 4.930\n",
      "[epoch 44, iterations:   110] loss: 4.842\n",
      "[epoch 44, iterations:   115] loss: 4.484\n",
      "[epoch 44, iterations:   120] loss: 4.520\n",
      "[epoch 44, iterations:   125] loss: 5.251\n",
      "[epoch 44, iterations:   130] loss: 4.464\n",
      "[epoch 44, iterations:   135] loss: 4.274\n",
      "[epoch 44, iterations:   140] loss: 4.459\n",
      "[epoch 44, iterations:   145] loss: 4.490\n",
      "[epoch 44, iterations:   150] loss: 4.479\n",
      "[epoch 44, iterations:   155] loss: 4.565\n",
      "[epoch 44, iterations:   160] loss: 4.304\n",
      "[epoch 44, iterations:   165] loss: 4.314\n",
      "[epoch 44, iterations:   170] loss: 4.342\n",
      "[epoch 44, iterations:   175] loss: 4.485\n",
      "[epoch 44, iterations:   180] loss: 4.913\n",
      "[epoch 44, iterations:   185] loss: 4.347\n",
      "[epoch 44, iterations:   190] loss: 5.600\n",
      "[epoch 44, iterations:   195] loss: 5.237\n",
      "[epoch 44, iterations:   200] loss: 4.721\n",
      "[epoch 44, iterations:   205] loss: 4.938\n",
      "[epoch 44, iterations:   210] loss: 4.818\n",
      "[epoch 44, iterations:   215] loss: 5.155\n",
      "[epoch 44, iterations:   220] loss: 4.548\n",
      "[epoch 44, iterations:   225] loss: 4.893\n",
      "[epoch 44, iterations:   230] loss: 4.473\n",
      "[epoch 44, iterations:   235] loss: 4.404\n",
      "[epoch 44, iterations:   240] loss: 4.228\n",
      "[epoch 44, iterations:   245] loss: 4.326\n",
      "[epoch 44, iterations:   250] loss: 4.383\n",
      "[epoch 44, iterations:   255] loss: 4.177\n",
      "[epoch 44, iterations:   260] loss: 4.586\n",
      "[epoch 44, iterations:   265] loss: 4.720\n",
      "[epoch 44, iterations:   270] loss: 4.212\n",
      "[epoch 44, iterations:   275] loss: 4.088\n",
      "[epoch 44, iterations:   280] loss: 4.162\n",
      "[epoch 44, iterations:   285] loss: 4.300\n",
      "[epoch 44, iterations:   290] loss: 4.009\n",
      "[epoch 44, iterations:   295] loss: 4.400\n",
      "[epoch 44, iterations:   300] loss: 4.491\n",
      "[epoch 44, iterations:   305] loss: 4.201\n",
      "[epoch 44, iterations:   310] loss: 5.072\n",
      "[epoch 44, iterations:   315] loss: 6.044\n",
      "[epoch 44, iterations:   320] loss: 5.036\n",
      "[epoch 44, iterations:   325] loss: 5.445\n",
      "[epoch 44, iterations:   330] loss: 3.873\n",
      "[epoch 44, iterations:   335] loss: 4.753\n",
      "[epoch 44, iterations:   340] loss: 4.967\n",
      "[epoch 44, iterations:   345] loss: 4.570\n",
      "[epoch 44, iterations:   350] loss: 4.850\n",
      "[epoch 44, iterations:   355] loss: 4.671\n",
      "[epoch 44, iterations:   360] loss: 4.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 44, iterations:   365] loss: 4.670\n",
      "[epoch 44, iterations:   370] loss: 4.654\n",
      "[epoch 44, iterations:   375] loss: 4.412\n",
      "[epoch 44, iterations:   380] loss: 4.020\n",
      "[epoch 44, iterations:   385] loss: 4.855\n",
      "[epoch 44, iterations:   390] loss: 4.911\n",
      "[epoch 44, iterations:   395] loss: 4.824\n",
      "[epoch 44, iterations:   400] loss: 4.873\n",
      "[epoch 45, iterations:     5] loss: 4.697\n",
      "[epoch 45, iterations:    10] loss: 4.932\n",
      "[epoch 45, iterations:    15] loss: 4.841\n",
      "[epoch 45, iterations:    20] loss: 5.066\n",
      "[epoch 45, iterations:    25] loss: 4.281\n",
      "[epoch 45, iterations:    30] loss: 4.367\n",
      "[epoch 45, iterations:    35] loss: 4.399\n",
      "[epoch 45, iterations:    40] loss: 4.878\n",
      "[epoch 45, iterations:    45] loss: 4.593\n",
      "[epoch 45, iterations:    50] loss: 4.707\n",
      "[epoch 45, iterations:    55] loss: 4.794\n",
      "[epoch 45, iterations:    60] loss: 4.551\n",
      "[epoch 45, iterations:    65] loss: 4.752\n",
      "[epoch 45, iterations:    70] loss: 4.071\n",
      "[epoch 45, iterations:    75] loss: 4.362\n",
      "[epoch 45, iterations:    80] loss: 4.209\n",
      "[epoch 45, iterations:    85] loss: 3.991\n",
      "[epoch 45, iterations:    90] loss: 4.141\n",
      "[epoch 45, iterations:    95] loss: 3.912\n",
      "[epoch 45, iterations:   100] loss: 4.356\n",
      "[epoch 45, iterations:   105] loss: 4.277\n",
      "[epoch 45, iterations:   110] loss: 4.000\n",
      "[epoch 45, iterations:   115] loss: 4.778\n",
      "[epoch 45, iterations:   120] loss: 4.658\n",
      "[epoch 45, iterations:   125] loss: 4.842\n",
      "[epoch 45, iterations:   130] loss: 4.222\n",
      "[epoch 45, iterations:   135] loss: 4.136\n",
      "[epoch 45, iterations:   140] loss: 4.253\n",
      "[epoch 45, iterations:   145] loss: 4.525\n",
      "[epoch 45, iterations:   150] loss: 4.807\n",
      "[epoch 45, iterations:   155] loss: 4.741\n",
      "[epoch 45, iterations:   160] loss: 4.729\n",
      "[epoch 45, iterations:   165] loss: 5.000\n",
      "[epoch 45, iterations:   170] loss: 4.757\n",
      "[epoch 45, iterations:   175] loss: 5.010\n",
      "[epoch 45, iterations:   180] loss: 4.995\n",
      "[epoch 45, iterations:   185] loss: 5.130\n",
      "[epoch 45, iterations:   190] loss: 5.015\n",
      "[epoch 45, iterations:   195] loss: 4.860\n",
      "[epoch 45, iterations:   200] loss: 5.122\n",
      "[epoch 45, iterations:   205] loss: 4.707\n",
      "[epoch 45, iterations:   210] loss: 5.006\n",
      "[epoch 45, iterations:   215] loss: 5.023\n",
      "[epoch 45, iterations:   220] loss: 4.899\n",
      "[epoch 45, iterations:   225] loss: 4.977\n",
      "[epoch 45, iterations:   230] loss: 4.758\n",
      "[epoch 45, iterations:   235] loss: 4.884\n",
      "[epoch 45, iterations:   240] loss: 4.995\n",
      "[epoch 45, iterations:   245] loss: 4.714\n",
      "[epoch 45, iterations:   250] loss: 4.941\n",
      "[epoch 45, iterations:   255] loss: 4.860\n",
      "[epoch 45, iterations:   260] loss: 4.843\n",
      "[epoch 45, iterations:   265] loss: 4.914\n",
      "[epoch 45, iterations:   270] loss: 4.772\n",
      "[epoch 45, iterations:   275] loss: 4.717\n",
      "[epoch 45, iterations:   280] loss: 4.284\n",
      "[epoch 45, iterations:   285] loss: 4.195\n",
      "[epoch 45, iterations:   290] loss: 4.208\n",
      "[epoch 45, iterations:   295] loss: 3.814\n",
      "[epoch 45, iterations:   300] loss: 4.190\n",
      "[epoch 45, iterations:   305] loss: 4.495\n",
      "[epoch 45, iterations:   310] loss: 4.749\n",
      "[epoch 45, iterations:   315] loss: 4.671\n",
      "[epoch 45, iterations:   320] loss: 4.786\n",
      "[epoch 45, iterations:   325] loss: 5.137\n",
      "[epoch 45, iterations:   330] loss: 5.170\n",
      "[epoch 45, iterations:   335] loss: 4.815\n",
      "[epoch 45, iterations:   340] loss: 5.111\n",
      "[epoch 45, iterations:   345] loss: 5.220\n",
      "[epoch 45, iterations:   350] loss: 5.094\n",
      "[epoch 45, iterations:   355] loss: 5.054\n",
      "[epoch 45, iterations:   360] loss: 5.128\n",
      "[epoch 45, iterations:   365] loss: 4.804\n",
      "[epoch 45, iterations:   370] loss: 4.569\n",
      "[epoch 45, iterations:   375] loss: 4.679\n",
      "[epoch 45, iterations:   380] loss: 4.866\n",
      "[epoch 45, iterations:   385] loss: 4.701\n",
      "[epoch 45, iterations:   390] loss: 4.370\n",
      "[epoch 45, iterations:   395] loss: 4.276\n",
      "[epoch 45, iterations:   400] loss: 4.803\n",
      "[epoch 46, iterations:     5] loss: 4.706\n",
      "[epoch 46, iterations:    10] loss: 4.846\n",
      "[epoch 46, iterations:    15] loss: 5.694\n",
      "[epoch 46, iterations:    20] loss: 4.931\n",
      "[epoch 46, iterations:    25] loss: 4.849\n",
      "[epoch 46, iterations:    30] loss: 5.078\n",
      "[epoch 46, iterations:    35] loss: 5.377\n",
      "[epoch 46, iterations:    40] loss: 4.960\n",
      "[epoch 46, iterations:    45] loss: 5.115\n",
      "[epoch 46, iterations:    50] loss: 5.031\n",
      "[epoch 46, iterations:    55] loss: 5.001\n",
      "[epoch 46, iterations:    60] loss: 4.931\n",
      "[epoch 46, iterations:    65] loss: 5.246\n",
      "[epoch 46, iterations:    70] loss: 5.266\n",
      "[epoch 46, iterations:    75] loss: 5.012\n",
      "[epoch 46, iterations:    80] loss: 5.287\n",
      "[epoch 46, iterations:    85] loss: 5.151\n",
      "[epoch 46, iterations:    90] loss: 4.826\n",
      "[epoch 46, iterations:    95] loss: 5.288\n",
      "[epoch 46, iterations:   100] loss: 4.808\n",
      "[epoch 46, iterations:   105] loss: 5.269\n",
      "[epoch 46, iterations:   110] loss: 5.185\n",
      "[epoch 46, iterations:   115] loss: 5.088\n",
      "[epoch 46, iterations:   120] loss: 5.144\n",
      "[epoch 46, iterations:   125] loss: 5.021\n",
      "[epoch 46, iterations:   130] loss: 5.030\n",
      "[epoch 46, iterations:   135] loss: 5.010\n",
      "[epoch 46, iterations:   140] loss: 4.961\n",
      "[epoch 46, iterations:   145] loss: 5.020\n",
      "[epoch 46, iterations:   150] loss: 4.989\n",
      "[epoch 46, iterations:   155] loss: 4.896\n",
      "[epoch 46, iterations:   160] loss: 5.258\n",
      "[epoch 46, iterations:   165] loss: 5.126\n",
      "[epoch 46, iterations:   170] loss: 4.830\n",
      "[epoch 46, iterations:   175] loss: 5.077\n",
      "[epoch 46, iterations:   180] loss: 5.066\n",
      "[epoch 46, iterations:   185] loss: 5.006\n",
      "[epoch 46, iterations:   190] loss: 5.170\n",
      "[epoch 46, iterations:   195] loss: 5.415\n",
      "[epoch 46, iterations:   200] loss: 4.903\n",
      "[epoch 46, iterations:   205] loss: 4.943\n",
      "[epoch 46, iterations:   210] loss: 5.459\n",
      "[epoch 46, iterations:   215] loss: 4.929\n",
      "[epoch 46, iterations:   220] loss: 5.339\n",
      "[epoch 46, iterations:   225] loss: 4.659\n",
      "[epoch 46, iterations:   230] loss: 5.335\n",
      "[epoch 46, iterations:   235] loss: 4.921\n",
      "[epoch 46, iterations:   240] loss: 5.134\n",
      "[epoch 46, iterations:   245] loss: 4.700\n",
      "[epoch 46, iterations:   250] loss: 4.883\n",
      "[epoch 46, iterations:   255] loss: 4.900\n",
      "[epoch 46, iterations:   260] loss: 4.870\n",
      "[epoch 46, iterations:   265] loss: 5.354\n",
      "[epoch 46, iterations:   270] loss: 4.821\n",
      "[epoch 46, iterations:   275] loss: 4.909\n",
      "[epoch 46, iterations:   280] loss: 4.849\n",
      "[epoch 46, iterations:   285] loss: 5.137\n",
      "[epoch 46, iterations:   290] loss: 4.849\n",
      "[epoch 46, iterations:   295] loss: 5.155\n",
      "[epoch 46, iterations:   300] loss: 5.089\n",
      "[epoch 46, iterations:   305] loss: 5.006\n",
      "[epoch 46, iterations:   310] loss: 4.644\n",
      "[epoch 46, iterations:   315] loss: 4.638\n",
      "[epoch 46, iterations:   320] loss: 4.785\n",
      "[epoch 46, iterations:   325] loss: 5.204\n",
      "[epoch 46, iterations:   330] loss: 4.658\n",
      "[epoch 46, iterations:   335] loss: 4.798\n",
      "[epoch 46, iterations:   340] loss: 4.694\n",
      "[epoch 46, iterations:   345] loss: 4.868\n",
      "[epoch 46, iterations:   350] loss: 4.910\n",
      "[epoch 46, iterations:   355] loss: 4.952\n",
      "[epoch 46, iterations:   360] loss: 4.885\n",
      "[epoch 46, iterations:   365] loss: 5.019\n",
      "[epoch 46, iterations:   370] loss: 4.865\n",
      "[epoch 46, iterations:   375] loss: 4.925\n",
      "[epoch 46, iterations:   380] loss: 4.808\n",
      "[epoch 46, iterations:   385] loss: 5.014\n",
      "[epoch 46, iterations:   390] loss: 4.877\n",
      "[epoch 46, iterations:   395] loss: 4.518\n",
      "[epoch 46, iterations:   400] loss: 4.713\n",
      "[epoch 47, iterations:     5] loss: 4.779\n",
      "[epoch 47, iterations:    10] loss: 4.568\n",
      "[epoch 47, iterations:    15] loss: 4.305\n",
      "[epoch 47, iterations:    20] loss: 4.003\n",
      "[epoch 47, iterations:    25] loss: 4.266\n",
      "[epoch 47, iterations:    30] loss: 4.322\n",
      "[epoch 47, iterations:    35] loss: 4.182\n",
      "[epoch 47, iterations:    40] loss: 5.013\n",
      "[epoch 47, iterations:    45] loss: 3.560\n",
      "[epoch 47, iterations:    50] loss: 3.700\n",
      "[epoch 47, iterations:    55] loss: 4.043\n",
      "[epoch 47, iterations:    60] loss: 3.645\n",
      "[epoch 47, iterations:    65] loss: 4.580\n",
      "[epoch 47, iterations:    70] loss: 4.671\n",
      "[epoch 47, iterations:    75] loss: 4.416\n",
      "[epoch 47, iterations:    80] loss: 3.949\n",
      "[epoch 47, iterations:    85] loss: 3.734\n",
      "[epoch 47, iterations:    90] loss: 4.573\n",
      "[epoch 47, iterations:    95] loss: 4.487\n",
      "[epoch 47, iterations:   100] loss: 4.221\n",
      "[epoch 47, iterations:   105] loss: 3.235\n",
      "[epoch 47, iterations:   110] loss: 3.435\n",
      "[epoch 47, iterations:   115] loss: 3.763\n",
      "[epoch 47, iterations:   120] loss: 3.543\n",
      "[epoch 47, iterations:   125] loss: 5.088\n",
      "[epoch 47, iterations:   130] loss: 3.819\n",
      "[epoch 47, iterations:   135] loss: 4.383\n",
      "[epoch 47, iterations:   140] loss: 4.904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 47, iterations:   145] loss: 4.665\n",
      "[epoch 47, iterations:   150] loss: 4.483\n",
      "[epoch 47, iterations:   155] loss: 4.740\n",
      "[epoch 47, iterations:   160] loss: 4.113\n",
      "[epoch 47, iterations:   165] loss: 3.995\n",
      "[epoch 47, iterations:   170] loss: 4.790\n",
      "[epoch 47, iterations:   175] loss: 5.059\n",
      "[epoch 47, iterations:   180] loss: 5.391\n",
      "[epoch 47, iterations:   185] loss: 4.657\n",
      "[epoch 47, iterations:   190] loss: 4.961\n",
      "[epoch 47, iterations:   195] loss: 4.888\n",
      "[epoch 47, iterations:   200] loss: 5.256\n",
      "[epoch 47, iterations:   205] loss: 5.142\n",
      "[epoch 47, iterations:   210] loss: 4.665\n",
      "[epoch 47, iterations:   215] loss: 4.975\n",
      "[epoch 47, iterations:   220] loss: 4.668\n",
      "[epoch 47, iterations:   225] loss: 4.481\n",
      "[epoch 47, iterations:   230] loss: 4.199\n",
      "[epoch 47, iterations:   235] loss: 3.988\n",
      "[epoch 47, iterations:   240] loss: 4.070\n",
      "[epoch 47, iterations:   245] loss: 5.212\n",
      "[epoch 47, iterations:   250] loss: 3.702\n",
      "[epoch 47, iterations:   255] loss: 4.010\n",
      "[epoch 47, iterations:   260] loss: 2.908\n",
      "[epoch 47, iterations:   265] loss: 3.570\n",
      "[epoch 47, iterations:   270] loss: 3.289\n",
      "[epoch 47, iterations:   275] loss: 3.853\n",
      "[epoch 47, iterations:   280] loss: 3.709\n",
      "[epoch 47, iterations:   285] loss: 3.964\n",
      "[epoch 47, iterations:   290] loss: 3.125\n",
      "[epoch 47, iterations:   295] loss: 3.992\n",
      "[epoch 47, iterations:   300] loss: 3.999\n",
      "[epoch 47, iterations:   305] loss: 3.588\n",
      "[epoch 47, iterations:   310] loss: 3.835\n",
      "[epoch 47, iterations:   315] loss: 3.717\n",
      "[epoch 47, iterations:   320] loss: 4.009\n",
      "[epoch 47, iterations:   325] loss: 4.955\n",
      "[epoch 47, iterations:   330] loss: 4.411\n",
      "[epoch 47, iterations:   335] loss: 4.790\n",
      "[epoch 47, iterations:   340] loss: 4.827\n",
      "[epoch 47, iterations:   345] loss: 4.517\n",
      "[epoch 47, iterations:   350] loss: 4.894\n",
      "[epoch 47, iterations:   355] loss: 4.316\n",
      "[epoch 47, iterations:   360] loss: 4.347\n",
      "[epoch 47, iterations:   365] loss: 3.667\n",
      "[epoch 47, iterations:   370] loss: 3.468\n",
      "[epoch 47, iterations:   375] loss: 3.625\n",
      "[epoch 47, iterations:   380] loss: 3.802\n",
      "[epoch 47, iterations:   385] loss: 3.959\n",
      "[epoch 47, iterations:   390] loss: 4.270\n",
      "[epoch 47, iterations:   395] loss: 4.202\n",
      "[epoch 47, iterations:   400] loss: 4.275\n",
      "[epoch 48, iterations:     5] loss: 4.078\n",
      "[epoch 48, iterations:    10] loss: 3.661\n",
      "[epoch 48, iterations:    15] loss: 3.635\n",
      "[epoch 48, iterations:    20] loss: 3.369\n",
      "[epoch 48, iterations:    25] loss: 4.274\n",
      "[epoch 48, iterations:    30] loss: 4.312\n",
      "[epoch 48, iterations:    35] loss: 4.010\n",
      "[epoch 48, iterations:    40] loss: 4.093\n",
      "[epoch 48, iterations:    45] loss: 4.183\n",
      "[epoch 48, iterations:    50] loss: 4.383\n",
      "[epoch 48, iterations:    55] loss: 4.038\n",
      "[epoch 48, iterations:    60] loss: 4.750\n",
      "[epoch 48, iterations:    65] loss: 4.640\n",
      "[epoch 48, iterations:    70] loss: 4.612\n",
      "[epoch 48, iterations:    75] loss: 3.379\n",
      "[epoch 48, iterations:    80] loss: 4.070\n",
      "[epoch 48, iterations:    85] loss: 4.773\n",
      "[epoch 48, iterations:    90] loss: 4.847\n",
      "[epoch 48, iterations:    95] loss: 5.034\n",
      "[epoch 48, iterations:   100] loss: 5.221\n",
      "[epoch 48, iterations:   105] loss: 4.811\n",
      "[epoch 48, iterations:   110] loss: 5.133\n",
      "[epoch 48, iterations:   115] loss: 4.886\n",
      "[epoch 48, iterations:   120] loss: 4.776\n",
      "[epoch 48, iterations:   125] loss: 4.819\n",
      "[epoch 48, iterations:   130] loss: 5.037\n",
      "[epoch 48, iterations:   135] loss: 4.919\n",
      "[epoch 48, iterations:   140] loss: 5.207\n",
      "[epoch 48, iterations:   145] loss: 5.050\n",
      "[epoch 48, iterations:   150] loss: 4.528\n",
      "[epoch 48, iterations:   155] loss: 4.540\n",
      "[epoch 48, iterations:   160] loss: 4.824\n",
      "[epoch 48, iterations:   165] loss: 4.573\n",
      "[epoch 48, iterations:   170] loss: 4.538\n",
      "[epoch 48, iterations:   175] loss: 4.538\n",
      "[epoch 48, iterations:   180] loss: 4.716\n",
      "[epoch 48, iterations:   185] loss: 4.433\n",
      "[epoch 48, iterations:   190] loss: 3.419\n",
      "[epoch 48, iterations:   195] loss: 4.410\n",
      "[epoch 48, iterations:   200] loss: 6.078\n",
      "[epoch 48, iterations:   205] loss: 5.522\n",
      "[epoch 48, iterations:   210] loss: 5.740\n",
      "[epoch 48, iterations:   215] loss: 5.255\n",
      "[epoch 48, iterations:   220] loss: 6.010\n",
      "[epoch 48, iterations:   225] loss: 6.128\n",
      "[epoch 48, iterations:   230] loss: 5.319\n",
      "[epoch 48, iterations:   235] loss: 5.794\n",
      "[epoch 48, iterations:   240] loss: 5.660\n",
      "[epoch 48, iterations:   245] loss: 5.538\n",
      "[epoch 48, iterations:   250] loss: 5.633\n",
      "[epoch 48, iterations:   255] loss: 5.825\n",
      "[epoch 48, iterations:   260] loss: 5.397\n",
      "[epoch 48, iterations:   265] loss: 4.907\n",
      "[epoch 48, iterations:   270] loss: 5.484\n",
      "[epoch 48, iterations:   275] loss: 5.936\n",
      "[epoch 48, iterations:   280] loss: 5.666\n",
      "[epoch 48, iterations:   285] loss: 5.405\n",
      "[epoch 48, iterations:   290] loss: 5.927\n",
      "[epoch 48, iterations:   295] loss: 5.599\n",
      "[epoch 48, iterations:   300] loss: 5.758\n",
      "[epoch 48, iterations:   305] loss: 5.448\n",
      "[epoch 48, iterations:   310] loss: 5.639\n",
      "[epoch 48, iterations:   315] loss: 5.511\n",
      "[epoch 48, iterations:   320] loss: 5.875\n",
      "[epoch 48, iterations:   325] loss: 5.402\n",
      "[epoch 48, iterations:   330] loss: 5.991\n",
      "[epoch 48, iterations:   335] loss: 5.541\n",
      "[epoch 48, iterations:   340] loss: 5.892\n",
      "[epoch 48, iterations:   345] loss: 5.676\n",
      "[epoch 48, iterations:   350] loss: 5.736\n",
      "[epoch 48, iterations:   355] loss: 5.625\n",
      "[epoch 48, iterations:   360] loss: 5.753\n",
      "[epoch 48, iterations:   365] loss: 5.459\n",
      "[epoch 48, iterations:   370] loss: 5.315\n",
      "[epoch 48, iterations:   375] loss: 5.994\n",
      "[epoch 48, iterations:   380] loss: 5.494\n",
      "[epoch 48, iterations:   385] loss: 5.611\n",
      "[epoch 48, iterations:   390] loss: 5.346\n",
      "[epoch 48, iterations:   395] loss: 5.575\n",
      "[epoch 48, iterations:   400] loss: 5.409\n",
      "[epoch 49, iterations:     5] loss: 5.992\n",
      "[epoch 49, iterations:    10] loss: 5.966\n",
      "[epoch 49, iterations:    15] loss: 5.912\n",
      "[epoch 49, iterations:    20] loss: 5.375\n",
      "[epoch 49, iterations:    25] loss: 5.259\n",
      "[epoch 49, iterations:    30] loss: 5.709\n",
      "[epoch 49, iterations:    35] loss: 5.473\n",
      "[epoch 49, iterations:    40] loss: 5.385\n",
      "[epoch 49, iterations:    45] loss: 5.059\n",
      "[epoch 49, iterations:    50] loss: 5.787\n",
      "[epoch 49, iterations:    55] loss: 5.411\n",
      "[epoch 49, iterations:    60] loss: 5.748\n",
      "[epoch 49, iterations:    65] loss: 5.858\n",
      "[epoch 49, iterations:    70] loss: 5.159\n",
      "[epoch 49, iterations:    75] loss: 5.803\n",
      "[epoch 49, iterations:    80] loss: 5.632\n",
      "[epoch 49, iterations:    85] loss: 5.753\n",
      "[epoch 49, iterations:    90] loss: 5.558\n",
      "[epoch 49, iterations:    95] loss: 5.516\n",
      "[epoch 49, iterations:   100] loss: 5.717\n",
      "[epoch 49, iterations:   105] loss: 5.308\n",
      "[epoch 49, iterations:   110] loss: 5.484\n",
      "[epoch 49, iterations:   115] loss: 5.376\n",
      "[epoch 49, iterations:   120] loss: 5.629\n",
      "[epoch 49, iterations:   125] loss: 6.023\n",
      "[epoch 49, iterations:   130] loss: 5.408\n",
      "[epoch 49, iterations:   135] loss: 5.776\n",
      "[epoch 49, iterations:   140] loss: 5.721\n",
      "[epoch 49, iterations:   145] loss: 5.431\n",
      "[epoch 49, iterations:   150] loss: 5.211\n",
      "[epoch 49, iterations:   155] loss: 5.372\n",
      "[epoch 49, iterations:   160] loss: 5.276\n",
      "[epoch 49, iterations:   165] loss: 5.726\n",
      "[epoch 49, iterations:   170] loss: 5.867\n",
      "[epoch 49, iterations:   175] loss: 5.591\n",
      "[epoch 49, iterations:   180] loss: 5.962\n",
      "[epoch 49, iterations:   185] loss: 5.692\n",
      "[epoch 49, iterations:   190] loss: 5.414\n",
      "[epoch 49, iterations:   195] loss: 5.723\n",
      "[epoch 49, iterations:   200] loss: 5.186\n",
      "[epoch 49, iterations:   205] loss: 5.594\n",
      "[epoch 49, iterations:   210] loss: 5.666\n",
      "[epoch 49, iterations:   215] loss: 5.416\n",
      "[epoch 49, iterations:   220] loss: 5.312\n",
      "[epoch 49, iterations:   225] loss: 5.989\n",
      "[epoch 49, iterations:   230] loss: 6.381\n",
      "[epoch 49, iterations:   235] loss: 5.764\n",
      "[epoch 49, iterations:   240] loss: 5.554\n",
      "[epoch 49, iterations:   245] loss: 5.717\n",
      "[epoch 49, iterations:   250] loss: 5.869\n",
      "[epoch 49, iterations:   255] loss: 5.529\n",
      "[epoch 49, iterations:   260] loss: 5.801\n",
      "[epoch 49, iterations:   265] loss: 5.538\n",
      "[epoch 49, iterations:   270] loss: 5.693\n",
      "[epoch 49, iterations:   275] loss: 5.537\n",
      "[epoch 49, iterations:   280] loss: 5.497\n",
      "[epoch 49, iterations:   285] loss: 5.574\n",
      "[epoch 49, iterations:   290] loss: 5.623\n",
      "[epoch 49, iterations:   295] loss: 5.378\n",
      "[epoch 49, iterations:   300] loss: 5.526\n",
      "[epoch 49, iterations:   305] loss: 6.300\n",
      "[epoch 49, iterations:   310] loss: 5.156\n",
      "[epoch 49, iterations:   315] loss: 5.579\n",
      "[epoch 49, iterations:   320] loss: 5.911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 49, iterations:   325] loss: 5.705\n",
      "[epoch 49, iterations:   330] loss: 5.870\n",
      "[epoch 49, iterations:   335] loss: 5.152\n",
      "[epoch 49, iterations:   340] loss: 5.720\n",
      "[epoch 49, iterations:   345] loss: 5.838\n",
      "[epoch 49, iterations:   350] loss: 5.790\n",
      "[epoch 49, iterations:   355] loss: 5.505\n",
      "[epoch 49, iterations:   360] loss: 5.211\n",
      "[epoch 49, iterations:   365] loss: 5.571\n",
      "[epoch 49, iterations:   370] loss: 5.193\n",
      "[epoch 49, iterations:   375] loss: 5.330\n",
      "[epoch 49, iterations:   380] loss: 5.647\n",
      "[epoch 49, iterations:   385] loss: 5.308\n",
      "[epoch 49, iterations:   390] loss: 5.661\n",
      "[epoch 49, iterations:   395] loss: 5.736\n",
      "[epoch 49, iterations:   400] loss: 5.455\n",
      "[epoch 50, iterations:     5] loss: 5.224\n",
      "[epoch 50, iterations:    10] loss: 5.596\n",
      "[epoch 50, iterations:    15] loss: 5.391\n",
      "[epoch 50, iterations:    20] loss: 5.520\n",
      "[epoch 50, iterations:    25] loss: 6.159\n",
      "[epoch 50, iterations:    30] loss: 5.376\n",
      "[epoch 50, iterations:    35] loss: 5.868\n",
      "[epoch 50, iterations:    40] loss: 5.298\n",
      "[epoch 50, iterations:    45] loss: 5.512\n",
      "[epoch 50, iterations:    50] loss: 5.552\n",
      "[epoch 50, iterations:    55] loss: 5.841\n",
      "[epoch 50, iterations:    60] loss: 5.701\n",
      "[epoch 50, iterations:    65] loss: 5.309\n",
      "[epoch 50, iterations:    70] loss: 5.461\n",
      "[epoch 50, iterations:    75] loss: 5.893\n",
      "[epoch 50, iterations:    80] loss: 5.620\n",
      "[epoch 50, iterations:    85] loss: 5.827\n",
      "[epoch 50, iterations:    90] loss: 5.921\n",
      "[epoch 50, iterations:    95] loss: 5.358\n",
      "[epoch 50, iterations:   100] loss: 5.006\n",
      "[epoch 50, iterations:   105] loss: 5.431\n",
      "[epoch 50, iterations:   110] loss: 5.683\n",
      "[epoch 50, iterations:   115] loss: 5.494\n",
      "[epoch 50, iterations:   120] loss: 5.473\n",
      "[epoch 50, iterations:   125] loss: 5.531\n",
      "[epoch 50, iterations:   130] loss: 5.122\n",
      "[epoch 50, iterations:   135] loss: 5.311\n",
      "[epoch 50, iterations:   140] loss: 5.330\n",
      "[epoch 50, iterations:   145] loss: 5.301\n",
      "[epoch 50, iterations:   150] loss: 6.104\n",
      "[epoch 50, iterations:   155] loss: 5.438\n",
      "[epoch 50, iterations:   160] loss: 5.349\n",
      "[epoch 50, iterations:   165] loss: 5.258\n",
      "[epoch 50, iterations:   170] loss: 5.770\n",
      "[epoch 50, iterations:   175] loss: 5.686\n",
      "[epoch 50, iterations:   180] loss: 5.566\n",
      "[epoch 50, iterations:   185] loss: 5.436\n",
      "[epoch 50, iterations:   190] loss: 5.397\n",
      "[epoch 50, iterations:   195] loss: 6.035\n",
      "[epoch 50, iterations:   200] loss: 5.918\n",
      "[epoch 50, iterations:   205] loss: 5.400\n",
      "[epoch 50, iterations:   210] loss: 5.525\n",
      "[epoch 50, iterations:   215] loss: 5.741\n",
      "[epoch 50, iterations:   220] loss: 5.865\n",
      "[epoch 50, iterations:   225] loss: 5.774\n",
      "[epoch 50, iterations:   230] loss: 5.943\n",
      "[epoch 50, iterations:   235] loss: 5.177\n",
      "[epoch 50, iterations:   240] loss: 5.424\n",
      "[epoch 50, iterations:   245] loss: 5.310\n",
      "[epoch 50, iterations:   250] loss: 5.385\n",
      "[epoch 50, iterations:   255] loss: 5.736\n",
      "[epoch 50, iterations:   260] loss: 5.543\n",
      "[epoch 50, iterations:   265] loss: 5.397\n",
      "[epoch 50, iterations:   270] loss: 5.260\n",
      "[epoch 50, iterations:   275] loss: 5.457\n",
      "[epoch 50, iterations:   280] loss: 6.084\n",
      "[epoch 50, iterations:   285] loss: 5.753\n",
      "[epoch 50, iterations:   290] loss: 5.955\n",
      "[epoch 50, iterations:   295] loss: 5.603\n",
      "[epoch 50, iterations:   300] loss: 5.297\n",
      "[epoch 50, iterations:   305] loss: 5.271\n",
      "[epoch 50, iterations:   310] loss: 5.323\n",
      "[epoch 50, iterations:   315] loss: 5.300\n",
      "[epoch 50, iterations:   320] loss: 6.166\n",
      "[epoch 50, iterations:   325] loss: 5.828\n",
      "[epoch 50, iterations:   330] loss: 5.725\n",
      "[epoch 50, iterations:   335] loss: 5.547\n",
      "[epoch 50, iterations:   340] loss: 5.382\n",
      "[epoch 50, iterations:   345] loss: 5.392\n",
      "[epoch 50, iterations:   350] loss: 5.503\n",
      "[epoch 50, iterations:   355] loss: 5.783\n",
      "[epoch 50, iterations:   360] loss: 5.706\n",
      "[epoch 50, iterations:   365] loss: 5.335\n",
      "[epoch 50, iterations:   370] loss: 5.292\n",
      "[epoch 50, iterations:   375] loss: 6.003\n",
      "[epoch 50, iterations:   380] loss: 5.357\n",
      "[epoch 50, iterations:   385] loss: 5.064\n",
      "[epoch 50, iterations:   390] loss: 5.528\n",
      "[epoch 50, iterations:   395] loss: 6.119\n",
      "[epoch 50, iterations:   400] loss: 5.761\n",
      "[epoch 51, iterations:     5] loss: 5.661\n",
      "[epoch 51, iterations:    10] loss: 5.603\n",
      "[epoch 51, iterations:    15] loss: 5.522\n",
      "[epoch 51, iterations:    20] loss: 5.770\n",
      "[epoch 51, iterations:    25] loss: 5.616\n",
      "[epoch 51, iterations:    30] loss: 5.428\n",
      "[epoch 51, iterations:    35] loss: 5.267\n",
      "[epoch 51, iterations:    40] loss: 5.937\n",
      "[epoch 51, iterations:    45] loss: 5.726\n",
      "[epoch 51, iterations:    50] loss: 5.717\n",
      "[epoch 51, iterations:    55] loss: 5.694\n",
      "[epoch 51, iterations:    60] loss: 5.898\n",
      "[epoch 51, iterations:    65] loss: 5.280\n",
      "[epoch 51, iterations:    70] loss: 6.112\n",
      "[epoch 51, iterations:    75] loss: 5.426\n",
      "[epoch 51, iterations:    80] loss: 5.760\n",
      "[epoch 51, iterations:    85] loss: 5.220\n",
      "[epoch 51, iterations:    90] loss: 5.096\n",
      "[epoch 51, iterations:    95] loss: 5.512\n",
      "[epoch 51, iterations:   100] loss: 5.288\n",
      "[epoch 51, iterations:   105] loss: 5.722\n",
      "[epoch 51, iterations:   110] loss: 5.461\n",
      "[epoch 51, iterations:   115] loss: 6.050\n",
      "[epoch 51, iterations:   120] loss: 5.752\n",
      "[epoch 51, iterations:   125] loss: 5.543\n",
      "[epoch 51, iterations:   130] loss: 5.660\n",
      "[epoch 51, iterations:   135] loss: 5.392\n",
      "[epoch 51, iterations:   140] loss: 5.341\n",
      "[epoch 51, iterations:   145] loss: 5.066\n",
      "[epoch 51, iterations:   150] loss: 5.342\n",
      "[epoch 51, iterations:   155] loss: 5.583\n",
      "[epoch 51, iterations:   160] loss: 5.548\n",
      "[epoch 51, iterations:   165] loss: 5.267\n",
      "[epoch 51, iterations:   170] loss: 6.254\n",
      "[epoch 51, iterations:   175] loss: 5.456\n",
      "[epoch 51, iterations:   180] loss: 5.965\n",
      "[epoch 51, iterations:   185] loss: 5.785\n",
      "[epoch 51, iterations:   190] loss: 5.528\n",
      "[epoch 51, iterations:   195] loss: 5.695\n",
      "[epoch 51, iterations:   200] loss: 5.241\n",
      "[epoch 51, iterations:   205] loss: 5.576\n",
      "[epoch 51, iterations:   210] loss: 5.646\n",
      "[epoch 51, iterations:   215] loss: 5.817\n",
      "[epoch 51, iterations:   220] loss: 4.788\n",
      "[epoch 51, iterations:   225] loss: 5.387\n",
      "[epoch 51, iterations:   230] loss: 5.510\n",
      "[epoch 51, iterations:   235] loss: 5.495\n",
      "[epoch 51, iterations:   240] loss: 5.463\n",
      "[epoch 51, iterations:   245] loss: 6.001\n",
      "[epoch 51, iterations:   250] loss: 5.343\n",
      "[epoch 51, iterations:   255] loss: 5.404\n",
      "[epoch 51, iterations:   260] loss: 5.413\n",
      "[epoch 51, iterations:   265] loss: 5.486\n",
      "[epoch 51, iterations:   270] loss: 5.485\n",
      "[epoch 51, iterations:   275] loss: 5.707\n",
      "[epoch 51, iterations:   280] loss: 5.509\n",
      "[epoch 51, iterations:   285] loss: 5.691\n",
      "[epoch 51, iterations:   290] loss: 5.594\n",
      "[epoch 51, iterations:   295] loss: 5.348\n",
      "[epoch 51, iterations:   300] loss: 5.318\n",
      "[epoch 51, iterations:   305] loss: 4.983\n",
      "[epoch 51, iterations:   310] loss: 5.253\n",
      "[epoch 51, iterations:   315] loss: 5.549\n",
      "[epoch 51, iterations:   320] loss: 5.345\n",
      "[epoch 51, iterations:   325] loss: 5.688\n",
      "[epoch 51, iterations:   330] loss: 5.368\n",
      "[epoch 51, iterations:   335] loss: 5.242\n",
      "[epoch 51, iterations:   340] loss: 5.370\n",
      "[epoch 51, iterations:   345] loss: 5.477\n",
      "[epoch 51, iterations:   350] loss: 5.643\n",
      "[epoch 51, iterations:   355] loss: 5.544\n",
      "[epoch 51, iterations:   360] loss: 5.714\n",
      "[epoch 51, iterations:   365] loss: 5.439\n",
      "[epoch 51, iterations:   370] loss: 5.374\n",
      "[epoch 51, iterations:   375] loss: 5.155\n",
      "[epoch 51, iterations:   380] loss: 5.436\n",
      "[epoch 51, iterations:   385] loss: 5.822\n",
      "[epoch 51, iterations:   390] loss: 5.074\n",
      "[epoch 51, iterations:   395] loss: 6.123\n",
      "[epoch 51, iterations:   400] loss: 6.074\n",
      "[epoch 52, iterations:     5] loss: 5.384\n",
      "[epoch 52, iterations:    10] loss: 5.674\n",
      "[epoch 52, iterations:    15] loss: 5.181\n",
      "[epoch 52, iterations:    20] loss: 5.670\n",
      "[epoch 52, iterations:    25] loss: 5.689\n",
      "[epoch 52, iterations:    30] loss: 5.376\n",
      "[epoch 52, iterations:    35] loss: 5.800\n",
      "[epoch 52, iterations:    40] loss: 5.217\n",
      "[epoch 52, iterations:    45] loss: 5.480\n",
      "[epoch 52, iterations:    50] loss: 5.408\n",
      "[epoch 52, iterations:    55] loss: 5.477\n",
      "[epoch 52, iterations:    60] loss: 5.715\n",
      "[epoch 52, iterations:    65] loss: 5.752\n",
      "[epoch 52, iterations:    70] loss: 5.369\n",
      "[epoch 52, iterations:    75] loss: 5.727\n",
      "[epoch 52, iterations:    80] loss: 5.826\n",
      "[epoch 52, iterations:    85] loss: 5.742\n",
      "[epoch 52, iterations:    90] loss: 5.366\n",
      "[epoch 52, iterations:    95] loss: 5.629\n",
      "[epoch 52, iterations:   100] loss: 6.249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 52, iterations:   105] loss: 5.360\n",
      "[epoch 52, iterations:   110] loss: 5.365\n",
      "[epoch 52, iterations:   115] loss: 5.158\n",
      "[epoch 52, iterations:   120] loss: 5.942\n",
      "[epoch 52, iterations:   125] loss: 5.582\n",
      "[epoch 52, iterations:   130] loss: 5.992\n",
      "[epoch 52, iterations:   135] loss: 5.396\n",
      "[epoch 52, iterations:   140] loss: 5.073\n",
      "[epoch 52, iterations:   145] loss: 5.979\n",
      "[epoch 52, iterations:   150] loss: 5.612\n",
      "[epoch 52, iterations:   155] loss: 5.532\n",
      "[epoch 52, iterations:   160] loss: 5.484\n",
      "[epoch 52, iterations:   165] loss: 5.180\n",
      "[epoch 52, iterations:   170] loss: 5.613\n",
      "[epoch 52, iterations:   175] loss: 5.234\n",
      "[epoch 52, iterations:   180] loss: 5.892\n",
      "[epoch 52, iterations:   185] loss: 5.520\n",
      "[epoch 52, iterations:   190] loss: 5.402\n",
      "[epoch 52, iterations:   195] loss: 5.406\n",
      "[epoch 52, iterations:   200] loss: 5.827\n",
      "[epoch 52, iterations:   205] loss: 5.728\n",
      "[epoch 52, iterations:   210] loss: 5.247\n",
      "[epoch 52, iterations:   215] loss: 5.439\n",
      "[epoch 52, iterations:   220] loss: 5.742\n",
      "[epoch 52, iterations:   225] loss: 4.904\n",
      "[epoch 52, iterations:   230] loss: 5.440\n",
      "[epoch 52, iterations:   235] loss: 5.340\n",
      "[epoch 52, iterations:   240] loss: 5.730\n",
      "[epoch 52, iterations:   245] loss: 5.803\n",
      "[epoch 52, iterations:   250] loss: 5.805\n",
      "[epoch 52, iterations:   255] loss: 5.350\n",
      "[epoch 52, iterations:   260] loss: 6.044\n",
      "[epoch 52, iterations:   265] loss: 5.152\n",
      "[epoch 52, iterations:   270] loss: 5.572\n",
      "[epoch 52, iterations:   275] loss: 5.342\n",
      "[epoch 52, iterations:   280] loss: 5.550\n",
      "[epoch 52, iterations:   285] loss: 5.327\n",
      "[epoch 52, iterations:   290] loss: 5.021\n",
      "[epoch 52, iterations:   295] loss: 5.596\n",
      "[epoch 52, iterations:   300] loss: 5.620\n",
      "[epoch 52, iterations:   305] loss: 5.515\n",
      "[epoch 52, iterations:   310] loss: 5.586\n",
      "[epoch 52, iterations:   315] loss: 5.185\n",
      "[epoch 52, iterations:   320] loss: 5.497\n",
      "[epoch 52, iterations:   325] loss: 5.721\n",
      "[epoch 52, iterations:   330] loss: 5.526\n",
      "[epoch 52, iterations:   335] loss: 5.458\n",
      "[epoch 52, iterations:   340] loss: 5.514\n",
      "[epoch 52, iterations:   345] loss: 5.300\n",
      "[epoch 52, iterations:   350] loss: 5.139\n",
      "[epoch 52, iterations:   355] loss: 5.726\n",
      "[epoch 52, iterations:   360] loss: 5.396\n",
      "[epoch 52, iterations:   365] loss: 5.444\n",
      "[epoch 52, iterations:   370] loss: 5.489\n",
      "[epoch 52, iterations:   375] loss: 5.666\n",
      "[epoch 52, iterations:   380] loss: 5.351\n",
      "[epoch 52, iterations:   385] loss: 5.269\n",
      "[epoch 52, iterations:   390] loss: 5.551\n",
      "[epoch 52, iterations:   395] loss: 5.249\n",
      "[epoch 52, iterations:   400] loss: 5.198\n",
      "[epoch 53, iterations:     5] loss: 5.459\n",
      "[epoch 53, iterations:    10] loss: 5.467\n",
      "[epoch 53, iterations:    15] loss: 5.202\n",
      "[epoch 53, iterations:    20] loss: 5.427\n",
      "[epoch 53, iterations:    25] loss: 5.312\n",
      "[epoch 53, iterations:    30] loss: 5.909\n",
      "[epoch 53, iterations:    35] loss: 5.641\n",
      "[epoch 53, iterations:    40] loss: 5.498\n",
      "[epoch 53, iterations:    45] loss: 5.949\n",
      "[epoch 53, iterations:    50] loss: 5.933\n",
      "[epoch 53, iterations:    55] loss: 5.623\n",
      "[epoch 53, iterations:    60] loss: 5.489\n",
      "[epoch 53, iterations:    65] loss: 5.460\n",
      "[epoch 53, iterations:    70] loss: 5.868\n",
      "[epoch 53, iterations:    75] loss: 5.234\n",
      "[epoch 53, iterations:    80] loss: 5.371\n",
      "[epoch 53, iterations:    85] loss: 5.685\n",
      "[epoch 53, iterations:    90] loss: 5.859\n",
      "[epoch 53, iterations:    95] loss: 5.509\n",
      "[epoch 53, iterations:   100] loss: 5.460\n",
      "[epoch 53, iterations:   105] loss: 5.695\n",
      "[epoch 53, iterations:   110] loss: 5.301\n",
      "[epoch 53, iterations:   115] loss: 5.136\n",
      "[epoch 53, iterations:   120] loss: 5.421\n",
      "[epoch 53, iterations:   125] loss: 5.701\n",
      "[epoch 53, iterations:   130] loss: 5.838\n",
      "[epoch 53, iterations:   135] loss: 5.458\n",
      "[epoch 53, iterations:   140] loss: 5.018\n",
      "[epoch 53, iterations:   145] loss: 5.454\n",
      "[epoch 53, iterations:   150] loss: 5.408\n",
      "[epoch 53, iterations:   155] loss: 5.155\n",
      "[epoch 53, iterations:   160] loss: 5.581\n",
      "[epoch 53, iterations:   165] loss: 5.397\n",
      "[epoch 53, iterations:   170] loss: 5.293\n",
      "[epoch 53, iterations:   175] loss: 5.007\n",
      "[epoch 53, iterations:   180] loss: 5.495\n",
      "[epoch 53, iterations:   185] loss: 5.497\n",
      "[epoch 53, iterations:   190] loss: 5.338\n",
      "[epoch 53, iterations:   195] loss: 5.820\n",
      "[epoch 53, iterations:   200] loss: 5.539\n",
      "[epoch 53, iterations:   205] loss: 5.129\n",
      "[epoch 53, iterations:   210] loss: 5.664\n",
      "[epoch 53, iterations:   215] loss: 5.683\n",
      "[epoch 53, iterations:   220] loss: 5.949\n",
      "[epoch 53, iterations:   225] loss: 6.202\n",
      "[epoch 53, iterations:   230] loss: 5.707\n",
      "[epoch 53, iterations:   235] loss: 5.199\n",
      "[epoch 53, iterations:   240] loss: 5.428\n",
      "[epoch 53, iterations:   245] loss: 5.562\n",
      "[epoch 53, iterations:   250] loss: 5.201\n",
      "[epoch 53, iterations:   255] loss: 5.615\n",
      "[epoch 53, iterations:   260] loss: 5.196\n",
      "[epoch 53, iterations:   265] loss: 5.642\n",
      "[epoch 53, iterations:   270] loss: 5.372\n",
      "[epoch 53, iterations:   275] loss: 5.873\n",
      "[epoch 53, iterations:   280] loss: 5.638\n",
      "[epoch 53, iterations:   285] loss: 5.415\n",
      "[epoch 53, iterations:   290] loss: 5.202\n",
      "[epoch 53, iterations:   295] loss: 5.388\n",
      "[epoch 53, iterations:   300] loss: 5.131\n",
      "[epoch 53, iterations:   305] loss: 5.458\n",
      "[epoch 53, iterations:   310] loss: 5.295\n",
      "[epoch 53, iterations:   315] loss: 4.870\n",
      "[epoch 53, iterations:   320] loss: 5.252\n",
      "[epoch 53, iterations:   325] loss: 6.231\n",
      "[epoch 53, iterations:   330] loss: 5.110\n",
      "[epoch 53, iterations:   335] loss: 5.469\n",
      "[epoch 53, iterations:   340] loss: 5.410\n",
      "[epoch 53, iterations:   345] loss: 5.749\n",
      "[epoch 53, iterations:   350] loss: 5.751\n",
      "[epoch 53, iterations:   355] loss: 5.321\n",
      "[epoch 53, iterations:   360] loss: 5.130\n",
      "[epoch 53, iterations:   365] loss: 5.453\n",
      "[epoch 53, iterations:   370] loss: 5.553\n",
      "[epoch 53, iterations:   375] loss: 5.309\n",
      "[epoch 53, iterations:   380] loss: 5.533\n",
      "[epoch 53, iterations:   385] loss: 5.728\n",
      "[epoch 53, iterations:   390] loss: 5.802\n",
      "[epoch 53, iterations:   395] loss: 5.411\n",
      "[epoch 53, iterations:   400] loss: 5.020\n",
      "[epoch 54, iterations:     5] loss: 5.647\n",
      "[epoch 54, iterations:    10] loss: 5.648\n",
      "[epoch 54, iterations:    15] loss: 5.499\n",
      "[epoch 54, iterations:    20] loss: 5.253\n",
      "[epoch 54, iterations:    25] loss: 5.280\n",
      "[epoch 54, iterations:    30] loss: 5.554\n",
      "[epoch 54, iterations:    35] loss: 5.474\n",
      "[epoch 54, iterations:    40] loss: 4.860\n",
      "[epoch 54, iterations:    45] loss: 5.040\n",
      "[epoch 54, iterations:    50] loss: 5.602\n",
      "[epoch 54, iterations:    55] loss: 5.372\n",
      "[epoch 54, iterations:    60] loss: 5.789\n",
      "[epoch 54, iterations:    65] loss: 5.427\n",
      "[epoch 54, iterations:    70] loss: 5.281\n",
      "[epoch 54, iterations:    75] loss: 5.120\n",
      "[epoch 54, iterations:    80] loss: 5.191\n",
      "[epoch 54, iterations:    85] loss: 5.379\n",
      "[epoch 54, iterations:    90] loss: 5.590\n",
      "[epoch 54, iterations:    95] loss: 5.554\n",
      "[epoch 54, iterations:   100] loss: 5.498\n",
      "[epoch 54, iterations:   105] loss: 5.259\n",
      "[epoch 54, iterations:   110] loss: 5.471\n",
      "[epoch 54, iterations:   115] loss: 5.648\n",
      "[epoch 54, iterations:   120] loss: 6.028\n",
      "[epoch 54, iterations:   125] loss: 5.624\n",
      "[epoch 54, iterations:   130] loss: 5.068\n",
      "[epoch 54, iterations:   135] loss: 5.702\n",
      "[epoch 54, iterations:   140] loss: 5.179\n",
      "[epoch 54, iterations:   145] loss: 6.003\n",
      "[epoch 54, iterations:   150] loss: 5.423\n",
      "[epoch 54, iterations:   155] loss: 5.201\n",
      "[epoch 54, iterations:   160] loss: 5.488\n",
      "[epoch 54, iterations:   165] loss: 5.483\n",
      "[epoch 54, iterations:   170] loss: 5.156\n",
      "[epoch 54, iterations:   175] loss: 5.574\n",
      "[epoch 54, iterations:   180] loss: 5.134\n",
      "[epoch 54, iterations:   185] loss: 5.164\n",
      "[epoch 54, iterations:   190] loss: 5.280\n",
      "[epoch 54, iterations:   195] loss: 6.316\n",
      "[epoch 54, iterations:   200] loss: 5.473\n",
      "[epoch 54, iterations:   205] loss: 5.892\n",
      "[epoch 54, iterations:   210] loss: 5.520\n",
      "[epoch 54, iterations:   215] loss: 5.241\n",
      "[epoch 54, iterations:   220] loss: 5.891\n",
      "[epoch 54, iterations:   225] loss: 5.159\n",
      "[epoch 54, iterations:   230] loss: 5.110\n",
      "[epoch 54, iterations:   235] loss: 5.717\n",
      "[epoch 54, iterations:   240] loss: 5.657\n",
      "[epoch 54, iterations:   245] loss: 5.543\n",
      "[epoch 54, iterations:   250] loss: 5.128\n",
      "[epoch 54, iterations:   255] loss: 5.625\n",
      "[epoch 54, iterations:   260] loss: 5.116\n",
      "[epoch 54, iterations:   265] loss: 5.161\n",
      "[epoch 54, iterations:   270] loss: 5.863\n",
      "[epoch 54, iterations:   275] loss: 5.600\n",
      "[epoch 54, iterations:   280] loss: 5.965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 54, iterations:   285] loss: 5.568\n",
      "[epoch 54, iterations:   290] loss: 5.276\n",
      "[epoch 54, iterations:   295] loss: 5.550\n",
      "[epoch 54, iterations:   300] loss: 5.262\n",
      "[epoch 54, iterations:   305] loss: 5.304\n",
      "[epoch 54, iterations:   310] loss: 5.365\n",
      "[epoch 54, iterations:   315] loss: 5.153\n",
      "[epoch 54, iterations:   320] loss: 5.789\n",
      "[epoch 54, iterations:   325] loss: 5.071\n",
      "[epoch 54, iterations:   330] loss: 5.139\n",
      "[epoch 54, iterations:   335] loss: 4.955\n",
      "[epoch 54, iterations:   340] loss: 5.649\n",
      "[epoch 54, iterations:   345] loss: 5.328\n",
      "[epoch 54, iterations:   350] loss: 5.863\n",
      "[epoch 54, iterations:   355] loss: 5.153\n",
      "[epoch 54, iterations:   360] loss: 5.408\n",
      "[epoch 54, iterations:   365] loss: 5.692\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "# print every 5th sequence\n",
    "print_running_loss = 5\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        sequence, label = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # set hidden states to zero after each sequence\n",
    "        hidden_states = lstm.init_hidden(batch_size)\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        label_scores = lstm(sequence,hidden_states)\n",
    "        last_label = torch.reshape(label_scores[0][len(label_scores[0])-1],[1,5]) # only the last element of sequence!\n",
    "        loss = loss_fn(last_label, label.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % print_running_loss == print_running_loss-1:    # print 10 times during an epoch\n",
    "            print('[epoch %d, iterations: %5d] loss: %.3f' %\n",
    "                  (overall_epochs, i + 1, running_loss / print_running_loss))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    ## save model every epoch\n",
    "    val_accuracy= validate()\n",
    "    file_name=\"weights-a\"+str(round(val_accuracy,4))+\"-e\"+str(overall_epochs)+\".pth\"\n",
    "    torch.save(lstm.state_dict(), \"models/\"+file_name)\n",
    "    \n",
    "    overall_epochs+=1\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ebe4b",
   "metadata": {},
   "source": [
    "## Training and Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa52973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "def decode_label(encoded_label):\n",
    "    return argmax(encoded_label)\n",
    "\n",
    "def get_accuracy(dataloader):\n",
    "    predictions=[]\n",
    "    correct_or_wrong=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequence,label in dataloader:\n",
    "            hidden_states=lstm.init_hidden(batch_size)\n",
    "            pred_label = lstm(sequence,hidden_states)\n",
    "            last_label = pred_label[0][len(pred_label[0])-1]\n",
    "            prediction= decode_label(last_label)\n",
    "            predictions.append(prediction)\n",
    "            correct_or_wrong.append(prediction == label)\n",
    "    return sum(correct_or_wrong)/len(correct_or_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca63d57c",
   "metadata": {},
   "source": [
    "## Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37609af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4150])\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3bbf21",
   "metadata": {},
   "source": [
    "## Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f311561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4100])\n"
     ]
    }
   ],
   "source": [
    "test_dataset=CustomSequenceDataset(val_x,val_y,transform = encode_genome_sequence)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size)\n",
    "print(get_accuracy(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
    "assert prediction_test.ndim == 1\n",
    "assert prediction_test.shape[0] == 250\n",
    "\n",
    "# AND SAVE EXACTLY AS SHOWN BELOW\n",
    "np.save('prediction.npy', prediction.astype(int))\n",
    "\n",
    "# MAKE SURE THAT THE FILE HAS THE CORRECT FORMAT\n",
    "def validate_prediction_format():\n",
    "    loaded = np.load('prediction.npy')\n",
    "    assert loaded.shape == (250, )\n",
    "    assert loaded.dtype == int\n",
    "    assert (loaded <= 4).all()\n",
    "    assert (loaded >= 0).all()\n",
    "validate_prediction_format()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
