{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3652cfa",
   "metadata": {},
   "source": [
    "## III c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8dab70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TrivialPhi(nn.Module):\n",
    "    \"\"\" Trivial implementation of Phi\"\"\"\n",
    "    def forward(self,inputs):\n",
    "        return inputs\n",
    "    \n",
    "class DensePhi(nn.Module):\n",
    "    \"\"\" Simple dense layer phi\"\"\"\n",
    "    def __init__(self,phi_in,phi_out):\n",
    "        super().__init__()\n",
    "        self.layer=nn.Linear(in_features=phi_in,out_features=phi_out)\n",
    "        self.reLU=nn.ReLU()\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        return self.reLU(self.layer(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9473bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "class F(nn.Module):\n",
    "    def __init__(self,phi_in:int,phi:nn.Module): \n",
    "        \"\"\"Creates a new instance of F.\n",
    "        Parameters\n",
    "        - - - - - -\n",
    "        phi_in : int\n",
    "        The input dimension of phi, i.e., the expected\n",
    "        shape is [batch_size, phi_in]\n",
    "        phi : nn.Module\n",
    "        PyTorch module which implements a neural network block \"Phi\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.phi = phi\n",
    "        self.phi_in = phi_in\n",
    "        self.xb_size = phi_in[1]\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        xa,xb=inputs.split([inputs.shape[1]-self.xb_size,self.xb_size],dim=1)\n",
    "        ya = xa + self.phi(xb)\n",
    "        yb = xb\n",
    "        return torch.cat((ya,yb),axis=1)\n",
    "\n",
    "    def inverse(self, inputs):\n",
    "        ya,yb=inputs.split([inputs.shape[1]-self.xb_size,self.xb_size],dim=1)\n",
    "        xb=yb\n",
    "        xa=ya-self.phi(yb)\n",
    "        return torch.cat((xa,xb),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94da997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (__main__.TestF) ... ok\n",
      "test_inverse (__main__.TestF) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.034s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f49c3168a30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "def test_phi(x):\n",
    "    return x\n",
    "\n",
    "class TestF(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        phi_in = (3,2) # batch_size = 3\n",
    "        phi_module=TrivialPhi()\n",
    "        self.model=F(phi_in,phi_module)\n",
    "        xa = torch.tensor(((1,2),(1,2),(1,2)))\n",
    "        xb = torch.tensor(((3,4),(3,4),(3,4)))\n",
    "        self.x = torch.cat((xa,xb),axis=1)\n",
    "        ya = torch.tensor(((4,6),(4,6),(4,6)))\n",
    "        yb = torch.tensor(((3,4),(3,4),(3,4)))\n",
    "        self.y= torch.cat((ya,yb),axis=1)\n",
    "        \n",
    "    def test_forward(self):\n",
    "        y_pred = self.model(self.x)\n",
    "        self.assertTrue(torch.equal(y_pred,self.y))\n",
    "        \n",
    "    def test_inverse(self):\n",
    "        x_pred = self.model.inverse(self.y)\n",
    "        self.assertTrue(torch.equal(x_pred,self.x))\n",
    "            \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ea12e",
   "metadata": {},
   "source": [
    "## III d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1be65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class S(nn.Module):\n",
    "    def __init__(self, n_A, n_B):\n",
    "        \"\"\" Creates a new instance of S.\n",
    "        Parameters\n",
    "        - - - - - -\n",
    "        n_A : int\n",
    "        Number of components for x_A\n",
    "        n_B : int\n",
    "        Number of components for x_B\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_A=n_A\n",
    "        self.n_B=n_B\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        xa,xb=inputs.split([self.n_A,self.n_B],dim=1)\n",
    "        return torch.cat((xb,xa),dim=1)\n",
    "    \n",
    "    def inverse(self, inputs):\n",
    "        xb,xa=inputs.split([self.n_B,self.n_A],dim=1)\n",
    "        return torch.cat((xa,xb),dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb1d951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (__main__.TestF) ... ok\n",
      "test_inverse (__main__.TestF) ... ok\n",
      "test_forward (__main__.TestS) ... ok\n",
      "test_inverse (__main__.TestS) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.012s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f4a10455850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestS(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.model=S(2,2)\n",
    "        # batch size 4\n",
    "        xa = torch.tensor(((1,2),(1,2),(1,2),(1,2)))\n",
    "        xb = torch.tensor(((3,4),(3,4),(3,4),(3,4)))\n",
    "        self.forward=torch.cat(tensors=(xa,xb),dim=1)\n",
    "        self.backward=torch.cat(tensors=(xb,xa),dim=1)\n",
    "        \n",
    "    def test_forward(self):\n",
    "        y_pred = self.model(self.forward)\n",
    "        self.assertTrue(torch.equal(y_pred,self.backward))\n",
    "        \n",
    "    def test_inverse(self):\n",
    "        y_pred = self.model.inverse(self.backward)\n",
    "        self.assertTrue(torch.equal(y_pred,self.forward))\n",
    "                    \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014c6e7",
   "metadata": {},
   "source": [
    "## III e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34f6148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self,n_A,n_B,phi):\n",
    "        \"\"\" Creates a new instance of G.\n",
    "        Parameters\n",
    "        - - - - - -\n",
    "        n_A : int\n",
    "        Number of components for x_A\n",
    "        n_B : int\n",
    "        Number of components for x_B\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_A=n_A\n",
    "        self.n_B=n_B\n",
    "        \n",
    "        self.F1=F(phi_in=(4,2),phi=phi)\n",
    "        self.S1=S(2,2)\n",
    "        self.F2=F(phi_in=(4,2),phi=phi)\n",
    "        self.S2=S(2,2)\n",
    "        self.F3=F(phi_in=(4,2),phi=phi)\n",
    "        self.network_stack=[self.F1,self.S1,self.F2,self.S2,self.F3]\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        current_value=inputs\n",
    "        for layer in self.network_stack:\n",
    "            current_value=layer(current_value)\n",
    "        return current_value\n",
    "    \n",
    "    def inverse(self,inputs):\n",
    "        current_value=inputs\n",
    "        for layer in self.network_stack:\n",
    "            current_value=layer.inverse(current_value)\n",
    "        return current_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2414424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (__main__.TestF) ... ok\n",
      "test_inverse (__main__.TestF) ... ok\n",
      "test_forward (__main__.TestG) ... ok\n",
      "test_inverse (__main__.TestG) ... ok\n",
      "test_training (__main__.TestG) ... ok\n",
      "test_forward (__main__.TestS) ... ok\n",
      "test_inverse (__main__.TestS) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.9411, 16.0069,  7.1359,  9.9806],\n",
      "        [10.9411, 16.0069,  7.1359,  9.9806],\n",
      "        [10.9411, 16.0069,  7.1359,  9.9806],\n",
      "        [10.9411, 16.0069,  7.1359,  9.9806]])\n",
      "tensor([[11., 16.,  7., 10.],\n",
      "        [11., 16.,  7., 10.],\n",
      "        [11., 16.,  7., 10.],\n",
      "        [11., 16.,  7., 10.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 1.463s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f49c307b580>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import torch.optim as optim\n",
    "\n",
    "class TestG(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.model=G(2,2,TrivialPhi())\n",
    "        # batch size 4\n",
    "        xa = torch.tensor(((1,2),(1,2),(1,2),(1,2))).float()\n",
    "        xb = torch.tensor(((3,4),(3,4),(3,4),(3,4))).float()\n",
    "        ## calculated this solution by hand\n",
    "        ya = torch.tensor(((11,16),(11,16),(11,16),(11,16))).float()\n",
    "        yb = torch.tensor(((7,10),(7,10),(7,10),(7,10))).float()\n",
    "        self.input=torch.cat(tensors=(xa,xb),dim=1)\n",
    "        self.solution=torch.cat(tensors=(ya,yb),dim=1)\n",
    "        \n",
    "    def test_forward(self):\n",
    "        y_pred = self.model(self.input)\n",
    "        self.assertTrue(torch.equal(y_pred,self.solution))\n",
    "        \n",
    "    def test_inverse(self):\n",
    "        y_pred = self.model.inverse(self.solution)\n",
    "        self.assertTrue(torch.equal(y_pred,self.input))\n",
    "        \n",
    "    def test_training(self):\n",
    "        model= G(2,2,DensePhi(phi_in=2,phi_out=2))\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer=optim.Adam(model.parameters(), lr=0.005)\n",
    "        \n",
    "        #training \n",
    "        for epoch in range(0,1000):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(self.input)\n",
    "            loss = loss_fn(outputs, self.solution)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        #test\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(self.input)\n",
    "            print(y_pred)\n",
    "            print(self.solution)\n",
    "            relative_tolerance=0.1\n",
    "            absolute_tolerance=1\n",
    "            elementwise_compare = torch.isclose(y_pred,self.solution,relative_tolerance,absolute_tolerance)\n",
    "            self.assertTrue(elementwise_compare.all())\n",
    "        \n",
    "                    \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
